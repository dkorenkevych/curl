{"episode": 0.0, "episode_reward": 0.0, "eval_time": 10.588212251663208, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 0}
{"episode": 4.0, "episode_reward": 0.0, "eval_time": 9.83199691772461, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 1000}
{"episode": 7.0, "episode_reward": 0.0, "eval_time": 10.13217282295227, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 2000}
{"episode": 10.0, "episode_reward": 0.0, "eval_time": 10.212539672851562, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 3000}
{"episode": 13.0, "episode_reward": 0.0, "eval_time": 10.176899194717407, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 4000}
{"episode": 16.0, "episode_reward": 0.0, "eval_time": 10.15816593170166, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 5000}
{"episode": 19.0, "episode_reward": 0.0, "eval_time": 10.158259391784668, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 6000}
{"episode": 22.0, "episode_reward": 0.0, "eval_time": 10.123363971710205, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 7000}
{"episode": 25.0, "episode_reward": 0.0, "eval_time": 10.155610799789429, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 8000}
{"episode": 28.0, "episode_reward": 0.0, "eval_time": 10.184259176254272, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 9000}
{"episode": 31.0, "episode_reward": 0.0, "eval_time": 10.111972332000732, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 10000}
{"episode": 34.0, "episode_reward": 0.0, "eval_time": 10.172097444534302, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 11000}
{"episode": 37.0, "episode_reward": 0.0, "eval_time": 10.21830129623413, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 12000}
{"episode": 40.0, "episode_reward": 0.0, "eval_time": 10.16208815574646, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 13000}
{"episode": 43.0, "episode_reward": 0.0, "eval_time": 10.187361001968384, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 14000}
{"episode": 46.0, "episode_reward": 0.0, "eval_time": 10.153969526290894, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 15000}
{"episode": 49.0, "episode_reward": 0.0, "eval_time": 10.11526083946228, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 16000}
{"episode": 52.0, "episode_reward": 0.0, "eval_time": 10.26585578918457, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 17000}
{"episode": 55.0, "episode_reward": 0.0, "eval_time": 10.129635334014893, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 18000}
{"episode": 58.0, "episode_reward": 0.0, "eval_time": 10.161766290664673, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 19000}
{"episode": 61.0, "episode_reward": -0.4, "eval_time": 10.17420220375061, "mean_episode_reward": -0.4, "best_episode_reward": 2.0, "step": 20000}
{"episode": 64.0, "episode_reward": 0.0, "eval_time": 10.042781591415405, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 21000}
{"episode": 67.0, "episode_reward": 0.0, "eval_time": 10.028205156326294, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 22000}
{"episode": 70.0, "episode_reward": 0.0, "eval_time": 10.129155158996582, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 23000}
{"episode": 73.0, "episode_reward": 0.0, "eval_time": 10.128115892410278, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 24000}
{"episode": 76.0, "episode_reward": 0.2, "eval_time": 10.252363681793213, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 25000}
{"episode": 79.0, "episode_reward": 0.0, "eval_time": 9.974561929702759, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 26000}
{"episode": 82.0, "episode_reward": 0.0, "eval_time": 10.1951904296875, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 27000}
{"episode": 85.0, "episode_reward": 0.0, "eval_time": 10.16358733177185, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 28000}
{"episode": 88.0, "episode_reward": 0.0, "eval_time": 10.284868955612183, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 29000}
{"episode": 91.0, "episode_reward": 0.0, "eval_time": 10.250756025314331, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 30000}
{"episode": 94.0, "episode_reward": 0.0, "eval_time": 10.058724880218506, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 31000}
{"episode": 97.0, "episode_reward": 0.0, "eval_time": 10.256876945495605, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 32000}
{"episode": 100.0, "episode_reward": 0.0, "eval_time": 10.094559907913208, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 33000}
{"episode": 103.0, "episode_reward": 0.0, "eval_time": 9.93749737739563, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 34000}
{"episode": 106.0, "episode_reward": 0.0, "eval_time": 10.053812742233276, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 35000}
{"episode": 109.0, "episode_reward": 0.0, "eval_time": 10.26028323173523, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 36000}
{"episode": 112.0, "episode_reward": -0.1, "eval_time": 9.855483293533325, "mean_episode_reward": -0.1, "best_episode_reward": 0.0, "step": 37000}
{"episode": 115.0, "episode_reward": 0.1, "eval_time": 10.159229516983032, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 38000}
{"episode": 118.0, "episode_reward": -0.7, "eval_time": 10.172957420349121, "mean_episode_reward": -0.7, "best_episode_reward": 0.0, "step": 39000}
{"episode": 121.0, "episode_reward": 0.0, "eval_time": 10.277249097824097, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 40000}
{"episode": 124.0, "episode_reward": 0.0, "eval_time": 10.189512491226196, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 41000}
{"episode": 127.0, "episode_reward": 0.0, "eval_time": 10.229564666748047, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 42000}
{"episode": 130.0, "episode_reward": 0.0, "eval_time": 10.175331115722656, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 43000}
{"episode": 133.0, "episode_reward": 0.0, "eval_time": 10.215142726898193, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 44000}
{"episode": 136.0, "episode_reward": 0.0, "eval_time": 9.882966041564941, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 45000}
{"episode": 139.0, "episode_reward": 0.8, "eval_time": 10.232894897460938, "mean_episode_reward": 0.8, "best_episode_reward": 1.0, "step": 46000}
{"episode": 142.0, "episode_reward": 0.0, "eval_time": 10.174318075180054, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 47000}
{"episode": 145.0, "episode_reward": -0.7, "eval_time": 9.998671531677246, "mean_episode_reward": -0.7, "best_episode_reward": 0.0, "step": 48000}
{"episode": 148.0, "episode_reward": 0.0, "eval_time": 10.01923680305481, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 49000}
{"episode": 151.0, "episode_reward": 0.1, "eval_time": 10.591414451599121, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 50000}
{"episode": 154.0, "episode_reward": 0.0, "eval_time": 9.992497205734253, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 51000}
{"episode": 157.0, "episode_reward": 0.0, "eval_time": 10.158251762390137, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 52000}
{"episode": 160.0, "episode_reward": 0.0, "eval_time": 10.240278720855713, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 53000}
{"episode": 163.0, "episode_reward": 0.0, "eval_time": 10.125246047973633, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 54000}
{"episode": 166.0, "episode_reward": 0.0, "eval_time": 9.769787788391113, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 55000}
{"episode": 169.0, "episode_reward": -0.6, "eval_time": 10.236189126968384, "mean_episode_reward": -0.6, "best_episode_reward": 0.0, "step": 56000}
{"episode": 172.0, "episode_reward": 0.0, "eval_time": 9.922837257385254, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 57000}
{"episode": 175.0, "episode_reward": 0.0, "eval_time": 10.275188207626343, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 58000}
{"episode": 178.0, "episode_reward": 0.0, "eval_time": 10.288722038269043, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 59000}
{"episode": 181.0, "episode_reward": 0.0, "eval_time": 10.365269184112549, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 60000}
{"episode": 184.0, "episode_reward": 0.8, "eval_time": 10.030066728591919, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 61000}
{"episode": 187.0, "episode_reward": 0.0, "eval_time": 10.095769882202148, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 62000}
{"episode": 190.0, "episode_reward": 0.0, "eval_time": 10.186392307281494, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 63000}
{"episode": 193.0, "episode_reward": 0.0, "eval_time": 10.302765846252441, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 64000}
{"episode": 196.0, "episode_reward": 0.0, "eval_time": 10.291263341903687, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 65000}
{"episode": 199.0, "episode_reward": 0.0, "eval_time": 10.170186042785645, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 66000}
{"episode": 202.0, "episode_reward": 0.0, "eval_time": 10.165887832641602, "mean_episode_reward": 0.0, "best_episode_reward": 1.0, "step": 67000}
{"episode": 205.0, "episode_reward": 0.2, "eval_time": 10.151476383209229, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 68000}
{"episode": 208.0, "episode_reward": 0.0, "eval_time": 10.182319402694702, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 69000}
{"episode": 211.0, "episode_reward": 3.0, "eval_time": 9.690443277359009, "mean_episode_reward": 3.0, "best_episode_reward": 5.0, "step": 70000}
{"episode": 214.0, "episode_reward": 0.0, "eval_time": 10.308354616165161, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 71000}
{"episode": 217.0, "episode_reward": 0.0, "eval_time": 10.275199174880981, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 72000}
{"episode": 220.0, "episode_reward": -0.2, "eval_time": 9.91813039779663, "mean_episode_reward": -0.2, "best_episode_reward": 1.0, "step": 73000}
{"episode": 223.0, "episode_reward": 0.1, "eval_time": 10.31955885887146, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 74000}
{"episode": 226.0, "episode_reward": 0.0, "eval_time": 10.266441106796265, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 75000}
{"episode": 229.0, "episode_reward": 0.0, "eval_time": 10.308490753173828, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 76000}
{"episode": 232.0, "episode_reward": 0.0, "eval_time": 10.285839080810547, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 77000}
{"episode": 235.0, "episode_reward": 0.0, "eval_time": 10.064940214157104, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 78000}
{"episode": 238.0, "episode_reward": 0.1, "eval_time": 10.167694807052612, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 79000}
{"episode": 241.0, "episode_reward": 0.2, "eval_time": 10.2248055934906, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 80000}
{"episode": 244.0, "episode_reward": 0.0, "eval_time": 10.179356098175049, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 81000}
{"episode": 247.0, "episode_reward": 0.0, "eval_time": 10.198511362075806, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 82000}
{"episode": 250.0, "episode_reward": 0.0, "eval_time": 10.180350303649902, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 83000}
{"episode": 253.0, "episode_reward": 0.0, "eval_time": 10.079773664474487, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 84000}
{"episode": 256.0, "episode_reward": 0.7, "eval_time": 10.133871078491211, "mean_episode_reward": 0.7, "best_episode_reward": 1.0, "step": 85000}
{"episode": 259.0, "episode_reward": 0.0, "eval_time": 10.378039360046387, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 86000}
{"episode": 262.0, "episode_reward": 0.0, "eval_time": 10.114068746566772, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 87000}
{"episode": 265.0, "episode_reward": 0.5, "eval_time": 10.186069965362549, "mean_episode_reward": 0.5, "best_episode_reward": 1.0, "step": 88000}
{"episode": 268.0, "episode_reward": 1.8, "eval_time": 10.113000869750977, "mean_episode_reward": 1.8, "best_episode_reward": 3.0, "step": 89000}
{"episode": 271.0, "episode_reward": 0.3, "eval_time": 10.115089654922485, "mean_episode_reward": 0.3, "best_episode_reward": 1.0, "step": 90000}
{"episode": 274.0, "episode_reward": 0.0, "eval_time": 10.228032350540161, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 91000}
{"episode": 277.0, "episode_reward": 1.0, "eval_time": 10.062122344970703, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 92000}
{"episode": 280.0, "episode_reward": 0.5, "eval_time": 10.139261484146118, "mean_episode_reward": 0.5, "best_episode_reward": 1.0, "step": 93000}
{"episode": 283.0, "episode_reward": 0.6, "eval_time": 10.119559049606323, "mean_episode_reward": 0.6, "best_episode_reward": 1.0, "step": 94000}
{"episode": 286.0, "episode_reward": 0.0, "eval_time": 10.060053825378418, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 95000}
{"episode": 289.0, "episode_reward": 0.4, "eval_time": 10.319113492965698, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 96000}
{"episode": 292.0, "episode_reward": 0.0, "eval_time": 10.1436026096344, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 97000}
{"episode": 295.0, "episode_reward": 1.7, "eval_time": 10.063475370407104, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 98000}
{"episode": 298.0, "episode_reward": 1.5, "eval_time": 9.98900580406189, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 99000}
{"episode": 301.0, "episode_reward": -0.1, "eval_time": 10.197620630264282, "mean_episode_reward": -0.1, "best_episode_reward": 0.0, "step": 100000}
{"episode": 304.0, "episode_reward": 1.3, "eval_time": 10.096758604049683, "mean_episode_reward": 1.3, "best_episode_reward": 2.0, "step": 101000}
{"episode": 307.0, "episode_reward": 0.6, "eval_time": 10.060139656066895, "mean_episode_reward": 0.6, "best_episode_reward": 1.0, "step": 102000}
{"episode": 310.0, "episode_reward": -0.1, "eval_time": 10.218307733535767, "mean_episode_reward": -0.1, "best_episode_reward": 1.0, "step": 103000}
{"episode": 313.0, "episode_reward": 0.7, "eval_time": 10.152483701705933, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 104000}
{"episode": 316.0, "episode_reward": 0.6, "eval_time": 10.154556512832642, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 105000}
{"episode": 319.0, "episode_reward": -0.3, "eval_time": 10.098670721054077, "mean_episode_reward": -0.3, "best_episode_reward": 1.0, "step": 106000}
{"episode": 322.0, "episode_reward": 1.4, "eval_time": 9.960630893707275, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 107000}
{"episode": 325.0, "episode_reward": -0.1, "eval_time": 10.007842063903809, "mean_episode_reward": -0.1, "best_episode_reward": 0.0, "step": 108000}
{"episode": 328.0, "episode_reward": 0.5, "eval_time": 9.799115657806396, "mean_episode_reward": 0.5, "best_episode_reward": 3.0, "step": 109000}
{"episode": 331.0, "episode_reward": 1.3, "eval_time": 10.06726598739624, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 110000}
{"episode": 334.0, "episode_reward": 0.7, "eval_time": 10.048980474472046, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 111000}
{"episode": 337.0, "episode_reward": 1.8, "eval_time": 10.056326866149902, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 112000}
{"episode": 340.0, "episode_reward": 2.5, "eval_time": 9.963495016098022, "mean_episode_reward": 2.5, "best_episode_reward": 4.0, "step": 113000}
{"episode": 343.0, "episode_reward": 2.1, "eval_time": 10.082975625991821, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 114000}
{"episode": 346.0, "episode_reward": 1.8, "eval_time": 10.153322696685791, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 115000}
{"episode": 349.0, "episode_reward": 0.5, "eval_time": 10.309434175491333, "mean_episode_reward": 0.5, "best_episode_reward": 4.0, "step": 116000}
{"episode": 352.0, "episode_reward": 1.3, "eval_time": 10.015986919403076, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 117000}
{"episode": 355.0, "episode_reward": 1.6, "eval_time": 10.01753568649292, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 118000}
{"episode": 358.0, "episode_reward": 2.2, "eval_time": 10.034627676010132, "mean_episode_reward": 2.2, "best_episode_reward": 3.0, "step": 119000}
{"episode": 361.0, "episode_reward": 1.0, "eval_time": 10.113183736801147, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 120000}
{"episode": 364.0, "episode_reward": 0.8, "eval_time": 10.200133800506592, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 121000}
{"episode": 367.0, "episode_reward": 1.7, "eval_time": 9.973622560501099, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 122000}
{"episode": 370.0, "episode_reward": 0.9, "eval_time": 10.01561427116394, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 123000}
{"episode": 373.0, "episode_reward": 2.5, "eval_time": 10.09555172920227, "mean_episode_reward": 2.5, "best_episode_reward": 4.0, "step": 124000}
{"episode": 376.0, "episode_reward": 0.0, "eval_time": 10.07606554031372, "mean_episode_reward": 0.0, "best_episode_reward": 2.0, "step": 125000}
{"episode": 379.0, "episode_reward": 2.2, "eval_time": 10.048712253570557, "mean_episode_reward": 2.2, "best_episode_reward": 5.0, "step": 126000}
{"episode": 382.0, "episode_reward": 1.6, "eval_time": 10.005772590637207, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 127000}
{"episode": 385.0, "episode_reward": 1.9, "eval_time": 10.098748922348022, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 128000}
{"episode": 388.0, "episode_reward": 1.4, "eval_time": 10.023226022720337, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 129000}
{"episode": 391.0, "episode_reward": 1.0, "eval_time": 10.219744205474854, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 130000}
{"episode": 394.0, "episode_reward": 0.8, "eval_time": 10.128359079360962, "mean_episode_reward": 0.8, "best_episode_reward": 4.0, "step": 131000}
{"episode": 397.0, "episode_reward": 0.1, "eval_time": 10.042502403259277, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 132000}
{"episode": 400.0, "episode_reward": 0.2, "eval_time": 10.11434268951416, "mean_episode_reward": 0.2, "best_episode_reward": 2.0, "step": 133000}
{"episode": 403.0, "episode_reward": 1.5, "eval_time": 10.071952819824219, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 134000}
{"episode": 406.0, "episode_reward": 1.0, "eval_time": 10.047296047210693, "mean_episode_reward": 1.0, "best_episode_reward": 4.0, "step": 135000}
{"episode": 409.0, "episode_reward": 0.8, "eval_time": 10.06246018409729, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 136000}
{"episode": 412.0, "episode_reward": 0.8, "eval_time": 10.191307544708252, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 137000}
{"episode": 415.0, "episode_reward": 0.3, "eval_time": 9.994196653366089, "mean_episode_reward": 0.3, "best_episode_reward": 3.0, "step": 138000}
{"episode": 418.0, "episode_reward": 1.3, "eval_time": 10.184972524642944, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 139000}
{"episode": 421.0, "episode_reward": 1.3, "eval_time": 10.155628204345703, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 140000}
{"episode": 424.0, "episode_reward": 1.0, "eval_time": 10.17020320892334, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 141000}
{"episode": 427.0, "episode_reward": 0.9, "eval_time": 10.194794178009033, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 142000}
{"episode": 430.0, "episode_reward": 0.7, "eval_time": 10.158750534057617, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 143000}
{"episode": 433.0, "episode_reward": 2.0, "eval_time": 10.149971723556519, "mean_episode_reward": 2.0, "best_episode_reward": 3.0, "step": 144000}
{"episode": 436.0, "episode_reward": 1.0, "eval_time": 10.19100284576416, "mean_episode_reward": 1.0, "best_episode_reward": 4.0, "step": 145000}
{"episode": 439.0, "episode_reward": 1.3, "eval_time": 10.128075122833252, "mean_episode_reward": 1.3, "best_episode_reward": 5.0, "step": 146000}
{"episode": 442.0, "episode_reward": 1.0, "eval_time": 10.194583654403687, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 147000}
{"episode": 445.0, "episode_reward": 1.3, "eval_time": 10.111308813095093, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 148000}
{"episode": 448.0, "episode_reward": 0.2, "eval_time": 10.1134512424469, "mean_episode_reward": 0.2, "best_episode_reward": 2.0, "step": 149000}
{"episode": 451.0, "episode_reward": 1.8, "eval_time": 10.030760049819946, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 150000}
{"episode": 454.0, "episode_reward": 0.7, "eval_time": 10.18150806427002, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 151000}
{"episode": 457.0, "episode_reward": 0.9, "eval_time": 10.22656774520874, "mean_episode_reward": 0.9, "best_episode_reward": 4.0, "step": 152000}
{"episode": 460.0, "episode_reward": 0.8, "eval_time": 10.101301431655884, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 153000}
{"episode": 463.0, "episode_reward": 0.3, "eval_time": 10.014023780822754, "mean_episode_reward": 0.3, "best_episode_reward": 1.0, "step": 154000}
{"episode": 466.0, "episode_reward": 1.3, "eval_time": 10.16942572593689, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 155000}
{"episode": 469.0, "episode_reward": 0.4, "eval_time": 10.144803285598755, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 156000}
{"episode": 472.0, "episode_reward": 0.8, "eval_time": 10.19187879562378, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 157000}
{"episode": 475.0, "episode_reward": 0.9, "eval_time": 10.186277866363525, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 158000}
{"episode": 478.0, "episode_reward": 0.6, "eval_time": 10.237957239151001, "mean_episode_reward": 0.6, "best_episode_reward": 3.0, "step": 159000}
{"episode": 481.0, "episode_reward": 0.3, "eval_time": 10.166187047958374, "mean_episode_reward": 0.3, "best_episode_reward": 1.0, "step": 160000}
{"episode": 484.0, "episode_reward": 2.7, "eval_time": 10.0297110080719, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 161000}
{"episode": 487.0, "episode_reward": 1.7, "eval_time": 10.18488597869873, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 162000}
{"episode": 490.0, "episode_reward": 1.9, "eval_time": 10.098435640335083, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 163000}
{"episode": 493.0, "episode_reward": 1.5, "eval_time": 10.270587921142578, "mean_episode_reward": 1.5, "best_episode_reward": 5.0, "step": 164000}
{"episode": 496.0, "episode_reward": 2.2, "eval_time": 10.068517446517944, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 165000}
{"episode": 499.0, "episode_reward": 0.8, "eval_time": 10.091180086135864, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 166000}
{"episode": 502.0, "episode_reward": 1.1, "eval_time": 10.152605533599854, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 167000}
{"episode": 505.0, "episode_reward": 0.1, "eval_time": 10.141106605529785, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 168000}
{"episode": 508.0, "episode_reward": -0.3, "eval_time": 10.150999307632446, "mean_episode_reward": -0.3, "best_episode_reward": 1.0, "step": 169000}
{"episode": 511.0, "episode_reward": 1.9, "eval_time": 10.037289381027222, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 170000}
{"episode": 514.0, "episode_reward": 0.7, "eval_time": 10.097952842712402, "mean_episode_reward": 0.7, "best_episode_reward": 3.0, "step": 171000}
{"episode": 517.0, "episode_reward": 1.2, "eval_time": 10.131465911865234, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 172000}
{"episode": 520.0, "episode_reward": 1.5, "eval_time": 10.156695365905762, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 173000}
{"episode": 523.0, "episode_reward": 1.8, "eval_time": 9.99691915512085, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 174000}
{"episode": 526.0, "episode_reward": 1.0, "eval_time": 9.992267847061157, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 175000}
{"episode": 529.0, "episode_reward": 1.2, "eval_time": 10.080182313919067, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 176000}
{"episode": 532.0, "episode_reward": 1.8, "eval_time": 10.11656641960144, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 177000}
{"episode": 535.0, "episode_reward": 0.5, "eval_time": 10.193950414657593, "mean_episode_reward": 0.5, "best_episode_reward": 4.0, "step": 178000}
{"episode": 538.0, "episode_reward": -0.1, "eval_time": 10.163711786270142, "mean_episode_reward": -0.1, "best_episode_reward": 3.0, "step": 179000}
{"episode": 541.0, "episode_reward": 1.1, "eval_time": 10.142894983291626, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 180000}
{"episode": 544.0, "episode_reward": 2.3, "eval_time": 10.128191232681274, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 181000}
{"episode": 547.0, "episode_reward": 1.1, "eval_time": 10.1833016872406, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 182000}
{"episode": 550.0, "episode_reward": 0.6, "eval_time": 10.181939363479614, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 183000}
{"episode": 553.0, "episode_reward": 0.7, "eval_time": 10.151037216186523, "mean_episode_reward": 0.7, "best_episode_reward": 3.0, "step": 184000}
{"episode": 556.0, "episode_reward": 1.7, "eval_time": 10.140788793563843, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 185000}
{"episode": 559.0, "episode_reward": 0.9, "eval_time": 10.0485360622406, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 186000}
{"episode": 562.0, "episode_reward": 1.8, "eval_time": 10.265029668807983, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 187000}
{"episode": 565.0, "episode_reward": 1.1, "eval_time": 10.180859327316284, "mean_episode_reward": 1.1, "best_episode_reward": 2.0, "step": 188000}
{"episode": 568.0, "episode_reward": 1.9, "eval_time": 10.101603507995605, "mean_episode_reward": 1.9, "best_episode_reward": 6.0, "step": 189000}
{"episode": 571.0, "episode_reward": 0.6, "eval_time": 10.120009899139404, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 190000}
{"episode": 574.0, "episode_reward": 2.2, "eval_time": 10.022373914718628, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 191000}
{"episode": 577.0, "episode_reward": 2.3, "eval_time": 10.069455623626709, "mean_episode_reward": 2.3, "best_episode_reward": 7.0, "step": 192000}
{"episode": 580.0, "episode_reward": 2.2, "eval_time": 10.234512090682983, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 193000}
{"episode": 583.0, "episode_reward": 1.4, "eval_time": 10.100836038589478, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 194000}
{"episode": 586.0, "episode_reward": 0.8, "eval_time": 10.226033210754395, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 195000}
{"episode": 589.0, "episode_reward": 1.7, "eval_time": 10.09992003440857, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 196000}
{"episode": 592.0, "episode_reward": 1.4, "eval_time": 10.259546995162964, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 197000}
{"episode": 595.0, "episode_reward": 0.8, "eval_time": 10.237873792648315, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 198000}
{"episode": 598.0, "episode_reward": 1.1, "eval_time": 10.076516151428223, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 199000}
{"episode": 601.0, "episode_reward": 2.1, "eval_time": 10.23823618888855, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 200000}
{"episode": 604.0, "episode_reward": 1.0, "eval_time": 10.107900619506836, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 201000}
{"episode": 607.0, "episode_reward": 0.7, "eval_time": 10.098916053771973, "mean_episode_reward": 0.7, "best_episode_reward": 3.0, "step": 202000}
{"episode": 610.0, "episode_reward": 1.2, "eval_time": 10.114935636520386, "mean_episode_reward": 1.2, "best_episode_reward": 2.0, "step": 203000}
{"episode": 613.0, "episode_reward": 1.0, "eval_time": 10.082849264144897, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 204000}
{"episode": 616.0, "episode_reward": 1.6, "eval_time": 10.1486074924469, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 205000}
{"episode": 619.0, "episode_reward": 1.1, "eval_time": 10.098952770233154, "mean_episode_reward": 1.1, "best_episode_reward": 2.0, "step": 206000}
{"episode": 622.0, "episode_reward": 1.3, "eval_time": 10.09331202507019, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 207000}
{"episode": 625.0, "episode_reward": 1.8, "eval_time": 9.96475863456726, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 208000}
{"episode": 628.0, "episode_reward": 0.4, "eval_time": 10.108809232711792, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 209000}
{"episode": 631.0, "episode_reward": 0.8, "eval_time": 10.138644695281982, "mean_episode_reward": 0.8, "best_episode_reward": 4.0, "step": 210000}
{"episode": 634.0, "episode_reward": 0.9, "eval_time": 10.049194097518921, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 211000}
{"episode": 637.0, "episode_reward": 0.9, "eval_time": 10.087430238723755, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 212000}
{"episode": 640.0, "episode_reward": 0.8, "eval_time": 10.156963109970093, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 213000}
{"episode": 643.0, "episode_reward": 2.0, "eval_time": 10.143568277359009, "mean_episode_reward": 2.0, "best_episode_reward": 4.0, "step": 214000}
{"episode": 646.0, "episode_reward": 1.2, "eval_time": 10.092029571533203, "mean_episode_reward": 1.2, "best_episode_reward": 2.0, "step": 215000}
{"episode": 649.0, "episode_reward": 1.8, "eval_time": 10.162038326263428, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 216000}
{"episode": 652.0, "episode_reward": 1.7, "eval_time": 10.162657260894775, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 217000}
{"episode": 655.0, "episode_reward": 1.0, "eval_time": 10.108461618423462, "mean_episode_reward": 1.0, "best_episode_reward": 4.0, "step": 218000}
{"episode": 658.0, "episode_reward": 1.7, "eval_time": 9.994919300079346, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 219000}
{"episode": 661.0, "episode_reward": 0.5, "eval_time": 10.186141014099121, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 220000}
{"episode": 664.0, "episode_reward": 2.3, "eval_time": 10.155109167098999, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 221000}
{"episode": 667.0, "episode_reward": 1.5, "eval_time": 9.990300416946411, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 222000}
{"episode": 670.0, "episode_reward": 2.1, "eval_time": 10.054096221923828, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 223000}
{"episode": 673.0, "episode_reward": 1.4, "eval_time": 10.0458984375, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 224000}
{"episode": 676.0, "episode_reward": 1.1, "eval_time": 10.07097315788269, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 225000}
{"episode": 679.0, "episode_reward": 1.6, "eval_time": 10.171402931213379, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 226000}
{"episode": 682.0, "episode_reward": 1.7, "eval_time": 10.222458600997925, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 227000}
{"episode": 685.0, "episode_reward": 2.9, "eval_time": 10.073095083236694, "mean_episode_reward": 2.9, "best_episode_reward": 5.0, "step": 228000}
{"episode": 688.0, "episode_reward": 1.6, "eval_time": 10.048752069473267, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 229000}
{"episode": 691.0, "episode_reward": 1.5, "eval_time": 10.016664028167725, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 230000}
{"episode": 694.0, "episode_reward": 1.2, "eval_time": 10.107630014419556, "mean_episode_reward": 1.2, "best_episode_reward": 6.0, "step": 231000}
{"episode": 697.0, "episode_reward": 1.8, "eval_time": 10.15130615234375, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 232000}
{"episode": 700.0, "episode_reward": 0.8, "eval_time": 10.292421579360962, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 233000}
{"episode": 703.0, "episode_reward": 1.6, "eval_time": 10.224217891693115, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 234000}
{"episode": 706.0, "episode_reward": 1.2, "eval_time": 10.304418563842773, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 235000}
{"episode": 709.0, "episode_reward": 0.5, "eval_time": 10.016281366348267, "mean_episode_reward": 0.5, "best_episode_reward": 3.0, "step": 236000}
{"episode": 712.0, "episode_reward": 2.1, "eval_time": 9.997723579406738, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 237000}
{"episode": 715.0, "episode_reward": 1.4, "eval_time": 10.361306428909302, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 238000}
{"episode": 718.0, "episode_reward": 2.2, "eval_time": 10.027915954589844, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 239000}
{"episode": 721.0, "episode_reward": 1.6, "eval_time": 10.179484844207764, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 240000}
{"episode": 724.0, "episode_reward": 1.6, "eval_time": 10.038363695144653, "mean_episode_reward": 1.6, "best_episode_reward": 5.0, "step": 241000}
{"episode": 727.0, "episode_reward": 0.8, "eval_time": 10.15100884437561, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 242000}
{"episode": 730.0, "episode_reward": 2.7, "eval_time": 10.033198833465576, "mean_episode_reward": 2.7, "best_episode_reward": 4.0, "step": 243000}
{"episode": 733.0, "episode_reward": 0.5, "eval_time": 10.211349248886108, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 244000}
{"episode": 736.0, "episode_reward": 1.4, "eval_time": 10.446344375610352, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 245000}
{"episode": 739.0, "episode_reward": 2.1, "eval_time": 10.155272483825684, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 246000}
{"episode": 742.0, "episode_reward": 1.6, "eval_time": 10.255054712295532, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 247000}
{"episode": 745.0, "episode_reward": 0.8, "eval_time": 10.025193929672241, "mean_episode_reward": 0.8, "best_episode_reward": 4.0, "step": 248000}
{"episode": 748.0, "episode_reward": 1.1, "eval_time": 10.235467433929443, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 249000}
{"episode": 751.0, "episode_reward": 1.5, "eval_time": 10.375158786773682, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 250000}
{"episode": 754.0, "episode_reward": 1.3, "eval_time": 10.147138833999634, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 251000}
{"episode": 757.0, "episode_reward": 1.9, "eval_time": 9.970222473144531, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 252000}
{"episode": 760.0, "episode_reward": 1.4, "eval_time": 10.189149141311646, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 253000}
{"episode": 763.0, "episode_reward": 1.4, "eval_time": 10.280853748321533, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 254000}
{"episode": 766.0, "episode_reward": 0.8, "eval_time": 10.200549125671387, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 255000}
{"episode": 769.0, "episode_reward": 2.9, "eval_time": 10.151265621185303, "mean_episode_reward": 2.9, "best_episode_reward": 5.0, "step": 256000}
{"episode": 772.0, "episode_reward": 1.7, "eval_time": 10.128604173660278, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 257000}
{"episode": 775.0, "episode_reward": 1.0, "eval_time": 10.061633586883545, "mean_episode_reward": 1.0, "best_episode_reward": 4.0, "step": 258000}
{"episode": 778.0, "episode_reward": 2.0, "eval_time": 10.084598302841187, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 259000}
{"episode": 781.0, "episode_reward": 1.8, "eval_time": 10.166036128997803, "mean_episode_reward": 1.8, "best_episode_reward": 3.0, "step": 260000}
{"episode": 784.0, "episode_reward": 1.6, "eval_time": 10.124014854431152, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 261000}
{"episode": 787.0, "episode_reward": 1.5, "eval_time": 10.100489854812622, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 262000}
{"episode": 790.0, "episode_reward": 1.9, "eval_time": 10.196654081344604, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 263000}
{"episode": 793.0, "episode_reward": 1.2, "eval_time": 10.176367998123169, "mean_episode_reward": 1.2, "best_episode_reward": 4.0, "step": 264000}
{"episode": 796.0, "episode_reward": 1.0, "eval_time": 10.265463829040527, "mean_episode_reward": 1.0, "best_episode_reward": 4.0, "step": 265000}
{"episode": 799.0, "episode_reward": 1.0, "eval_time": 10.170965433120728, "mean_episode_reward": 1.0, "best_episode_reward": 5.0, "step": 266000}
{"episode": 802.0, "episode_reward": 0.8, "eval_time": 10.445170164108276, "mean_episode_reward": 0.8, "best_episode_reward": 4.0, "step": 267000}
{"episode": 805.0, "episode_reward": 1.9, "eval_time": 10.057347059249878, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 268000}
{"episode": 808.0, "episode_reward": 1.4, "eval_time": 10.040764808654785, "mean_episode_reward": 1.4, "best_episode_reward": 2.0, "step": 269000}
{"episode": 811.0, "episode_reward": 2.9, "eval_time": 10.187260150909424, "mean_episode_reward": 2.9, "best_episode_reward": 5.0, "step": 270000}
{"episode": 814.0, "episode_reward": 1.7, "eval_time": 10.231514930725098, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 271000}
{"episode": 817.0, "episode_reward": 2.1, "eval_time": 10.17524790763855, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 272000}
{"episode": 820.0, "episode_reward": 2.2, "eval_time": 10.173825025558472, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 273000}
{"episode": 823.0, "episode_reward": 1.4, "eval_time": 10.227747678756714, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 274000}
{"episode": 826.0, "episode_reward": 1.9, "eval_time": 10.193076133728027, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 275000}
{"episode": 829.0, "episode_reward": 1.3, "eval_time": 10.14283299446106, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 276000}
{"episode": 832.0, "episode_reward": 1.5, "eval_time": 10.3431077003479, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 277000}
{"episode": 835.0, "episode_reward": 3.5, "eval_time": 10.145825624465942, "mean_episode_reward": 3.5, "best_episode_reward": 7.0, "step": 278000}
{"episode": 838.0, "episode_reward": 1.7, "eval_time": 10.396184206008911, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 279000}
{"episode": 841.0, "episode_reward": 1.7, "eval_time": 10.127971887588501, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 280000}
{"episode": 844.0, "episode_reward": 2.3, "eval_time": 10.090720653533936, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 281000}
{"episode": 847.0, "episode_reward": 2.6, "eval_time": 10.145264148712158, "mean_episode_reward": 2.6, "best_episode_reward": 7.0, "step": 282000}
{"episode": 850.0, "episode_reward": 2.1, "eval_time": 10.033045291900635, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 283000}
{"episode": 853.0, "episode_reward": 1.3, "eval_time": 10.276161909103394, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 284000}
{"episode": 856.0, "episode_reward": 1.4, "eval_time": 10.180489301681519, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 285000}
{"episode": 859.0, "episode_reward": 1.7, "eval_time": 10.186576128005981, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 286000}
{"episode": 862.0, "episode_reward": 1.5, "eval_time": 10.17229962348938, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 287000}
{"episode": 865.0, "episode_reward": 1.7, "eval_time": 10.107478618621826, "mean_episode_reward": 1.7, "best_episode_reward": 5.0, "step": 288000}
{"episode": 868.0, "episode_reward": 2.4, "eval_time": 10.043165683746338, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 289000}
{"episode": 871.0, "episode_reward": 1.7, "eval_time": 10.051818370819092, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 290000}
{"episode": 874.0, "episode_reward": 2.4, "eval_time": 10.20169186592102, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 291000}
{"episode": 877.0, "episode_reward": 1.8, "eval_time": 10.086220026016235, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 292000}
{"episode": 880.0, "episode_reward": 1.8, "eval_time": 10.234103679656982, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 293000}
{"episode": 883.0, "episode_reward": 2.3, "eval_time": 10.173797607421875, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 294000}
{"episode": 886.0, "episode_reward": 1.7, "eval_time": 10.084665536880493, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 295000}
{"episode": 889.0, "episode_reward": 2.3, "eval_time": 10.05581283569336, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 296000}
{"episode": 892.0, "episode_reward": 2.4, "eval_time": 10.050787448883057, "mean_episode_reward": 2.4, "best_episode_reward": 6.0, "step": 297000}
{"episode": 895.0, "episode_reward": 3.4, "eval_time": 10.096721410751343, "mean_episode_reward": 3.4, "best_episode_reward": 6.0, "step": 298000}
{"episode": 898.0, "episode_reward": 1.7, "eval_time": 10.185532331466675, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 299000}
{"episode": 901.0, "episode_reward": 2.9, "eval_time": 10.083898782730103, "mean_episode_reward": 2.9, "best_episode_reward": 6.0, "step": 300000}
{"episode": 904.0, "episode_reward": 1.9, "eval_time": 10.254929542541504, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 301000}
{"episode": 907.0, "episode_reward": 1.9, "eval_time": 10.220786333084106, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 302000}
{"episode": 910.0, "episode_reward": 1.1, "eval_time": 10.212851762771606, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 303000}
{"episode": 913.0, "episode_reward": 2.8, "eval_time": 10.076764345169067, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 304000}
{"episode": 916.0, "episode_reward": 1.3, "eval_time": 10.057238101959229, "mean_episode_reward": 1.3, "best_episode_reward": 2.0, "step": 305000}
{"episode": 919.0, "episode_reward": 2.9, "eval_time": 10.073572874069214, "mean_episode_reward": 2.9, "best_episode_reward": 7.0, "step": 306000}
{"episode": 922.0, "episode_reward": 2.8, "eval_time": 10.000829935073853, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 307000}
{"episode": 925.0, "episode_reward": 2.3, "eval_time": 9.997902154922485, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 308000}
{"episode": 928.0, "episode_reward": 1.8, "eval_time": 10.05376124382019, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 309000}
{"episode": 931.0, "episode_reward": 3.2, "eval_time": 10.135844230651855, "mean_episode_reward": 3.2, "best_episode_reward": 7.0, "step": 310000}
{"episode": 934.0, "episode_reward": 1.8, "eval_time": 10.219398736953735, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 311000}
{"episode": 937.0, "episode_reward": 1.3, "eval_time": 10.205398082733154, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 312000}
{"episode": 940.0, "episode_reward": 3.3, "eval_time": 10.02499771118164, "mean_episode_reward": 3.3, "best_episode_reward": 7.0, "step": 313000}
{"episode": 943.0, "episode_reward": 1.9, "eval_time": 9.987468004226685, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 314000}
{"episode": 946.0, "episode_reward": 1.1, "eval_time": 10.028902530670166, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 315000}
{"episode": 949.0, "episode_reward": 1.9, "eval_time": 9.970328092575073, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 316000}
{"episode": 952.0, "episode_reward": 3.9, "eval_time": 9.973020792007446, "mean_episode_reward": 3.9, "best_episode_reward": 6.0, "step": 317000}
{"episode": 955.0, "episode_reward": 3.3, "eval_time": 9.967024803161621, "mean_episode_reward": 3.3, "best_episode_reward": 5.0, "step": 318000}
{"episode": 958.0, "episode_reward": 1.9, "eval_time": 10.026437282562256, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 319000}
{"episode": 961.0, "episode_reward": 1.7, "eval_time": 10.026535272598267, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 320000}
{"episode": 964.0, "episode_reward": 4.0, "eval_time": 9.816687107086182, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 321000}
{"episode": 967.0, "episode_reward": 3.4, "eval_time": 10.019945621490479, "mean_episode_reward": 3.4, "best_episode_reward": 6.0, "step": 322000}
{"episode": 970.0, "episode_reward": 3.1, "eval_time": 9.97835636138916, "mean_episode_reward": 3.1, "best_episode_reward": 5.0, "step": 323000}
{"episode": 973.0, "episode_reward": 0.5, "eval_time": 10.19151759147644, "mean_episode_reward": 0.5, "best_episode_reward": 3.0, "step": 324000}
{"episode": 976.0, "episode_reward": 3.5, "eval_time": 9.908422231674194, "mean_episode_reward": 3.5, "best_episode_reward": 6.0, "step": 325000}
{"episode": 979.0, "episode_reward": 3.0, "eval_time": 10.104609727859497, "mean_episode_reward": 3.0, "best_episode_reward": 5.0, "step": 326000}
{"episode": 982.0, "episode_reward": 2.3, "eval_time": 9.820631265640259, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 327000}
{"episode": 985.0, "episode_reward": 2.8, "eval_time": 9.954555988311768, "mean_episode_reward": 2.8, "best_episode_reward": 6.0, "step": 328000}
{"episode": 988.0, "episode_reward": 1.7, "eval_time": 10.09235143661499, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 329000}
{"episode": 991.0, "episode_reward": 2.5, "eval_time": 10.070716619491577, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 330000}
{"episode": 994.0, "episode_reward": 3.7, "eval_time": 9.964781999588013, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 331000}
{"episode": 997.0, "episode_reward": 4.5, "eval_time": 9.86881160736084, "mean_episode_reward": 4.5, "best_episode_reward": 6.0, "step": 332000}
{"episode": 1000.0, "episode_reward": 1.8, "eval_time": 10.132631301879883, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 333000}
{"episode": 1003.0, "episode_reward": 2.8, "eval_time": 10.114141941070557, "mean_episode_reward": 2.8, "best_episode_reward": 7.0, "step": 334000}
{"episode": 1006.0, "episode_reward": 2.7, "eval_time": 10.156804323196411, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 335000}
{"episode": 1009.0, "episode_reward": 3.5, "eval_time": 9.988187789916992, "mean_episode_reward": 3.5, "best_episode_reward": 7.0, "step": 336000}
{"episode": 1012.0, "episode_reward": 2.3, "eval_time": 9.738296270370483, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 337000}
{"episode": 1015.0, "episode_reward": 2.4, "eval_time": 10.128171443939209, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 338000}
{"episode": 1018.0, "episode_reward": 3.1, "eval_time": 9.959288120269775, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 339000}
{"episode": 1021.0, "episode_reward": 2.5, "eval_time": 10.086270809173584, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 340000}
{"episode": 1024.0, "episode_reward": 2.4, "eval_time": 9.913890600204468, "mean_episode_reward": 2.4, "best_episode_reward": 6.0, "step": 341000}
{"episode": 1027.0, "episode_reward": 5.1, "eval_time": 9.941802978515625, "mean_episode_reward": 5.1, "best_episode_reward": 8.0, "step": 342000}
{"episode": 1030.0, "episode_reward": 2.2, "eval_time": 10.061140298843384, "mean_episode_reward": 2.2, "best_episode_reward": 7.0, "step": 343000}
{"episode": 1033.0, "episode_reward": 2.3, "eval_time": 10.063295125961304, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 344000}
{"episode": 1036.0, "episode_reward": 2.5, "eval_time": 9.94782567024231, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 345000}
{"episode": 1039.0, "episode_reward": 3.6, "eval_time": 9.87532091140747, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 346000}
{"episode": 1042.0, "episode_reward": 1.4, "eval_time": 10.21557331085205, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 347000}
{"episode": 1045.0, "episode_reward": 2.8, "eval_time": 10.06760025024414, "mean_episode_reward": 2.8, "best_episode_reward": 7.0, "step": 348000}
{"episode": 1048.0, "episode_reward": 2.5, "eval_time": 10.108946323394775, "mean_episode_reward": 2.5, "best_episode_reward": 6.0, "step": 349000}
{"episode": 1051.0, "episode_reward": 3.4, "eval_time": 10.050366401672363, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 350000}
{"episode": 1054.0, "episode_reward": 2.9, "eval_time": 10.048535346984863, "mean_episode_reward": 2.9, "best_episode_reward": 8.0, "step": 351000}
{"episode": 1057.0, "episode_reward": 2.8, "eval_time": 9.852843999862671, "mean_episode_reward": 2.8, "best_episode_reward": 6.0, "step": 352000}
{"episode": 1060.0, "episode_reward": 4.2, "eval_time": 10.157275438308716, "mean_episode_reward": 4.2, "best_episode_reward": 6.0, "step": 353000}
{"episode": 1063.0, "episode_reward": 3.4, "eval_time": 9.898135423660278, "mean_episode_reward": 3.4, "best_episode_reward": 6.0, "step": 354000}
{"episode": 1066.0, "episode_reward": 2.6, "eval_time": 9.945180416107178, "mean_episode_reward": 2.6, "best_episode_reward": 7.0, "step": 355000}
{"episode": 1069.0, "episode_reward": 4.8, "eval_time": 9.965669631958008, "mean_episode_reward": 4.8, "best_episode_reward": 8.0, "step": 356000}
{"episode": 1072.0, "episode_reward": 4.2, "eval_time": 9.956613063812256, "mean_episode_reward": 4.2, "best_episode_reward": 8.0, "step": 357000}
{"episode": 1075.0, "episode_reward": 3.3, "eval_time": 10.055814981460571, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 358000}
{"episode": 1078.0, "episode_reward": 3.8, "eval_time": 10.07882285118103, "mean_episode_reward": 3.8, "best_episode_reward": 6.0, "step": 359000}
{"episode": 1081.0, "episode_reward": 4.6, "eval_time": 9.881655216217041, "mean_episode_reward": 4.6, "best_episode_reward": 10.0, "step": 360000}
{"episode": 1084.0, "episode_reward": 4.0, "eval_time": 10.059584379196167, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 361000}
{"episode": 1087.0, "episode_reward": 3.8, "eval_time": 9.987340688705444, "mean_episode_reward": 3.8, "best_episode_reward": 6.0, "step": 362000}
{"episode": 1090.0, "episode_reward": 2.3, "eval_time": 9.98108172416687, "mean_episode_reward": 2.3, "best_episode_reward": 3.0, "step": 363000}
{"episode": 1093.0, "episode_reward": 3.1, "eval_time": 10.091587781906128, "mean_episode_reward": 3.1, "best_episode_reward": 5.0, "step": 364000}
{"episode": 1096.0, "episode_reward": 2.3, "eval_time": 10.255924701690674, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 365000}
{"episode": 1099.0, "episode_reward": 3.8, "eval_time": 10.330916404724121, "mean_episode_reward": 3.8, "best_episode_reward": 6.0, "step": 366000}
{"episode": 1102.0, "episode_reward": 2.7, "eval_time": 9.982573509216309, "mean_episode_reward": 2.7, "best_episode_reward": 6.0, "step": 367000}
{"episode": 1105.0, "episode_reward": 5.2, "eval_time": 10.003790616989136, "mean_episode_reward": 5.2, "best_episode_reward": 9.0, "step": 368000}
{"episode": 1108.0, "episode_reward": 2.3, "eval_time": 10.026882886886597, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 369000}
{"episode": 1111.0, "episode_reward": 4.5, "eval_time": 10.18384313583374, "mean_episode_reward": 4.5, "best_episode_reward": 7.0, "step": 370000}
{"episode": 1114.0, "episode_reward": 4.1, "eval_time": 10.139349460601807, "mean_episode_reward": 4.1, "best_episode_reward": 6.0, "step": 371000}
{"episode": 1117.0, "episode_reward": 4.6, "eval_time": 9.923287868499756, "mean_episode_reward": 4.6, "best_episode_reward": 8.0, "step": 372000}
{"episode": 1120.0, "episode_reward": 2.2, "eval_time": 9.95543909072876, "mean_episode_reward": 2.2, "best_episode_reward": 5.0, "step": 373000}
{"episode": 1123.0, "episode_reward": 3.2, "eval_time": 9.919986963272095, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 374000}
{"episode": 1126.0, "episode_reward": 4.8, "eval_time": 9.781988620758057, "mean_episode_reward": 4.8, "best_episode_reward": 6.0, "step": 375000}
{"episode": 1129.0, "episode_reward": 5.3, "eval_time": 9.882293701171875, "mean_episode_reward": 5.3, "best_episode_reward": 10.0, "step": 376000}
{"episode": 1132.0, "episode_reward": 4.6, "eval_time": 9.729837417602539, "mean_episode_reward": 4.6, "best_episode_reward": 8.0, "step": 377000}
{"episode": 1135.0, "episode_reward": 4.6, "eval_time": 10.119795083999634, "mean_episode_reward": 4.6, "best_episode_reward": 7.0, "step": 378000}
{"episode": 1138.0, "episode_reward": 3.3, "eval_time": 9.820322513580322, "mean_episode_reward": 3.3, "best_episode_reward": 5.0, "step": 379000}
{"episode": 1141.0, "episode_reward": 4.3, "eval_time": 9.940166234970093, "mean_episode_reward": 4.3, "best_episode_reward": 7.0, "step": 380000}
{"episode": 1144.0, "episode_reward": 5.0, "eval_time": 9.829448938369751, "mean_episode_reward": 5.0, "best_episode_reward": 8.0, "step": 381000}
{"episode": 1147.0, "episode_reward": 4.7, "eval_time": 10.042562246322632, "mean_episode_reward": 4.7, "best_episode_reward": 8.0, "step": 382000}
{"episode": 1150.0, "episode_reward": 3.1, "eval_time": 9.96513557434082, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 383000}
{"episode": 1153.0, "episode_reward": 2.5, "eval_time": 10.208596467971802, "mean_episode_reward": 2.5, "best_episode_reward": 4.0, "step": 384000}
{"episode": 1156.0, "episode_reward": 4.5, "eval_time": 9.874852418899536, "mean_episode_reward": 4.5, "best_episode_reward": 7.0, "step": 385000}
{"episode": 1159.0, "episode_reward": 2.3, "eval_time": 9.91865086555481, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 386000}
{"episode": 1162.0, "episode_reward": 3.8, "eval_time": 9.910758256912231, "mean_episode_reward": 3.8, "best_episode_reward": 7.0, "step": 387000}
{"episode": 1165.0, "episode_reward": 5.4, "eval_time": 9.672019004821777, "mean_episode_reward": 5.4, "best_episode_reward": 9.0, "step": 388000}
{"episode": 1168.0, "episode_reward": 4.0, "eval_time": 9.640462160110474, "mean_episode_reward": 4.0, "best_episode_reward": 7.0, "step": 389000}
{"episode": 1171.0, "episode_reward": 4.4, "eval_time": 10.10197138786316, "mean_episode_reward": 4.4, "best_episode_reward": 7.0, "step": 390000}
{"episode": 1174.0, "episode_reward": 4.0, "eval_time": 9.909551620483398, "mean_episode_reward": 4.0, "best_episode_reward": 7.0, "step": 391000}
{"episode": 1177.0, "episode_reward": 3.8, "eval_time": 9.943581104278564, "mean_episode_reward": 3.8, "best_episode_reward": 8.0, "step": 392000}
{"episode": 1180.0, "episode_reward": 4.2, "eval_time": 10.08254098892212, "mean_episode_reward": 4.2, "best_episode_reward": 7.0, "step": 393000}
{"episode": 1183.0, "episode_reward": 3.7, "eval_time": 9.832914590835571, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 394000}
{"episode": 1186.0, "episode_reward": 3.7, "eval_time": 9.872918605804443, "mean_episode_reward": 3.7, "best_episode_reward": 5.0, "step": 395000}
{"episode": 1189.0, "episode_reward": 3.7, "eval_time": 9.756389856338501, "mean_episode_reward": 3.7, "best_episode_reward": 8.0, "step": 396000}
{"episode": 1192.0, "episode_reward": 4.8, "eval_time": 10.10885214805603, "mean_episode_reward": 4.8, "best_episode_reward": 10.0, "step": 397000}
{"episode": 1195.0, "episode_reward": 5.3, "eval_time": 9.863204717636108, "mean_episode_reward": 5.3, "best_episode_reward": 8.0, "step": 398000}
{"episode": 1198.0, "episode_reward": 4.0, "eval_time": 10.034020185470581, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 399000}
{"episode": 1201.0, "episode_reward": 4.8, "eval_time": 9.906896591186523, "mean_episode_reward": 4.8, "best_episode_reward": 8.0, "step": 400000}
{"episode": 1204.0, "episode_reward": 4.0, "eval_time": 9.912437438964844, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 401000}
{"episode": 1207.0, "episode_reward": 4.3, "eval_time": 9.935109615325928, "mean_episode_reward": 4.3, "best_episode_reward": 6.0, "step": 402000}
{"episode": 1210.0, "episode_reward": 4.6, "eval_time": 10.013279676437378, "mean_episode_reward": 4.6, "best_episode_reward": 7.0, "step": 403000}
{"episode": 1213.0, "episode_reward": 5.5, "eval_time": 9.680652856826782, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 404000}
{"episode": 1216.0, "episode_reward": 3.7, "eval_time": 9.83818244934082, "mean_episode_reward": 3.7, "best_episode_reward": 8.0, "step": 405000}
{"episode": 1219.0, "episode_reward": 5.9, "eval_time": 9.859365940093994, "mean_episode_reward": 5.9, "best_episode_reward": 11.0, "step": 406000}
{"episode": 1222.0, "episode_reward": 6.4, "eval_time": 9.80603575706482, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 407000}
{"episode": 1225.0, "episode_reward": 4.9, "eval_time": 9.857838153839111, "mean_episode_reward": 4.9, "best_episode_reward": 10.0, "step": 408000}
{"episode": 1228.0, "episode_reward": 7.5, "eval_time": 9.765464305877686, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 409000}
{"episode": 1231.0, "episode_reward": 6.1, "eval_time": 9.708522319793701, "mean_episode_reward": 6.1, "best_episode_reward": 10.0, "step": 410000}
{"episode": 1234.0, "episode_reward": 6.0, "eval_time": 9.809950590133667, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 411000}
{"episode": 1237.0, "episode_reward": 5.2, "eval_time": 9.924389362335205, "mean_episode_reward": 5.2, "best_episode_reward": 9.0, "step": 412000}
{"episode": 1240.0, "episode_reward": 7.0, "eval_time": 9.788788795471191, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 413000}
{"episode": 1243.0, "episode_reward": 6.0, "eval_time": 9.801408052444458, "mean_episode_reward": 6.0, "best_episode_reward": 10.0, "step": 414000}
{"episode": 1246.0, "episode_reward": 6.4, "eval_time": 9.945010662078857, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 415000}
{"episode": 1249.0, "episode_reward": 4.7, "eval_time": 9.87665843963623, "mean_episode_reward": 4.7, "best_episode_reward": 7.0, "step": 416000}
{"episode": 1252.0, "episode_reward": 3.5, "eval_time": 9.793940782546997, "mean_episode_reward": 3.5, "best_episode_reward": 10.0, "step": 417000}
{"episode": 1255.0, "episode_reward": 6.4, "eval_time": 9.653691053390503, "mean_episode_reward": 6.4, "best_episode_reward": 12.0, "step": 418000}
{"episode": 1258.0, "episode_reward": 6.5, "eval_time": 9.567731618881226, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 419000}
{"episode": 1261.0, "episode_reward": 6.1, "eval_time": 9.697578430175781, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 420000}
{"episode": 1264.0, "episode_reward": 6.3, "eval_time": 9.804092645645142, "mean_episode_reward": 6.3, "best_episode_reward": 9.0, "step": 421000}
{"episode": 1267.0, "episode_reward": 6.8, "eval_time": 9.757280349731445, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 422000}
{"episode": 1270.0, "episode_reward": 6.0, "eval_time": 9.98073935508728, "mean_episode_reward": 6.0, "best_episode_reward": 11.0, "step": 423000}
{"episode": 1273.0, "episode_reward": 5.4, "eval_time": 9.814108848571777, "mean_episode_reward": 5.4, "best_episode_reward": 8.0, "step": 424000}
{"episode": 1276.0, "episode_reward": 5.1, "eval_time": 9.807614088058472, "mean_episode_reward": 5.1, "best_episode_reward": 10.0, "step": 425000}
{"episode": 1279.0, "episode_reward": 7.0, "eval_time": 9.573058366775513, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 426000}
{"episode": 1282.0, "episode_reward": 6.1, "eval_time": 9.730542659759521, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 427000}
{"episode": 1285.0, "episode_reward": 4.8, "eval_time": 9.71903133392334, "mean_episode_reward": 4.8, "best_episode_reward": 8.0, "step": 428000}
{"episode": 1288.0, "episode_reward": 6.5, "eval_time": 9.787041902542114, "mean_episode_reward": 6.5, "best_episode_reward": 10.0, "step": 429000}
{"episode": 1291.0, "episode_reward": 5.6, "eval_time": 9.785768270492554, "mean_episode_reward": 5.6, "best_episode_reward": 10.0, "step": 430000}
{"episode": 1294.0, "episode_reward": 5.4, "eval_time": 9.793567419052124, "mean_episode_reward": 5.4, "best_episode_reward": 10.0, "step": 431000}
{"episode": 1297.0, "episode_reward": 5.5, "eval_time": 9.691001892089844, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 432000}
{"episode": 1300.0, "episode_reward": 5.7, "eval_time": 9.726645708084106, "mean_episode_reward": 5.7, "best_episode_reward": 8.0, "step": 433000}
{"episode": 1303.0, "episode_reward": 5.7, "eval_time": 9.929462432861328, "mean_episode_reward": 5.7, "best_episode_reward": 10.0, "step": 434000}
{"episode": 1306.0, "episode_reward": 6.8, "eval_time": 9.694437742233276, "mean_episode_reward": 6.8, "best_episode_reward": 8.0, "step": 435000}
{"episode": 1309.0, "episode_reward": 6.6, "eval_time": 9.80678391456604, "mean_episode_reward": 6.6, "best_episode_reward": 9.0, "step": 436000}
{"episode": 1312.0, "episode_reward": 6.4, "eval_time": 9.890011548995972, "mean_episode_reward": 6.4, "best_episode_reward": 10.0, "step": 437000}
{"episode": 1315.0, "episode_reward": 6.1, "eval_time": 9.915250539779663, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 438000}
{"episode": 1318.0, "episode_reward": 6.3, "eval_time": 9.73418927192688, "mean_episode_reward": 6.3, "best_episode_reward": 8.0, "step": 439000}
{"episode": 1321.0, "episode_reward": 3.9, "eval_time": 9.89692759513855, "mean_episode_reward": 3.9, "best_episode_reward": 7.0, "step": 440000}
{"episode": 1324.0, "episode_reward": 4.9, "eval_time": 9.958794593811035, "mean_episode_reward": 4.9, "best_episode_reward": 7.0, "step": 441000}
{"episode": 1327.0, "episode_reward": 6.5, "eval_time": 9.786606550216675, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 442000}
{"episode": 1330.0, "episode_reward": 6.5, "eval_time": 9.741724967956543, "mean_episode_reward": 6.5, "best_episode_reward": 10.0, "step": 443000}
{"episode": 1333.0, "episode_reward": 6.2, "eval_time": 9.695886611938477, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 444000}
{"episode": 1336.0, "episode_reward": 5.9, "eval_time": 9.60187029838562, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 445000}
{"episode": 1339.0, "episode_reward": 6.4, "eval_time": 9.69929814338684, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 446000}
{"episode": 1342.0, "episode_reward": 5.6, "eval_time": 9.814992189407349, "mean_episode_reward": 5.6, "best_episode_reward": 8.0, "step": 447000}
{"episode": 1345.0, "episode_reward": 6.1, "eval_time": 9.838864088058472, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 448000}
{"episode": 1348.0, "episode_reward": 7.8, "eval_time": 9.747647285461426, "mean_episode_reward": 7.8, "best_episode_reward": 12.0, "step": 449000}
{"episode": 1351.0, "episode_reward": 6.0, "eval_time": 9.884069681167603, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 450000}
{"episode": 1354.0, "episode_reward": 5.8, "eval_time": 9.716900825500488, "mean_episode_reward": 5.8, "best_episode_reward": 10.0, "step": 451000}
{"episode": 1357.0, "episode_reward": 5.8, "eval_time": 9.744926929473877, "mean_episode_reward": 5.8, "best_episode_reward": 9.0, "step": 452000}
{"episode": 1360.0, "episode_reward": 7.5, "eval_time": 9.663140773773193, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 453000}
{"episode": 1363.0, "episode_reward": 6.8, "eval_time": 9.670911312103271, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 454000}
{"episode": 1366.0, "episode_reward": 9.3, "eval_time": 9.615705490112305, "mean_episode_reward": 9.3, "best_episode_reward": 11.0, "step": 455000}
{"episode": 1369.0, "episode_reward": 6.4, "eval_time": 9.776615381240845, "mean_episode_reward": 6.4, "best_episode_reward": 10.0, "step": 456000}
{"episode": 1372.0, "episode_reward": 6.4, "eval_time": 9.557251691818237, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 457000}
{"episode": 1375.0, "episode_reward": 5.0, "eval_time": 9.644845485687256, "mean_episode_reward": 5.0, "best_episode_reward": 7.0, "step": 458000}
{"episode": 1378.0, "episode_reward": 8.1, "eval_time": 9.571547031402588, "mean_episode_reward": 8.1, "best_episode_reward": 13.0, "step": 459000}
{"episode": 1381.0, "episode_reward": 7.9, "eval_time": 9.555211544036865, "mean_episode_reward": 7.9, "best_episode_reward": 11.0, "step": 460000}
{"episode": 1384.0, "episode_reward": 6.0, "eval_time": 9.747055292129517, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 461000}
{"episode": 1387.0, "episode_reward": 6.6, "eval_time": 9.737125158309937, "mean_episode_reward": 6.6, "best_episode_reward": 10.0, "step": 462000}
{"episode": 1390.0, "episode_reward": 7.4, "eval_time": 9.63218092918396, "mean_episode_reward": 7.4, "best_episode_reward": 10.0, "step": 463000}
{"episode": 1393.0, "episode_reward": 4.7, "eval_time": 9.441300392150879, "mean_episode_reward": 4.7, "best_episode_reward": 6.0, "step": 464000}
{"episode": 1396.0, "episode_reward": 7.0, "eval_time": 9.635150909423828, "mean_episode_reward": 7.0, "best_episode_reward": 12.0, "step": 465000}
{"episode": 1399.0, "episode_reward": 7.9, "eval_time": 9.514817237854004, "mean_episode_reward": 7.9, "best_episode_reward": 13.0, "step": 466000}
{"episode": 1402.0, "episode_reward": 5.8, "eval_time": 9.50386381149292, "mean_episode_reward": 5.8, "best_episode_reward": 8.0, "step": 467000}
{"episode": 1405.0, "episode_reward": 7.5, "eval_time": 9.6142098903656, "mean_episode_reward": 7.5, "best_episode_reward": 12.0, "step": 468000}
{"episode": 1408.0, "episode_reward": 8.6, "eval_time": 9.691444396972656, "mean_episode_reward": 8.6, "best_episode_reward": 14.0, "step": 469000}
{"episode": 1411.0, "episode_reward": 3.7, "eval_time": 9.884531259536743, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 470000}
{"episode": 1414.0, "episode_reward": 7.6, "eval_time": 9.729270219802856, "mean_episode_reward": 7.6, "best_episode_reward": 10.0, "step": 471000}
{"episode": 1417.0, "episode_reward": 5.3, "eval_time": 9.778434753417969, "mean_episode_reward": 5.3, "best_episode_reward": 8.0, "step": 472000}
{"episode": 1420.0, "episode_reward": 6.8, "eval_time": 9.525443315505981, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 473000}
{"episode": 1423.0, "episode_reward": 7.3, "eval_time": 9.669135808944702, "mean_episode_reward": 7.3, "best_episode_reward": 14.0, "step": 474000}
{"episode": 1426.0, "episode_reward": 5.3, "eval_time": 9.716209173202515, "mean_episode_reward": 5.3, "best_episode_reward": 8.0, "step": 475000}
{"episode": 1429.0, "episode_reward": 6.1, "eval_time": 9.709238290786743, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 476000}
{"episode": 1432.0, "episode_reward": 7.2, "eval_time": 9.627275705337524, "mean_episode_reward": 7.2, "best_episode_reward": 10.0, "step": 477000}
{"episode": 1435.0, "episode_reward": 6.1, "eval_time": 9.52678918838501, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 478000}
{"episode": 1438.0, "episode_reward": 6.1, "eval_time": 9.741456747055054, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 479000}
{"episode": 1441.0, "episode_reward": 7.1, "eval_time": 9.622275590896606, "mean_episode_reward": 7.1, "best_episode_reward": 10.0, "step": 480000}
{"episode": 1444.0, "episode_reward": 7.5, "eval_time": 9.5641188621521, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 481000}
{"episode": 1447.0, "episode_reward": 7.2, "eval_time": 9.710114240646362, "mean_episode_reward": 7.2, "best_episode_reward": 10.0, "step": 482000}
{"episode": 1450.0, "episode_reward": 7.3, "eval_time": 9.792068481445312, "mean_episode_reward": 7.3, "best_episode_reward": 12.0, "step": 483000}
{"episode": 1453.0, "episode_reward": 6.4, "eval_time": 9.766864538192749, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 484000}
{"episode": 1456.0, "episode_reward": 5.5, "eval_time": 9.698407173156738, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 485000}
{"episode": 1459.0, "episode_reward": 5.7, "eval_time": 9.809603214263916, "mean_episode_reward": 5.7, "best_episode_reward": 7.0, "step": 486000}
{"episode": 1462.0, "episode_reward": 5.0, "eval_time": 9.77901291847229, "mean_episode_reward": 5.0, "best_episode_reward": 8.0, "step": 487000}
{"episode": 1465.0, "episode_reward": 4.3, "eval_time": 9.90918493270874, "mean_episode_reward": 4.3, "best_episode_reward": 7.0, "step": 488000}
{"episode": 1468.0, "episode_reward": 5.4, "eval_time": 9.83780574798584, "mean_episode_reward": 5.4, "best_episode_reward": 10.0, "step": 489000}
{"episode": 1471.0, "episode_reward": 7.1, "eval_time": 9.618156909942627, "mean_episode_reward": 7.1, "best_episode_reward": 10.0, "step": 490000}
{"episode": 1474.0, "episode_reward": 7.7, "eval_time": 9.650712251663208, "mean_episode_reward": 7.7, "best_episode_reward": 10.0, "step": 491000}
{"episode": 1477.0, "episode_reward": 7.1, "eval_time": 9.705805778503418, "mean_episode_reward": 7.1, "best_episode_reward": 8.0, "step": 492000}
{"episode": 1480.0, "episode_reward": 7.8, "eval_time": 9.65493631362915, "mean_episode_reward": 7.8, "best_episode_reward": 12.0, "step": 493000}
{"episode": 1483.0, "episode_reward": 5.9, "eval_time": 9.780367851257324, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 494000}
{"episode": 1486.0, "episode_reward": 6.9, "eval_time": 9.676782846450806, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 495000}
{"episode": 1489.0, "episode_reward": 5.2, "eval_time": 9.636257648468018, "mean_episode_reward": 5.2, "best_episode_reward": 9.0, "step": 496000}
{"episode": 1492.0, "episode_reward": 7.1, "eval_time": 9.680151224136353, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 497000}
{"episode": 1495.0, "episode_reward": 7.2, "eval_time": 9.689329147338867, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 498000}
{"episode": 1498.0, "episode_reward": 1.5, "eval_time": 9.864999055862427, "mean_episode_reward": 1.5, "best_episode_reward": 5.0, "step": 499000}
{"episode": 1501.0, "episode_reward": 7.2, "eval_time": 9.610625267028809, "mean_episode_reward": 7.2, "best_episode_reward": 10.0, "step": 500000}
{"episode": 1504.0, "episode_reward": 5.0, "eval_time": 9.539018392562866, "mean_episode_reward": 5.0, "best_episode_reward": 10.0, "step": 501000}
{"episode": 1507.0, "episode_reward": 8.2, "eval_time": 9.732628583908081, "mean_episode_reward": 8.2, "best_episode_reward": 14.0, "step": 502000}
{"episode": 1510.0, "episode_reward": 8.2, "eval_time": 9.598442077636719, "mean_episode_reward": 8.2, "best_episode_reward": 12.0, "step": 503000}
{"episode": 1513.0, "episode_reward": 5.1, "eval_time": 9.67966365814209, "mean_episode_reward": 5.1, "best_episode_reward": 7.0, "step": 504000}
{"episode": 1516.0, "episode_reward": 6.4, "eval_time": 9.58061408996582, "mean_episode_reward": 6.4, "best_episode_reward": 10.0, "step": 505000}
{"episode": 1519.0, "episode_reward": 7.3, "eval_time": 9.573124170303345, "mean_episode_reward": 7.3, "best_episode_reward": 10.0, "step": 506000}
{"episode": 1522.0, "episode_reward": 6.1, "eval_time": 9.650878190994263, "mean_episode_reward": 6.1, "best_episode_reward": 10.0, "step": 507000}
{"episode": 1525.0, "episode_reward": 8.0, "eval_time": 9.556028127670288, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 508000}
{"episode": 1528.0, "episode_reward": 6.5, "eval_time": 9.605607509613037, "mean_episode_reward": 6.5, "best_episode_reward": 11.0, "step": 509000}
{"episode": 1531.0, "episode_reward": 6.6, "eval_time": 9.734168529510498, "mean_episode_reward": 6.6, "best_episode_reward": 11.0, "step": 510000}
{"episode": 1534.0, "episode_reward": 6.3, "eval_time": 9.63625454902649, "mean_episode_reward": 6.3, "best_episode_reward": 10.0, "step": 511000}
{"episode": 1537.0, "episode_reward": 6.3, "eval_time": 9.693284749984741, "mean_episode_reward": 6.3, "best_episode_reward": 10.0, "step": 512000}
{"episode": 1540.0, "episode_reward": 6.5, "eval_time": 9.715881109237671, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 513000}
{"episode": 1543.0, "episode_reward": 6.0, "eval_time": 9.601174116134644, "mean_episode_reward": 6.0, "best_episode_reward": 8.0, "step": 514000}
{"episode": 1546.0, "episode_reward": 7.7, "eval_time": 9.76840853691101, "mean_episode_reward": 7.7, "best_episode_reward": 13.0, "step": 515000}
{"episode": 1549.0, "episode_reward": 6.1, "eval_time": 9.481064558029175, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 516000}
{"episode": 1552.0, "episode_reward": 3.7, "eval_time": 9.643648386001587, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 517000}
{"episode": 1555.0, "episode_reward": 5.4, "eval_time": 9.711762428283691, "mean_episode_reward": 5.4, "best_episode_reward": 8.0, "step": 518000}
{"episode": 1558.0, "episode_reward": 6.4, "eval_time": 9.801883220672607, "mean_episode_reward": 6.4, "best_episode_reward": 8.0, "step": 519000}
{"episode": 1561.0, "episode_reward": 7.0, "eval_time": 9.655842542648315, "mean_episode_reward": 7.0, "best_episode_reward": 10.0, "step": 520000}
{"episode": 1564.0, "episode_reward": 4.0, "eval_time": 9.753845930099487, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 521000}
{"episode": 1567.0, "episode_reward": 7.1, "eval_time": 9.689533233642578, "mean_episode_reward": 7.1, "best_episode_reward": 11.0, "step": 522000}
{"episode": 1570.0, "episode_reward": 5.5, "eval_time": 9.560784816741943, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 523000}
{"episode": 1573.0, "episode_reward": 6.1, "eval_time": 9.710888385772705, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 524000}
{"episode": 1576.0, "episode_reward": 6.9, "eval_time": 9.888673067092896, "mean_episode_reward": 6.9, "best_episode_reward": 11.0, "step": 525000}
{"episode": 1579.0, "episode_reward": 6.5, "eval_time": 9.57688570022583, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 526000}
{"episode": 1582.0, "episode_reward": 5.3, "eval_time": 9.749770164489746, "mean_episode_reward": 5.3, "best_episode_reward": 7.0, "step": 527000}
{"episode": 1585.0, "episode_reward": 6.9, "eval_time": 9.651955366134644, "mean_episode_reward": 6.9, "best_episode_reward": 13.0, "step": 528000}
{"episode": 1588.0, "episode_reward": 6.4, "eval_time": 9.666070699691772, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 529000}
{"episode": 1591.0, "episode_reward": 5.9, "eval_time": 9.651277303695679, "mean_episode_reward": 5.9, "best_episode_reward": 10.0, "step": 530000}
{"episode": 1594.0, "episode_reward": 8.0, "eval_time": 9.601678133010864, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 531000}
{"episode": 1597.0, "episode_reward": 7.0, "eval_time": 9.634596109390259, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 532000}
{"episode": 1600.0, "episode_reward": 5.9, "eval_time": 9.456638097763062, "mean_episode_reward": 5.9, "best_episode_reward": 8.0, "step": 533000}
{"episode": 1603.0, "episode_reward": 3.7, "eval_time": 9.912016153335571, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 534000}
{"episode": 1606.0, "episode_reward": 6.3, "eval_time": 9.432459354400635, "mean_episode_reward": 6.3, "best_episode_reward": 8.0, "step": 535000}
{"episode": 1609.0, "episode_reward": 6.5, "eval_time": 9.59959101676941, "mean_episode_reward": 6.5, "best_episode_reward": 11.0, "step": 536000}
{"episode": 1612.0, "episode_reward": 7.3, "eval_time": 9.631389617919922, "mean_episode_reward": 7.3, "best_episode_reward": 13.0, "step": 537000}
{"episode": 1615.0, "episode_reward": 7.0, "eval_time": 9.582999467849731, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 538000}
{"episode": 1618.0, "episode_reward": 7.6, "eval_time": 9.599874496459961, "mean_episode_reward": 7.6, "best_episode_reward": 10.0, "step": 539000}
{"episode": 1621.0, "episode_reward": 5.5, "eval_time": 9.637714147567749, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 540000}
{"episode": 1624.0, "episode_reward": 6.7, "eval_time": 9.678707122802734, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 541000}
{"episode": 1627.0, "episode_reward": 7.1, "eval_time": 9.636795997619629, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 542000}
{"episode": 1630.0, "episode_reward": 6.0, "eval_time": 9.469900846481323, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 543000}
{"episode": 1633.0, "episode_reward": 6.2, "eval_time": 9.753634452819824, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 544000}
{"episode": 1636.0, "episode_reward": 7.3, "eval_time": 9.734894752502441, "mean_episode_reward": 7.3, "best_episode_reward": 10.0, "step": 545000}
{"episode": 1639.0, "episode_reward": 4.1, "eval_time": 9.677949905395508, "mean_episode_reward": 4.1, "best_episode_reward": 6.0, "step": 546000}
{"episode": 1642.0, "episode_reward": 6.1, "eval_time": 9.705916404724121, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 547000}
{"episode": 1645.0, "episode_reward": 5.5, "eval_time": 9.467031717300415, "mean_episode_reward": 5.5, "best_episode_reward": 9.0, "step": 548000}
{"episode": 1648.0, "episode_reward": 6.8, "eval_time": 9.506225824356079, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 549000}
{"episode": 1651.0, "episode_reward": 4.3, "eval_time": 9.499023914337158, "mean_episode_reward": 4.3, "best_episode_reward": 7.0, "step": 550000}
{"episode": 1654.0, "episode_reward": 3.6, "eval_time": 9.897816181182861, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 551000}
{"episode": 1657.0, "episode_reward": 5.8, "eval_time": 9.78655743598938, "mean_episode_reward": 5.8, "best_episode_reward": 8.0, "step": 552000}
{"episode": 1660.0, "episode_reward": 5.6, "eval_time": 9.46125340461731, "mean_episode_reward": 5.6, "best_episode_reward": 8.0, "step": 553000}
{"episode": 1663.0, "episode_reward": 5.4, "eval_time": 9.636254787445068, "mean_episode_reward": 5.4, "best_episode_reward": 7.0, "step": 554000}
{"episode": 1666.0, "episode_reward": 5.1, "eval_time": 9.545411825180054, "mean_episode_reward": 5.1, "best_episode_reward": 9.0, "step": 555000}
{"episode": 1669.0, "episode_reward": 6.2, "eval_time": 9.430949926376343, "mean_episode_reward": 6.2, "best_episode_reward": 10.0, "step": 556000}
{"episode": 1672.0, "episode_reward": 7.6, "eval_time": 9.664069652557373, "mean_episode_reward": 7.6, "best_episode_reward": 12.0, "step": 557000}
{"episode": 1675.0, "episode_reward": 5.8, "eval_time": 9.523836374282837, "mean_episode_reward": 5.8, "best_episode_reward": 10.0, "step": 558000}
{"episode": 1678.0, "episode_reward": 5.5, "eval_time": 9.693960428237915, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 559000}
{"episode": 1681.0, "episode_reward": 5.9, "eval_time": 9.666597366333008, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 560000}
{"episode": 1684.0, "episode_reward": 6.6, "eval_time": 9.76415205001831, "mean_episode_reward": 6.6, "best_episode_reward": 8.0, "step": 561000}
{"episode": 1687.0, "episode_reward": 8.0, "eval_time": 9.78591275215149, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 562000}
{"episode": 1690.0, "episode_reward": 7.3, "eval_time": 9.579559326171875, "mean_episode_reward": 7.3, "best_episode_reward": 9.0, "step": 563000}
{"episode": 1693.0, "episode_reward": 6.9, "eval_time": 9.65462875366211, "mean_episode_reward": 6.9, "best_episode_reward": 8.0, "step": 564000}
{"episode": 1696.0, "episode_reward": 6.2, "eval_time": 9.750597953796387, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 565000}
{"episode": 1699.0, "episode_reward": 7.7, "eval_time": 9.669270038604736, "mean_episode_reward": 7.7, "best_episode_reward": 12.0, "step": 566000}
{"episode": 1702.0, "episode_reward": 7.2, "eval_time": 9.691296100616455, "mean_episode_reward": 7.2, "best_episode_reward": 11.0, "step": 567000}
{"episode": 1705.0, "episode_reward": 6.8, "eval_time": 9.634679079055786, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 568000}
{"episode": 1708.0, "episode_reward": 5.9, "eval_time": 9.703864336013794, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 569000}
{"episode": 1711.0, "episode_reward": 6.2, "eval_time": 9.722719669342041, "mean_episode_reward": 6.2, "best_episode_reward": 11.0, "step": 570000}
{"episode": 1714.0, "episode_reward": 5.5, "eval_time": 9.58773684501648, "mean_episode_reward": 5.5, "best_episode_reward": 9.0, "step": 571000}
{"episode": 1717.0, "episode_reward": 6.9, "eval_time": 9.626516580581665, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 572000}
{"episode": 1720.0, "episode_reward": 5.3, "eval_time": 9.614888906478882, "mean_episode_reward": 5.3, "best_episode_reward": 8.0, "step": 573000}
{"episode": 1723.0, "episode_reward": 5.1, "eval_time": 9.533857107162476, "mean_episode_reward": 5.1, "best_episode_reward": 9.0, "step": 574000}
{"episode": 1726.0, "episode_reward": 6.4, "eval_time": 9.579110860824585, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 575000}
{"episode": 1729.0, "episode_reward": 6.0, "eval_time": 9.676440715789795, "mean_episode_reward": 6.0, "best_episode_reward": 8.0, "step": 576000}
{"episode": 1732.0, "episode_reward": 6.8, "eval_time": 9.58138370513916, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 577000}
{"episode": 1735.0, "episode_reward": 7.1, "eval_time": 9.611517906188965, "mean_episode_reward": 7.1, "best_episode_reward": 10.0, "step": 578000}
{"episode": 1738.0, "episode_reward": 7.2, "eval_time": 9.583391427993774, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 579000}
{"episode": 1741.0, "episode_reward": 6.5, "eval_time": 9.555636882781982, "mean_episode_reward": 6.5, "best_episode_reward": 11.0, "step": 580000}
{"episode": 1744.0, "episode_reward": 6.3, "eval_time": 9.693846464157104, "mean_episode_reward": 6.3, "best_episode_reward": 8.0, "step": 581000}
{"episode": 1747.0, "episode_reward": 6.4, "eval_time": 9.737744092941284, "mean_episode_reward": 6.4, "best_episode_reward": 10.0, "step": 582000}
{"episode": 1750.0, "episode_reward": 7.4, "eval_time": 9.630027055740356, "mean_episode_reward": 7.4, "best_episode_reward": 9.0, "step": 583000}
{"episode": 1753.0, "episode_reward": 6.6, "eval_time": 9.733872652053833, "mean_episode_reward": 6.6, "best_episode_reward": 8.0, "step": 584000}
{"episode": 1756.0, "episode_reward": 7.4, "eval_time": 9.744727849960327, "mean_episode_reward": 7.4, "best_episode_reward": 11.0, "step": 585000}
{"episode": 1759.0, "episode_reward": 6.4, "eval_time": 9.649298191070557, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 586000}
{"episode": 1762.0, "episode_reward": 7.0, "eval_time": 9.753840208053589, "mean_episode_reward": 7.0, "best_episode_reward": 10.0, "step": 587000}
{"episode": 1765.0, "episode_reward": 6.9, "eval_time": 9.649818658828735, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 588000}
{"episode": 1768.0, "episode_reward": 7.4, "eval_time": 9.60270619392395, "mean_episode_reward": 7.4, "best_episode_reward": 11.0, "step": 589000}
{"episode": 1771.0, "episode_reward": 7.1, "eval_time": 9.674501895904541, "mean_episode_reward": 7.1, "best_episode_reward": 8.0, "step": 590000}
{"episode": 1774.0, "episode_reward": 7.0, "eval_time": 9.691954135894775, "mean_episode_reward": 7.0, "best_episode_reward": 13.0, "step": 591000}
{"episode": 1777.0, "episode_reward": 5.8, "eval_time": 9.63733720779419, "mean_episode_reward": 5.8, "best_episode_reward": 9.0, "step": 592000}
{"episode": 1780.0, "episode_reward": 6.5, "eval_time": 9.58743405342102, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 593000}
{"episode": 1783.0, "episode_reward": 6.9, "eval_time": 9.790975093841553, "mean_episode_reward": 6.9, "best_episode_reward": 11.0, "step": 594000}
{"episode": 1786.0, "episode_reward": 6.4, "eval_time": 9.674304008483887, "mean_episode_reward": 6.4, "best_episode_reward": 10.0, "step": 595000}
{"episode": 1789.0, "episode_reward": 5.1, "eval_time": 9.700075626373291, "mean_episode_reward": 5.1, "best_episode_reward": 7.0, "step": 596000}
{"episode": 1792.0, "episode_reward": 5.9, "eval_time": 9.782130479812622, "mean_episode_reward": 5.9, "best_episode_reward": 8.0, "step": 597000}
{"episode": 1795.0, "episode_reward": 8.2, "eval_time": 9.585257053375244, "mean_episode_reward": 8.2, "best_episode_reward": 11.0, "step": 598000}
{"episode": 1798.0, "episode_reward": 5.4, "eval_time": 9.654767990112305, "mean_episode_reward": 5.4, "best_episode_reward": 9.0, "step": 599000}
{"episode": 1801.0, "episode_reward": 6.4, "eval_time": 9.611875772476196, "mean_episode_reward": 6.4, "best_episode_reward": 8.0, "step": 600000}
{"episode": 1804.0, "episode_reward": 6.6, "eval_time": 9.68773889541626, "mean_episode_reward": 6.6, "best_episode_reward": 9.0, "step": 601000}
{"episode": 1807.0, "episode_reward": 6.3, "eval_time": 9.7991783618927, "mean_episode_reward": 6.3, "best_episode_reward": 9.0, "step": 602000}
{"episode": 1810.0, "episode_reward": 6.2, "eval_time": 9.788347482681274, "mean_episode_reward": 6.2, "best_episode_reward": 8.0, "step": 603000}
{"episode": 1813.0, "episode_reward": 5.3, "eval_time": 9.672312498092651, "mean_episode_reward": 5.3, "best_episode_reward": 9.0, "step": 604000}
{"episode": 1816.0, "episode_reward": 7.0, "eval_time": 9.65595555305481, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 605000}
{"episode": 1819.0, "episode_reward": 6.2, "eval_time": 9.601306438446045, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 606000}
{"episode": 1822.0, "episode_reward": 7.8, "eval_time": 9.59455418586731, "mean_episode_reward": 7.8, "best_episode_reward": 10.0, "step": 607000}
{"episode": 1825.0, "episode_reward": 7.8, "eval_time": 9.655561208724976, "mean_episode_reward": 7.8, "best_episode_reward": 10.0, "step": 608000}
{"episode": 1828.0, "episode_reward": 5.4, "eval_time": 9.779657125473022, "mean_episode_reward": 5.4, "best_episode_reward": 8.0, "step": 609000}
{"episode": 1831.0, "episode_reward": 5.0, "eval_time": 9.854539155960083, "mean_episode_reward": 5.0, "best_episode_reward": 7.0, "step": 610000}
{"episode": 1834.0, "episode_reward": 6.8, "eval_time": 9.53931975364685, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 611000}
{"episode": 1837.0, "episode_reward": 6.5, "eval_time": 9.55733585357666, "mean_episode_reward": 6.5, "best_episode_reward": 11.0, "step": 612000}
{"episode": 1840.0, "episode_reward": 4.5, "eval_time": 9.790181398391724, "mean_episode_reward": 4.5, "best_episode_reward": 6.0, "step": 613000}
{"episode": 1843.0, "episode_reward": 7.6, "eval_time": 9.679641962051392, "mean_episode_reward": 7.6, "best_episode_reward": 11.0, "step": 614000}
{"episode": 1846.0, "episode_reward": 6.1, "eval_time": 9.572721481323242, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 615000}
{"episode": 1849.0, "episode_reward": 6.4, "eval_time": 9.619224548339844, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 616000}
{"episode": 1852.0, "episode_reward": 7.8, "eval_time": 9.610545873641968, "mean_episode_reward": 7.8, "best_episode_reward": 10.0, "step": 617000}
{"episode": 1855.0, "episode_reward": 6.9, "eval_time": 9.652236223220825, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 618000}
{"episode": 1858.0, "episode_reward": 6.1, "eval_time": 9.5340735912323, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 619000}
{"episode": 1861.0, "episode_reward": 5.3, "eval_time": 9.777379274368286, "mean_episode_reward": 5.3, "best_episode_reward": 7.0, "step": 620000}
{"episode": 1864.0, "episode_reward": 7.1, "eval_time": 10.020697832107544, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 621000}
{"episode": 1867.0, "episode_reward": 6.5, "eval_time": 9.67837643623352, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 622000}
{"episode": 1870.0, "episode_reward": 5.6, "eval_time": 9.776762008666992, "mean_episode_reward": 5.6, "best_episode_reward": 10.0, "step": 623000}
{"episode": 1873.0, "episode_reward": 7.6, "eval_time": 9.77013111114502, "mean_episode_reward": 7.6, "best_episode_reward": 10.0, "step": 624000}
{"episode": 1876.0, "episode_reward": 6.7, "eval_time": 9.667516469955444, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 625000}
{"episode": 1879.0, "episode_reward": 4.5, "eval_time": 9.683693170547485, "mean_episode_reward": 4.5, "best_episode_reward": 9.0, "step": 626000}
{"episode": 1882.0, "episode_reward": 7.5, "eval_time": 9.61697268486023, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 627000}
{"episode": 1885.0, "episode_reward": 6.9, "eval_time": 9.773651599884033, "mean_episode_reward": 6.9, "best_episode_reward": 10.0, "step": 628000}
{"episode": 1888.0, "episode_reward": 7.1, "eval_time": 9.69045090675354, "mean_episode_reward": 7.1, "best_episode_reward": 8.0, "step": 629000}
{"episode": 1891.0, "episode_reward": 6.8, "eval_time": 9.735974073410034, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 630000}
{"episode": 1894.0, "episode_reward": 5.8, "eval_time": 9.725297927856445, "mean_episode_reward": 5.8, "best_episode_reward": 9.0, "step": 631000}
{"episode": 1897.0, "episode_reward": 6.2, "eval_time": 9.67155408859253, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 632000}
{"episode": 1900.0, "episode_reward": 7.5, "eval_time": 9.655641794204712, "mean_episode_reward": 7.5, "best_episode_reward": 12.0, "step": 633000}
{"episode": 1903.0, "episode_reward": 6.9, "eval_time": 9.73009705543518, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 634000}
{"episode": 1906.0, "episode_reward": 7.5, "eval_time": 9.745898008346558, "mean_episode_reward": 7.5, "best_episode_reward": 13.0, "step": 635000}
{"episode": 1909.0, "episode_reward": 7.5, "eval_time": 9.685799360275269, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 636000}
{"episode": 1912.0, "episode_reward": 7.4, "eval_time": 9.725975751876831, "mean_episode_reward": 7.4, "best_episode_reward": 9.0, "step": 637000}
{"episode": 1915.0, "episode_reward": 6.1, "eval_time": 9.787389516830444, "mean_episode_reward": 6.1, "best_episode_reward": 11.0, "step": 638000}
{"episode": 1918.0, "episode_reward": 7.3, "eval_time": 9.72811508178711, "mean_episode_reward": 7.3, "best_episode_reward": 9.0, "step": 639000}
{"episode": 1921.0, "episode_reward": 7.2, "eval_time": 9.82590389251709, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 640000}
{"episode": 1924.0, "episode_reward": 6.8, "eval_time": 9.66387414932251, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 641000}
{"episode": 1927.0, "episode_reward": 7.7, "eval_time": 9.720687866210938, "mean_episode_reward": 7.7, "best_episode_reward": 9.0, "step": 642000}
{"episode": 1930.0, "episode_reward": 7.9, "eval_time": 9.743260145187378, "mean_episode_reward": 7.9, "best_episode_reward": 11.0, "step": 643000}
{"episode": 1933.0, "episode_reward": 6.4, "eval_time": 9.62705373764038, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 644000}
{"episode": 1936.0, "episode_reward": 6.2, "eval_time": 9.701671361923218, "mean_episode_reward": 6.2, "best_episode_reward": 8.0, "step": 645000}
{"episode": 1939.0, "episode_reward": 4.9, "eval_time": 9.687429666519165, "mean_episode_reward": 4.9, "best_episode_reward": 8.0, "step": 646000}
{"episode": 1942.0, "episode_reward": 6.2, "eval_time": 9.985933542251587, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 647000}
{"episode": 1945.0, "episode_reward": 7.1, "eval_time": 9.827641248703003, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 648000}
{"episode": 1948.0, "episode_reward": 6.6, "eval_time": 9.724343538284302, "mean_episode_reward": 6.6, "best_episode_reward": 8.0, "step": 649000}
{"episode": 1951.0, "episode_reward": 6.4, "eval_time": 9.641726732254028, "mean_episode_reward": 6.4, "best_episode_reward": 8.0, "step": 650000}
{"episode": 1954.0, "episode_reward": 6.9, "eval_time": 9.799442529678345, "mean_episode_reward": 6.9, "best_episode_reward": 10.0, "step": 651000}
{"episode": 1957.0, "episode_reward": 6.7, "eval_time": 9.689704179763794, "mean_episode_reward": 6.7, "best_episode_reward": 8.0, "step": 652000}
{"episode": 1960.0, "episode_reward": 6.0, "eval_time": 9.68045425415039, "mean_episode_reward": 6.0, "best_episode_reward": 8.0, "step": 653000}
{"episode": 1963.0, "episode_reward": 7.1, "eval_time": 9.74648404121399, "mean_episode_reward": 7.1, "best_episode_reward": 10.0, "step": 654000}
{"episode": 1966.0, "episode_reward": 6.9, "eval_time": 9.835515975952148, "mean_episode_reward": 6.9, "best_episode_reward": 8.0, "step": 655000}
{"episode": 1969.0, "episode_reward": 7.0, "eval_time": 9.71219515800476, "mean_episode_reward": 7.0, "best_episode_reward": 11.0, "step": 656000}
{"episode": 1972.0, "episode_reward": 6.5, "eval_time": 9.810034036636353, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 657000}
{"episode": 1975.0, "episode_reward": 7.1, "eval_time": 9.575939655303955, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 658000}
{"episode": 1978.0, "episode_reward": 7.3, "eval_time": 9.715840101242065, "mean_episode_reward": 7.3, "best_episode_reward": 9.0, "step": 659000}
{"episode": 1981.0, "episode_reward": 6.7, "eval_time": 9.674009084701538, "mean_episode_reward": 6.7, "best_episode_reward": 10.0, "step": 660000}
{"episode": 1984.0, "episode_reward": 7.4, "eval_time": 9.692328691482544, "mean_episode_reward": 7.4, "best_episode_reward": 9.0, "step": 661000}
{"episode": 1987.0, "episode_reward": 6.3, "eval_time": 9.508684158325195, "mean_episode_reward": 6.3, "best_episode_reward": 14.0, "step": 662000}
{"episode": 1990.0, "episode_reward": 6.3, "eval_time": 9.916430950164795, "mean_episode_reward": 6.3, "best_episode_reward": 12.0, "step": 663000}
{"episode": 1993.0, "episode_reward": 7.2, "eval_time": 9.783353090286255, "mean_episode_reward": 7.2, "best_episode_reward": 8.0, "step": 664000}
{"episode": 1996.0, "episode_reward": 8.9, "eval_time": 9.707149744033813, "mean_episode_reward": 8.9, "best_episode_reward": 20.0, "step": 665000}
{"episode": 1999.0, "episode_reward": 7.4, "eval_time": 9.725152254104614, "mean_episode_reward": 7.4, "best_episode_reward": 10.0, "step": 666000}
{"episode": 2002.0, "episode_reward": 6.1, "eval_time": 9.784674167633057, "mean_episode_reward": 6.1, "best_episode_reward": 10.0, "step": 667000}
{"episode": 2005.0, "episode_reward": 5.9, "eval_time": 9.769307851791382, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 668000}
{"episode": 2008.0, "episode_reward": 5.9, "eval_time": 9.806670904159546, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 669000}
{"episode": 2011.0, "episode_reward": 6.7, "eval_time": 9.633264541625977, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 670000}
{"episode": 2014.0, "episode_reward": 8.9, "eval_time": 9.776922225952148, "mean_episode_reward": 8.9, "best_episode_reward": 19.0, "step": 671000}
{"episode": 2017.0, "episode_reward": 7.5, "eval_time": 9.70691442489624, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 672000}
{"episode": 2020.0, "episode_reward": 8.0, "eval_time": 9.81841254234314, "mean_episode_reward": 8.0, "best_episode_reward": 9.0, "step": 673000}
{"episode": 2023.0, "episode_reward": 7.8, "eval_time": 9.887293577194214, "mean_episode_reward": 7.8, "best_episode_reward": 11.0, "step": 674000}
{"episode": 2026.0, "episode_reward": 7.8, "eval_time": 9.68283462524414, "mean_episode_reward": 7.8, "best_episode_reward": 11.0, "step": 675000}
{"episode": 2029.0, "episode_reward": 7.6, "eval_time": 9.692724704742432, "mean_episode_reward": 7.6, "best_episode_reward": 9.0, "step": 676000}
{"episode": 2032.0, "episode_reward": 7.4, "eval_time": 9.7752103805542, "mean_episode_reward": 7.4, "best_episode_reward": 9.0, "step": 677000}
{"episode": 2035.0, "episode_reward": 8.3, "eval_time": 9.865888833999634, "mean_episode_reward": 8.3, "best_episode_reward": 10.0, "step": 678000}
{"episode": 2038.0, "episode_reward": 8.0, "eval_time": 9.705409526824951, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 679000}
{"episode": 2041.0, "episode_reward": 8.4, "eval_time": 9.659504652023315, "mean_episode_reward": 8.4, "best_episode_reward": 10.0, "step": 680000}
{"episode": 2044.0, "episode_reward": 6.3, "eval_time": 9.494378089904785, "mean_episode_reward": 6.3, "best_episode_reward": 8.0, "step": 681000}
{"episode": 2047.0, "episode_reward": 5.9, "eval_time": 9.832682609558105, "mean_episode_reward": 5.9, "best_episode_reward": 8.0, "step": 682000}
{"episode": 2050.0, "episode_reward": 6.4, "eval_time": 9.643311500549316, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 683000}
{"episode": 2053.0, "episode_reward": 6.1, "eval_time": 10.48029375076294, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 684000}
{"episode": 2056.0, "episode_reward": 7.1, "eval_time": 9.731983184814453, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 685000}
{"episode": 2059.0, "episode_reward": 7.0, "eval_time": 9.604124307632446, "mean_episode_reward": 7.0, "best_episode_reward": 13.0, "step": 686000}
{"episode": 2062.0, "episode_reward": 7.0, "eval_time": 9.731998682022095, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 687000}
{"episode": 2065.0, "episode_reward": 4.6, "eval_time": 9.652648687362671, "mean_episode_reward": 4.6, "best_episode_reward": 7.0, "step": 688000}
{"episode": 2068.0, "episode_reward": 5.7, "eval_time": 9.721615076065063, "mean_episode_reward": 5.7, "best_episode_reward": 9.0, "step": 689000}
{"episode": 2071.0, "episode_reward": 7.7, "eval_time": 9.732906579971313, "mean_episode_reward": 7.7, "best_episode_reward": 11.0, "step": 690000}
{"episode": 2074.0, "episode_reward": 7.1, "eval_time": 9.722156763076782, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 691000}
{"episode": 2077.0, "episode_reward": 6.9, "eval_time": 9.595054626464844, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 692000}
{"episode": 2080.0, "episode_reward": 7.2, "eval_time": 9.65640926361084, "mean_episode_reward": 7.2, "best_episode_reward": 11.0, "step": 693000}
{"episode": 2083.0, "episode_reward": 1.0, "eval_time": 9.882696628570557, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 694000}
{"episode": 2086.0, "episode_reward": 5.8, "eval_time": 9.832064867019653, "mean_episode_reward": 5.8, "best_episode_reward": 8.0, "step": 695000}
{"episode": 2089.0, "episode_reward": 6.6, "eval_time": 9.728411197662354, "mean_episode_reward": 6.6, "best_episode_reward": 9.0, "step": 696000}
{"episode": 2092.0, "episode_reward": 7.5, "eval_time": 9.749621629714966, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 697000}
{"episode": 2095.0, "episode_reward": 6.8, "eval_time": 9.714802265167236, "mean_episode_reward": 6.8, "best_episode_reward": 8.0, "step": 698000}
{"episode": 2098.0, "episode_reward": 7.1, "eval_time": 9.73710298538208, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 699000}
{"episode": 2101.0, "episode_reward": 7.0, "eval_time": 9.800243854522705, "mean_episode_reward": 7.0, "best_episode_reward": 14.0, "step": 700000}
{"episode": 2104.0, "episode_reward": 5.5, "eval_time": 9.739040613174438, "mean_episode_reward": 5.5, "best_episode_reward": 8.0, "step": 701000}
{"episode": 2107.0, "episode_reward": 7.6, "eval_time": 9.857633829116821, "mean_episode_reward": 7.6, "best_episode_reward": 12.0, "step": 702000}
{"episode": 2110.0, "episode_reward": 7.6, "eval_time": 9.728659391403198, "mean_episode_reward": 7.6, "best_episode_reward": 9.0, "step": 703000}
{"episode": 2113.0, "episode_reward": 5.8, "eval_time": 9.624214887619019, "mean_episode_reward": 5.8, "best_episode_reward": 9.0, "step": 704000}
{"episode": 2116.0, "episode_reward": 5.6, "eval_time": 9.937026739120483, "mean_episode_reward": 5.6, "best_episode_reward": 9.0, "step": 705000}
{"episode": 2119.0, "episode_reward": 6.5, "eval_time": 9.787518978118896, "mean_episode_reward": 6.5, "best_episode_reward": 8.0, "step": 706000}
{"episode": 2122.0, "episode_reward": 7.5, "eval_time": 9.661723852157593, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 707000}
{"episode": 2125.0, "episode_reward": 6.8, "eval_time": 9.828340530395508, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 708000}
{"episode": 2128.0, "episode_reward": 6.9, "eval_time": 9.809058427810669, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 709000}
{"episode": 2131.0, "episode_reward": 8.0, "eval_time": 9.69978952407837, "mean_episode_reward": 8.0, "best_episode_reward": 9.0, "step": 710000}
{"episode": 2134.0, "episode_reward": 6.9, "eval_time": 9.67963457107544, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 711000}
{"episode": 2137.0, "episode_reward": 6.7, "eval_time": 9.662451982498169, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 712000}
{"episode": 2140.0, "episode_reward": 8.2, "eval_time": 9.681613683700562, "mean_episode_reward": 8.2, "best_episode_reward": 10.0, "step": 713000}
{"episode": 2143.0, "episode_reward": 8.2, "eval_time": 9.706952571868896, "mean_episode_reward": 8.2, "best_episode_reward": 10.0, "step": 714000}
{"episode": 2146.0, "episode_reward": 7.2, "eval_time": 9.689313173294067, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 715000}
{"episode": 2149.0, "episode_reward": 6.8, "eval_time": 9.899711608886719, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 716000}
{"episode": 2152.0, "episode_reward": 5.2, "eval_time": 9.939667701721191, "mean_episode_reward": 5.2, "best_episode_reward": 8.0, "step": 717000}
{"episode": 2155.0, "episode_reward": 6.7, "eval_time": 9.738425254821777, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 718000}
{"episode": 2158.0, "episode_reward": 4.7, "eval_time": 9.934437036514282, "mean_episode_reward": 4.7, "best_episode_reward": 7.0, "step": 719000}
{"episode": 2161.0, "episode_reward": 6.4, "eval_time": 9.780513048171997, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 720000}
{"episode": 2164.0, "episode_reward": 5.6, "eval_time": 9.699600219726562, "mean_episode_reward": 5.6, "best_episode_reward": 7.0, "step": 721000}
{"episode": 2167.0, "episode_reward": 6.7, "eval_time": 9.858888387680054, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 722000}
{"episode": 2170.0, "episode_reward": 7.3, "eval_time": 9.820332527160645, "mean_episode_reward": 7.3, "best_episode_reward": 10.0, "step": 723000}
{"episode": 2173.0, "episode_reward": 6.8, "eval_time": 9.702422380447388, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 724000}
{"episode": 2176.0, "episode_reward": 6.2, "eval_time": 9.866042613983154, "mean_episode_reward": 6.2, "best_episode_reward": 9.0, "step": 725000}
{"episode": 2179.0, "episode_reward": 8.7, "eval_time": 9.930360078811646, "mean_episode_reward": 8.7, "best_episode_reward": 11.0, "step": 726000}
{"episode": 2182.0, "episode_reward": 8.6, "eval_time": 9.688363075256348, "mean_episode_reward": 8.6, "best_episode_reward": 13.0, "step": 727000}
{"episode": 2185.0, "episode_reward": 8.2, "eval_time": 9.660958290100098, "mean_episode_reward": 8.2, "best_episode_reward": 10.0, "step": 728000}
{"episode": 2188.0, "episode_reward": 6.7, "eval_time": 9.740267515182495, "mean_episode_reward": 6.7, "best_episode_reward": 11.0, "step": 729000}
{"episode": 2191.0, "episode_reward": 8.2, "eval_time": 9.739920854568481, "mean_episode_reward": 8.2, "best_episode_reward": 20.0, "step": 730000}
{"episode": 2194.0, "episode_reward": 5.6, "eval_time": 9.63313889503479, "mean_episode_reward": 5.6, "best_episode_reward": 9.0, "step": 731000}
{"episode": 2197.0, "episode_reward": 7.4, "eval_time": 9.835615873336792, "mean_episode_reward": 7.4, "best_episode_reward": 8.0, "step": 732000}
{"episode": 2200.0, "episode_reward": 6.0, "eval_time": 9.784982919692993, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 733000}
{"episode": 2203.0, "episode_reward": 5.2, "eval_time": 9.845316410064697, "mean_episode_reward": 5.2, "best_episode_reward": 7.0, "step": 734000}
{"episode": 2206.0, "episode_reward": 7.3, "eval_time": 9.692281007766724, "mean_episode_reward": 7.3, "best_episode_reward": 10.0, "step": 735000}
{"episode": 2209.0, "episode_reward": 6.9, "eval_time": 9.788789987564087, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 736000}
{"episode": 2212.0, "episode_reward": 8.6, "eval_time": 9.76169228553772, "mean_episode_reward": 8.6, "best_episode_reward": 14.0, "step": 737000}
{"episode": 2215.0, "episode_reward": 6.9, "eval_time": 9.674464225769043, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 738000}
{"episode": 2218.0, "episode_reward": 8.8, "eval_time": 9.866257190704346, "mean_episode_reward": 8.8, "best_episode_reward": 17.0, "step": 739000}
{"episode": 2221.0, "episode_reward": 6.7, "eval_time": 9.873992681503296, "mean_episode_reward": 6.7, "best_episode_reward": 8.0, "step": 740000}
{"episode": 2224.0, "episode_reward": 6.8, "eval_time": 9.828147888183594, "mean_episode_reward": 6.8, "best_episode_reward": 10.0, "step": 741000}
{"episode": 2227.0, "episode_reward": 8.1, "eval_time": 9.828401327133179, "mean_episode_reward": 8.1, "best_episode_reward": 11.0, "step": 742000}
{"episode": 2230.0, "episode_reward": 7.2, "eval_time": 9.8206627368927, "mean_episode_reward": 7.2, "best_episode_reward": 12.0, "step": 743000}
{"episode": 2233.0, "episode_reward": 7.6, "eval_time": 9.905165433883667, "mean_episode_reward": 7.6, "best_episode_reward": 11.0, "step": 744000}
{"episode": 2236.0, "episode_reward": 6.6, "eval_time": 9.85581350326538, "mean_episode_reward": 6.6, "best_episode_reward": 12.0, "step": 745000}
{"episode": 2239.0, "episode_reward": 8.0, "eval_time": 9.856772661209106, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 746000}
{"episode": 2242.0, "episode_reward": 6.7, "eval_time": 9.91275668144226, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 747000}
{"episode": 2245.0, "episode_reward": 9.5, "eval_time": 9.70028305053711, "mean_episode_reward": 9.5, "best_episode_reward": 11.0, "step": 748000}
{"episode": 2248.0, "episode_reward": 8.0, "eval_time": 9.880064725875854, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 749000}
{"episode": 2251.0, "episode_reward": 8.1, "eval_time": 9.868337869644165, "mean_episode_reward": 8.1, "best_episode_reward": 14.0, "step": 750000}
{"episode": 2254.0, "episode_reward": 7.8, "eval_time": 9.808902263641357, "mean_episode_reward": 7.8, "best_episode_reward": 9.0, "step": 751000}
{"episode": 2257.0, "episode_reward": 8.8, "eval_time": 9.68216872215271, "mean_episode_reward": 8.8, "best_episode_reward": 14.0, "step": 752000}
{"episode": 2260.0, "episode_reward": 5.8, "eval_time": 9.936696767807007, "mean_episode_reward": 5.8, "best_episode_reward": 8.0, "step": 753000}
{"episode": 2263.0, "episode_reward": 7.2, "eval_time": 9.810274839401245, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 754000}
{"episode": 2266.0, "episode_reward": 7.7, "eval_time": 9.768663167953491, "mean_episode_reward": 7.7, "best_episode_reward": 10.0, "step": 755000}
{"episode": 2269.0, "episode_reward": 8.2, "eval_time": 9.75576901435852, "mean_episode_reward": 8.2, "best_episode_reward": 13.0, "step": 756000}
{"episode": 2272.0, "episode_reward": 7.0, "eval_time": 9.843311548233032, "mean_episode_reward": 7.0, "best_episode_reward": 12.0, "step": 757000}
{"episode": 2275.0, "episode_reward": 8.4, "eval_time": 9.82299518585205, "mean_episode_reward": 8.4, "best_episode_reward": 10.0, "step": 758000}
{"episode": 2278.0, "episode_reward": 7.2, "eval_time": 9.86618947982788, "mean_episode_reward": 7.2, "best_episode_reward": 11.0, "step": 759000}
{"episode": 2281.0, "episode_reward": 8.0, "eval_time": 9.804502010345459, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 760000}
{"episode": 2284.0, "episode_reward": 8.8, "eval_time": 9.795359134674072, "mean_episode_reward": 8.8, "best_episode_reward": 12.0, "step": 761000}
{"episode": 2287.0, "episode_reward": 7.7, "eval_time": 9.882298469543457, "mean_episode_reward": 7.7, "best_episode_reward": 11.0, "step": 762000}
{"episode": 2290.0, "episode_reward": 7.9, "eval_time": 9.793851375579834, "mean_episode_reward": 7.9, "best_episode_reward": 9.0, "step": 763000}
{"episode": 2293.0, "episode_reward": 8.3, "eval_time": 9.860678911209106, "mean_episode_reward": 8.3, "best_episode_reward": 11.0, "step": 764000}
{"episode": 2296.0, "episode_reward": 6.7, "eval_time": 9.78755784034729, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 765000}
{"episode": 2299.0, "episode_reward": 8.4, "eval_time": 9.761940717697144, "mean_episode_reward": 8.4, "best_episode_reward": 11.0, "step": 766000}
{"episode": 2302.0, "episode_reward": 7.0, "eval_time": 9.748627662658691, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 767000}
{"episode": 2305.0, "episode_reward": 6.7, "eval_time": 9.938825130462646, "mean_episode_reward": 6.7, "best_episode_reward": 9.0, "step": 768000}
{"episode": 2308.0, "episode_reward": 7.9, "eval_time": 9.856267213821411, "mean_episode_reward": 7.9, "best_episode_reward": 9.0, "step": 769000}
{"episode": 2311.0, "episode_reward": 5.2, "eval_time": 9.910193920135498, "mean_episode_reward": 5.2, "best_episode_reward": 8.0, "step": 770000}
{"episode": 2314.0, "episode_reward": 6.4, "eval_time": 9.806195735931396, "mean_episode_reward": 6.4, "best_episode_reward": 11.0, "step": 771000}
{"episode": 2317.0, "episode_reward": 7.9, "eval_time": 9.882015466690063, "mean_episode_reward": 7.9, "best_episode_reward": 11.0, "step": 772000}
{"episode": 2320.0, "episode_reward": 6.7, "eval_time": 9.813526630401611, "mean_episode_reward": 6.7, "best_episode_reward": 8.0, "step": 773000}
{"episode": 2323.0, "episode_reward": 7.2, "eval_time": 9.771959066390991, "mean_episode_reward": 7.2, "best_episode_reward": 8.0, "step": 774000}
{"episode": 2326.0, "episode_reward": 4.6, "eval_time": 10.012965440750122, "mean_episode_reward": 4.6, "best_episode_reward": 7.0, "step": 775000}
{"episode": 2329.0, "episode_reward": 6.9, "eval_time": 9.791459321975708, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 776000}
{"episode": 2332.0, "episode_reward": 9.1, "eval_time": 9.74931263923645, "mean_episode_reward": 9.1, "best_episode_reward": 10.0, "step": 777000}
{"episode": 2335.0, "episode_reward": 6.1, "eval_time": 10.032873392105103, "mean_episode_reward": 6.1, "best_episode_reward": 8.0, "step": 778000}
{"episode": 2338.0, "episode_reward": 8.6, "eval_time": 9.753942728042603, "mean_episode_reward": 8.6, "best_episode_reward": 13.0, "step": 779000}
{"episode": 2341.0, "episode_reward": 5.6, "eval_time": 9.97583293914795, "mean_episode_reward": 5.6, "best_episode_reward": 9.0, "step": 780000}
{"episode": 2344.0, "episode_reward": 8.4, "eval_time": 9.792603969573975, "mean_episode_reward": 8.4, "best_episode_reward": 12.0, "step": 781000}
{"episode": 2347.0, "episode_reward": 7.9, "eval_time": 9.784919738769531, "mean_episode_reward": 7.9, "best_episode_reward": 10.0, "step": 782000}
{"episode": 2350.0, "episode_reward": 8.8, "eval_time": 9.755999326705933, "mean_episode_reward": 8.8, "best_episode_reward": 11.0, "step": 783000}
{"episode": 2353.0, "episode_reward": 6.9, "eval_time": 9.737701892852783, "mean_episode_reward": 6.9, "best_episode_reward": 8.0, "step": 784000}
{"episode": 2356.0, "episode_reward": 8.5, "eval_time": 9.803271770477295, "mean_episode_reward": 8.5, "best_episode_reward": 10.0, "step": 785000}
{"episode": 2359.0, "episode_reward": 8.0, "eval_time": 9.752776861190796, "mean_episode_reward": 8.0, "best_episode_reward": 11.0, "step": 786000}
{"episode": 2362.0, "episode_reward": 7.7, "eval_time": 9.781627416610718, "mean_episode_reward": 7.7, "best_episode_reward": 12.0, "step": 787000}
{"episode": 2365.0, "episode_reward": 7.2, "eval_time": 9.68843960762024, "mean_episode_reward": 7.2, "best_episode_reward": 10.0, "step": 788000}
{"episode": 2368.0, "episode_reward": 9.2, "eval_time": 9.817564249038696, "mean_episode_reward": 9.2, "best_episode_reward": 12.0, "step": 789000}
{"episode": 2371.0, "episode_reward": 8.8, "eval_time": 9.742871046066284, "mean_episode_reward": 8.8, "best_episode_reward": 11.0, "step": 790000}
{"episode": 2374.0, "episode_reward": 6.7, "eval_time": 9.970584154129028, "mean_episode_reward": 6.7, "best_episode_reward": 12.0, "step": 791000}
{"episode": 2377.0, "episode_reward": 6.4, "eval_time": 9.901521921157837, "mean_episode_reward": 6.4, "best_episode_reward": 9.0, "step": 792000}
{"episode": 2380.0, "episode_reward": 8.0, "eval_time": 9.844341039657593, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 793000}
{"episode": 2383.0, "episode_reward": 8.1, "eval_time": 9.82254695892334, "mean_episode_reward": 8.1, "best_episode_reward": 13.0, "step": 794000}
{"episode": 2386.0, "episode_reward": 6.4, "eval_time": 9.8123939037323, "mean_episode_reward": 6.4, "best_episode_reward": 8.0, "step": 795000}
{"episode": 2389.0, "episode_reward": 7.7, "eval_time": 9.667677402496338, "mean_episode_reward": 7.7, "best_episode_reward": 10.0, "step": 796000}
{"episode": 2392.0, "episode_reward": 6.0, "eval_time": 9.815480709075928, "mean_episode_reward": 6.0, "best_episode_reward": 8.0, "step": 797000}
{"episode": 2395.0, "episode_reward": 7.8, "eval_time": 9.669655323028564, "mean_episode_reward": 7.8, "best_episode_reward": 10.0, "step": 798000}
{"episode": 2398.0, "episode_reward": 6.4, "eval_time": 9.739539623260498, "mean_episode_reward": 6.4, "best_episode_reward": 10.0, "step": 799000}
{"episode": 2401.0, "episode_reward": 8.0, "eval_time": 9.939897775650024, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 800000}
{"episode": 2404.0, "episode_reward": 7.8, "eval_time": 9.88025426864624, "mean_episode_reward": 7.8, "best_episode_reward": 9.0, "step": 801000}
{"episode": 2407.0, "episode_reward": 8.4, "eval_time": 9.794319152832031, "mean_episode_reward": 8.4, "best_episode_reward": 11.0, "step": 802000}
{"episode": 2410.0, "episode_reward": 9.8, "eval_time": 9.787413835525513, "mean_episode_reward": 9.8, "best_episode_reward": 16.0, "step": 803000}
{"episode": 2413.0, "episode_reward": 8.6, "eval_time": 9.768226623535156, "mean_episode_reward": 8.6, "best_episode_reward": 10.0, "step": 804000}
{"episode": 2416.0, "episode_reward": 9.6, "eval_time": 9.892394304275513, "mean_episode_reward": 9.6, "best_episode_reward": 16.0, "step": 805000}
{"episode": 2419.0, "episode_reward": 9.9, "eval_time": 9.71079707145691, "mean_episode_reward": 9.9, "best_episode_reward": 17.0, "step": 806000}
{"episode": 2422.0, "episode_reward": 8.3, "eval_time": 9.65272569656372, "mean_episode_reward": 8.3, "best_episode_reward": 9.0, "step": 807000}
{"episode": 2425.0, "episode_reward": 8.5, "eval_time": 9.782813310623169, "mean_episode_reward": 8.5, "best_episode_reward": 16.0, "step": 808000}
{"episode": 2428.0, "episode_reward": 7.9, "eval_time": 9.6160409450531, "mean_episode_reward": 7.9, "best_episode_reward": 11.0, "step": 809000}
{"episode": 2431.0, "episode_reward": 8.1, "eval_time": 9.888890504837036, "mean_episode_reward": 8.1, "best_episode_reward": 10.0, "step": 810000}
{"episode": 2434.0, "episode_reward": 6.1, "eval_time": 9.926268815994263, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 811000}
{"episode": 2437.0, "episode_reward": 8.6, "eval_time": 9.777442932128906, "mean_episode_reward": 8.6, "best_episode_reward": 12.0, "step": 812000}
{"episode": 2440.0, "episode_reward": 8.3, "eval_time": 9.817375421524048, "mean_episode_reward": 8.3, "best_episode_reward": 10.0, "step": 813000}
{"episode": 2443.0, "episode_reward": 8.7, "eval_time": 9.700956106185913, "mean_episode_reward": 8.7, "best_episode_reward": 11.0, "step": 814000}
{"episode": 2446.0, "episode_reward": 8.2, "eval_time": 9.787255764007568, "mean_episode_reward": 8.2, "best_episode_reward": 10.0, "step": 815000}
{"episode": 2449.0, "episode_reward": 7.2, "eval_time": 9.762884378433228, "mean_episode_reward": 7.2, "best_episode_reward": 12.0, "step": 816000}
{"episode": 2452.0, "episode_reward": 8.0, "eval_time": 9.691057920455933, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 817000}
{"episode": 2455.0, "episode_reward": 7.7, "eval_time": 9.723897457122803, "mean_episode_reward": 7.7, "best_episode_reward": 10.0, "step": 818000}
{"episode": 2458.0, "episode_reward": 8.8, "eval_time": 9.766238927841187, "mean_episode_reward": 8.8, "best_episode_reward": 10.0, "step": 819000}
{"episode": 2461.0, "episode_reward": 6.1, "eval_time": 9.75740385055542, "mean_episode_reward": 6.1, "best_episode_reward": 9.0, "step": 820000}
{"episode": 2464.0, "episode_reward": 8.3, "eval_time": 9.787218809127808, "mean_episode_reward": 8.3, "best_episode_reward": 9.0, "step": 821000}
{"episode": 2467.0, "episode_reward": 6.2, "eval_time": 9.753631114959717, "mean_episode_reward": 6.2, "best_episode_reward": 10.0, "step": 822000}
{"episode": 2470.0, "episode_reward": 5.9, "eval_time": 9.939576387405396, "mean_episode_reward": 5.9, "best_episode_reward": 9.0, "step": 823000}
{"episode": 2473.0, "episode_reward": 7.2, "eval_time": 9.677964687347412, "mean_episode_reward": 7.2, "best_episode_reward": 8.0, "step": 824000}
{"episode": 2476.0, "episode_reward": 7.9, "eval_time": 9.808711767196655, "mean_episode_reward": 7.9, "best_episode_reward": 10.0, "step": 825000}
{"episode": 2479.0, "episode_reward": 8.2, "eval_time": 9.642083406448364, "mean_episode_reward": 8.2, "best_episode_reward": 9.0, "step": 826000}
{"episode": 2482.0, "episode_reward": 8.0, "eval_time": 9.696622610092163, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 827000}
{"episode": 2485.0, "episode_reward": 8.5, "eval_time": 9.750428915023804, "mean_episode_reward": 8.5, "best_episode_reward": 10.0, "step": 828000}
{"episode": 2488.0, "episode_reward": 7.2, "eval_time": 9.75169587135315, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 829000}
{"episode": 2491.0, "episode_reward": 7.6, "eval_time": 10.003551959991455, "mean_episode_reward": 7.6, "best_episode_reward": 9.0, "step": 830000}
{"episode": 2494.0, "episode_reward": 9.0, "eval_time": 9.777199983596802, "mean_episode_reward": 9.0, "best_episode_reward": 10.0, "step": 831000}
{"episode": 2497.0, "episode_reward": 4.9, "eval_time": 10.042460918426514, "mean_episode_reward": 4.9, "best_episode_reward": 7.0, "step": 832000}
{"episode": 2500.0, "episode_reward": 6.0, "eval_time": 9.752059936523438, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 833000}
{"episode": 2503.0, "episode_reward": 7.9, "eval_time": 9.767903327941895, "mean_episode_reward": 7.9, "best_episode_reward": 10.0, "step": 834000}
{"episode": 2506.0, "episode_reward": 5.9, "eval_time": 9.909689664840698, "mean_episode_reward": 5.9, "best_episode_reward": 8.0, "step": 835000}
{"episode": 2509.0, "episode_reward": 7.1, "eval_time": 9.759861946105957, "mean_episode_reward": 7.1, "best_episode_reward": 8.0, "step": 836000}
{"episode": 2512.0, "episode_reward": 8.1, "eval_time": 9.749681949615479, "mean_episode_reward": 8.1, "best_episode_reward": 10.0, "step": 837000}
{"episode": 2515.0, "episode_reward": 7.4, "eval_time": 9.887950897216797, "mean_episode_reward": 7.4, "best_episode_reward": 9.0, "step": 838000}
{"episode": 2518.0, "episode_reward": 7.4, "eval_time": 9.8117835521698, "mean_episode_reward": 7.4, "best_episode_reward": 8.0, "step": 839000}
{"episode": 2521.0, "episode_reward": 8.1, "eval_time": 9.693180561065674, "mean_episode_reward": 8.1, "best_episode_reward": 10.0, "step": 840000}
{"episode": 2524.0, "episode_reward": 7.5, "eval_time": 9.710582733154297, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 841000}
{"episode": 2527.0, "episode_reward": 8.6, "eval_time": 9.712221384048462, "mean_episode_reward": 8.6, "best_episode_reward": 10.0, "step": 842000}
{"episode": 2530.0, "episode_reward": 7.6, "eval_time": 9.55652141571045, "mean_episode_reward": 7.6, "best_episode_reward": 9.0, "step": 843000}
{"episode": 2533.0, "episode_reward": 9.4, "eval_time": 9.757015943527222, "mean_episode_reward": 9.4, "best_episode_reward": 11.0, "step": 844000}
{"episode": 2536.0, "episode_reward": 8.5, "eval_time": 9.83773922920227, "mean_episode_reward": 8.5, "best_episode_reward": 12.0, "step": 845000}
{"episode": 2539.0, "episode_reward": 7.2, "eval_time": 9.789739608764648, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 846000}
{"episode": 2542.0, "episode_reward": 7.2, "eval_time": 9.709089517593384, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 847000}
{"episode": 2545.0, "episode_reward": 7.7, "eval_time": 9.734071016311646, "mean_episode_reward": 7.7, "best_episode_reward": 9.0, "step": 848000}
{"episode": 2548.0, "episode_reward": 6.2, "eval_time": 9.807440757751465, "mean_episode_reward": 6.2, "best_episode_reward": 8.0, "step": 849000}
{"episode": 2551.0, "episode_reward": 8.4, "eval_time": 9.797217607498169, "mean_episode_reward": 8.4, "best_episode_reward": 11.0, "step": 850000}
{"episode": 2554.0, "episode_reward": 7.6, "eval_time": 9.756442308425903, "mean_episode_reward": 7.6, "best_episode_reward": 9.0, "step": 851000}
{"episode": 2557.0, "episode_reward": 7.0, "eval_time": 9.799981594085693, "mean_episode_reward": 7.0, "best_episode_reward": 10.0, "step": 852000}
{"episode": 2560.0, "episode_reward": 7.8, "eval_time": 9.713679313659668, "mean_episode_reward": 7.8, "best_episode_reward": 9.0, "step": 853000}
{"episode": 2563.0, "episode_reward": 7.9, "eval_time": 9.737627267837524, "mean_episode_reward": 7.9, "best_episode_reward": 10.0, "step": 854000}
{"episode": 2566.0, "episode_reward": 6.8, "eval_time": 9.810716152191162, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 855000}
{"episode": 2569.0, "episode_reward": 7.6, "eval_time": 9.729038953781128, "mean_episode_reward": 7.6, "best_episode_reward": 10.0, "step": 856000}
{"episode": 2572.0, "episode_reward": 8.2, "eval_time": 9.70913052558899, "mean_episode_reward": 8.2, "best_episode_reward": 10.0, "step": 857000}
{"episode": 2575.0, "episode_reward": 7.0, "eval_time": 9.818768739700317, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 858000}
{"episode": 2578.0, "episode_reward": 5.4, "eval_time": 9.857792139053345, "mean_episode_reward": 5.4, "best_episode_reward": 8.0, "step": 859000}
{"episode": 2581.0, "episode_reward": 10.3, "eval_time": 9.783156633377075, "mean_episode_reward": 10.3, "best_episode_reward": 22.0, "step": 860000}
{"episode": 2584.0, "episode_reward": 8.2, "eval_time": 9.74457049369812, "mean_episode_reward": 8.2, "best_episode_reward": 11.0, "step": 861000}
{"episode": 2587.0, "episode_reward": 7.1, "eval_time": 9.798591613769531, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 862000}
{"episode": 2590.0, "episode_reward": 6.8, "eval_time": 9.779539346694946, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 863000}
{"episode": 2593.0, "episode_reward": 8.0, "eval_time": 9.661682844161987, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 864000}
{"episode": 2596.0, "episode_reward": 9.3, "eval_time": 9.756569385528564, "mean_episode_reward": 9.3, "best_episode_reward": 18.0, "step": 865000}
{"episode": 2599.0, "episode_reward": 6.9, "eval_time": 9.818853616714478, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 866000}
{"episode": 2602.0, "episode_reward": 7.3, "eval_time": 9.734285116195679, "mean_episode_reward": 7.3, "best_episode_reward": 10.0, "step": 867000}
{"episode": 2605.0, "episode_reward": 8.0, "eval_time": 9.711843013763428, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 868000}
{"episode": 2608.0, "episode_reward": 7.2, "eval_time": 9.63759469985962, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 869000}
{"episode": 2611.0, "episode_reward": 6.8, "eval_time": 9.5783109664917, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 870000}
{"episode": 2614.0, "episode_reward": 9.5, "eval_time": 9.753356218338013, "mean_episode_reward": 9.5, "best_episode_reward": 13.0, "step": 871000}
{"episode": 2617.0, "episode_reward": 8.2, "eval_time": 9.645309686660767, "mean_episode_reward": 8.2, "best_episode_reward": 12.0, "step": 872000}
{"episode": 2620.0, "episode_reward": 4.5, "eval_time": 9.687559604644775, "mean_episode_reward": 4.5, "best_episode_reward": 7.0, "step": 873000}
{"episode": 2623.0, "episode_reward": 7.4, "eval_time": 9.686142683029175, "mean_episode_reward": 7.4, "best_episode_reward": 12.0, "step": 874000}
{"episode": 2626.0, "episode_reward": 6.9, "eval_time": 9.684726238250732, "mean_episode_reward": 6.9, "best_episode_reward": 10.0, "step": 875000}
{"episode": 2629.0, "episode_reward": 7.0, "eval_time": 9.736185073852539, "mean_episode_reward": 7.0, "best_episode_reward": 8.0, "step": 876000}
{"episode": 2632.0, "episode_reward": 7.5, "eval_time": 9.755676031112671, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 877000}
{"episode": 2635.0, "episode_reward": 5.7, "eval_time": 9.807075023651123, "mean_episode_reward": 5.7, "best_episode_reward": 9.0, "step": 878000}
{"episode": 2638.0, "episode_reward": 6.7, "eval_time": 9.74046516418457, "mean_episode_reward": 6.7, "best_episode_reward": 10.0, "step": 879000}
{"episode": 2641.0, "episode_reward": 6.8, "eval_time": 9.808485269546509, "mean_episode_reward": 6.8, "best_episode_reward": 11.0, "step": 880000}
{"episode": 2644.0, "episode_reward": 7.5, "eval_time": 9.791051149368286, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 881000}
{"episode": 2647.0, "episode_reward": 8.4, "eval_time": 9.636730909347534, "mean_episode_reward": 8.4, "best_episode_reward": 11.0, "step": 882000}
{"episode": 2650.0, "episode_reward": 7.9, "eval_time": 9.713389873504639, "mean_episode_reward": 7.9, "best_episode_reward": 9.0, "step": 883000}
{"episode": 2653.0, "episode_reward": 4.4, "eval_time": 9.735087394714355, "mean_episode_reward": 4.4, "best_episode_reward": 6.0, "step": 884000}
{"episode": 2656.0, "episode_reward": 6.9, "eval_time": 9.66102147102356, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 885000}
{"episode": 2659.0, "episode_reward": 6.5, "eval_time": 9.714749574661255, "mean_episode_reward": 6.5, "best_episode_reward": 9.0, "step": 886000}
{"episode": 2662.0, "episode_reward": 6.7, "eval_time": 9.666379928588867, "mean_episode_reward": 6.7, "best_episode_reward": 8.0, "step": 887000}
{"episode": 2665.0, "episode_reward": 8.7, "eval_time": 9.841468334197998, "mean_episode_reward": 8.7, "best_episode_reward": 14.0, "step": 888000}
{"episode": 2668.0, "episode_reward": 6.4, "eval_time": 9.760103940963745, "mean_episode_reward": 6.4, "best_episode_reward": 8.0, "step": 889000}
{"episode": 2671.0, "episode_reward": 7.5, "eval_time": 9.716186285018921, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 890000}
{"episode": 2674.0, "episode_reward": 6.3, "eval_time": 9.837010383605957, "mean_episode_reward": 6.3, "best_episode_reward": 9.0, "step": 891000}
{"episode": 2677.0, "episode_reward": 7.6, "eval_time": 9.853376388549805, "mean_episode_reward": 7.6, "best_episode_reward": 10.0, "step": 892000}
{"episode": 2680.0, "episode_reward": 8.7, "eval_time": 9.716315031051636, "mean_episode_reward": 8.7, "best_episode_reward": 11.0, "step": 893000}
{"episode": 2683.0, "episode_reward": 8.1, "eval_time": 9.76836609840393, "mean_episode_reward": 8.1, "best_episode_reward": 12.0, "step": 894000}
{"episode": 2686.0, "episode_reward": 7.6, "eval_time": 9.687255620956421, "mean_episode_reward": 7.6, "best_episode_reward": 11.0, "step": 895000}
{"episode": 2689.0, "episode_reward": 8.0, "eval_time": 9.648568153381348, "mean_episode_reward": 8.0, "best_episode_reward": 11.0, "step": 896000}
{"episode": 2692.0, "episode_reward": 7.6, "eval_time": 9.71852731704712, "mean_episode_reward": 7.6, "best_episode_reward": 10.0, "step": 897000}
{"episode": 2695.0, "episode_reward": 7.9, "eval_time": 9.720422983169556, "mean_episode_reward": 7.9, "best_episode_reward": 10.0, "step": 898000}
{"episode": 2698.0, "episode_reward": 8.0, "eval_time": 9.761322259902954, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 899000}
{"episode": 2701.0, "episode_reward": 8.1, "eval_time": 9.841813087463379, "mean_episode_reward": 8.1, "best_episode_reward": 10.0, "step": 900000}
{"episode": 2704.0, "episode_reward": 7.7, "eval_time": 9.738348484039307, "mean_episode_reward": 7.7, "best_episode_reward": 16.0, "step": 901000}
{"episode": 2707.0, "episode_reward": 8.5, "eval_time": 9.72952675819397, "mean_episode_reward": 8.5, "best_episode_reward": 17.0, "step": 902000}
{"episode": 2710.0, "episode_reward": 7.8, "eval_time": 9.729015350341797, "mean_episode_reward": 7.8, "best_episode_reward": 10.0, "step": 903000}
{"episode": 2713.0, "episode_reward": 7.5, "eval_time": 9.788784980773926, "mean_episode_reward": 7.5, "best_episode_reward": 10.0, "step": 904000}
{"episode": 2716.0, "episode_reward": 7.8, "eval_time": 9.79195261001587, "mean_episode_reward": 7.8, "best_episode_reward": 12.0, "step": 905000}
{"episode": 2719.0, "episode_reward": 9.1, "eval_time": 9.764462947845459, "mean_episode_reward": 9.1, "best_episode_reward": 12.0, "step": 906000}
{"episode": 2722.0, "episode_reward": 7.4, "eval_time": 9.771803379058838, "mean_episode_reward": 7.4, "best_episode_reward": 10.0, "step": 907000}
{"episode": 2725.0, "episode_reward": 7.6, "eval_time": 9.779287815093994, "mean_episode_reward": 7.6, "best_episode_reward": 11.0, "step": 908000}
{"episode": 2728.0, "episode_reward": 7.2, "eval_time": 9.726168155670166, "mean_episode_reward": 7.2, "best_episode_reward": 10.0, "step": 909000}
{"episode": 2731.0, "episode_reward": 7.2, "eval_time": 9.755145788192749, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 910000}
{"episode": 2734.0, "episode_reward": 8.1, "eval_time": 9.627670764923096, "mean_episode_reward": 8.1, "best_episode_reward": 10.0, "step": 911000}
{"episode": 2737.0, "episode_reward": 7.4, "eval_time": 9.677112340927124, "mean_episode_reward": 7.4, "best_episode_reward": 10.0, "step": 912000}
{"episode": 2740.0, "episode_reward": 6.8, "eval_time": 9.667219638824463, "mean_episode_reward": 6.8, "best_episode_reward": 8.0, "step": 913000}
{"episode": 2743.0, "episode_reward": 8.9, "eval_time": 9.87395715713501, "mean_episode_reward": 8.9, "best_episode_reward": 10.0, "step": 914000}
{"episode": 2746.0, "episode_reward": 6.9, "eval_time": 9.667948484420776, "mean_episode_reward": 6.9, "best_episode_reward": 9.0, "step": 915000}
{"episode": 2749.0, "episode_reward": 8.0, "eval_time": 9.779916524887085, "mean_episode_reward": 8.0, "best_episode_reward": 10.0, "step": 916000}
{"episode": 2752.0, "episode_reward": 8.4, "eval_time": 9.684101581573486, "mean_episode_reward": 8.4, "best_episode_reward": 13.0, "step": 917000}
{"episode": 2755.0, "episode_reward": 9.0, "eval_time": 9.767436742782593, "mean_episode_reward": 9.0, "best_episode_reward": 11.0, "step": 918000}
{"episode": 2758.0, "episode_reward": 8.9, "eval_time": 9.640722513198853, "mean_episode_reward": 8.9, "best_episode_reward": 13.0, "step": 919000}
{"episode": 2761.0, "episode_reward": 7.8, "eval_time": 9.699509859085083, "mean_episode_reward": 7.8, "best_episode_reward": 9.0, "step": 920000}
{"episode": 2764.0, "episode_reward": 9.4, "eval_time": 9.787404298782349, "mean_episode_reward": 9.4, "best_episode_reward": 18.0, "step": 921000}
{"episode": 2767.0, "episode_reward": 8.3, "eval_time": 9.697108745574951, "mean_episode_reward": 8.3, "best_episode_reward": 10.0, "step": 922000}
{"episode": 2770.0, "episode_reward": 8.5, "eval_time": 9.759405851364136, "mean_episode_reward": 8.5, "best_episode_reward": 11.0, "step": 923000}
{"episode": 2773.0, "episode_reward": 10.3, "eval_time": 9.816310167312622, "mean_episode_reward": 10.3, "best_episode_reward": 16.0, "step": 924000}
{"episode": 2776.0, "episode_reward": 8.1, "eval_time": 9.637779235839844, "mean_episode_reward": 8.1, "best_episode_reward": 9.0, "step": 925000}
{"episode": 2779.0, "episode_reward": 8.5, "eval_time": 9.744157552719116, "mean_episode_reward": 8.5, "best_episode_reward": 11.0, "step": 926000}
{"episode": 2782.0, "episode_reward": 9.0, "eval_time": 9.757474422454834, "mean_episode_reward": 9.0, "best_episode_reward": 14.0, "step": 927000}
{"episode": 2785.0, "episode_reward": 7.7, "eval_time": 9.792319774627686, "mean_episode_reward": 7.7, "best_episode_reward": 10.0, "step": 928000}
{"episode": 2788.0, "episode_reward": 9.3, "eval_time": 9.82756495475769, "mean_episode_reward": 9.3, "best_episode_reward": 13.0, "step": 929000}
{"episode": 2791.0, "episode_reward": 9.0, "eval_time": 9.654657363891602, "mean_episode_reward": 9.0, "best_episode_reward": 14.0, "step": 930000}
{"episode": 2794.0, "episode_reward": 9.2, "eval_time": 9.726371765136719, "mean_episode_reward": 9.2, "best_episode_reward": 17.0, "step": 931000}
{"episode": 2797.0, "episode_reward": 8.6, "eval_time": 9.755204439163208, "mean_episode_reward": 8.6, "best_episode_reward": 14.0, "step": 932000}
{"episode": 2800.0, "episode_reward": 9.6, "eval_time": 9.7087242603302, "mean_episode_reward": 9.6, "best_episode_reward": 17.0, "step": 933000}
{"episode": 2803.0, "episode_reward": 9.8, "eval_time": 9.837000846862793, "mean_episode_reward": 9.8, "best_episode_reward": 18.0, "step": 934000}
{"episode": 2806.0, "episode_reward": 7.8, "eval_time": 9.827975273132324, "mean_episode_reward": 7.8, "best_episode_reward": 11.0, "step": 935000}
{"episode": 2809.0, "episode_reward": 5.6, "eval_time": 9.788736343383789, "mean_episode_reward": 5.6, "best_episode_reward": 8.0, "step": 936000}
{"episode": 2812.0, "episode_reward": 8.4, "eval_time": 9.756393432617188, "mean_episode_reward": 8.4, "best_episode_reward": 11.0, "step": 937000}
{"episode": 2815.0, "episode_reward": 7.1, "eval_time": 9.733237266540527, "mean_episode_reward": 7.1, "best_episode_reward": 9.0, "step": 938000}
{"episode": 2818.0, "episode_reward": 8.2, "eval_time": 9.80766773223877, "mean_episode_reward": 8.2, "best_episode_reward": 9.0, "step": 939000}
{"episode": 2821.0, "episode_reward": 6.2, "eval_time": 9.882135391235352, "mean_episode_reward": 6.2, "best_episode_reward": 8.0, "step": 940000}
{"episode": 2824.0, "episode_reward": 6.7, "eval_time": 9.851555347442627, "mean_episode_reward": 6.7, "best_episode_reward": 8.0, "step": 941000}
{"episode": 2827.0, "episode_reward": 8.2, "eval_time": 9.662169456481934, "mean_episode_reward": 8.2, "best_episode_reward": 10.0, "step": 942000}
{"episode": 2830.0, "episode_reward": 8.7, "eval_time": 9.729325771331787, "mean_episode_reward": 8.7, "best_episode_reward": 10.0, "step": 943000}
{"episode": 2833.0, "episode_reward": 9.0, "eval_time": 9.81796383857727, "mean_episode_reward": 9.0, "best_episode_reward": 14.0, "step": 944000}
{"episode": 2836.0, "episode_reward": 8.8, "eval_time": 9.848607778549194, "mean_episode_reward": 8.8, "best_episode_reward": 10.0, "step": 945000}
{"episode": 2839.0, "episode_reward": 7.5, "eval_time": 9.707239866256714, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 946000}
{"episode": 2842.0, "episode_reward": 5.4, "eval_time": 9.68636155128479, "mean_episode_reward": 5.4, "best_episode_reward": 7.0, "step": 947000}
{"episode": 2845.0, "episode_reward": 6.2, "eval_time": 9.65105152130127, "mean_episode_reward": 6.2, "best_episode_reward": 8.0, "step": 948000}
{"episode": 2848.0, "episode_reward": 7.3, "eval_time": 9.824656009674072, "mean_episode_reward": 7.3, "best_episode_reward": 9.0, "step": 949000}
{"episode": 2851.0, "episode_reward": 6.0, "eval_time": 9.79554796218872, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 950000}
{"episode": 2854.0, "episode_reward": 8.5, "eval_time": 9.801807880401611, "mean_episode_reward": 8.5, "best_episode_reward": 15.0, "step": 951000}
{"episode": 2857.0, "episode_reward": 6.6, "eval_time": 9.78194260597229, "mean_episode_reward": 6.6, "best_episode_reward": 10.0, "step": 952000}
{"episode": 2860.0, "episode_reward": 7.0, "eval_time": 9.734463930130005, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 953000}
{"episode": 2863.0, "episode_reward": 8.0, "eval_time": 9.711986303329468, "mean_episode_reward": 8.0, "best_episode_reward": 15.0, "step": 954000}
{"episode": 2866.0, "episode_reward": 13.2, "eval_time": 9.847587585449219, "mean_episode_reward": 13.2, "best_episode_reward": 19.0, "step": 955000}
{"episode": 2869.0, "episode_reward": 8.0, "eval_time": 9.733871698379517, "mean_episode_reward": 8.0, "best_episode_reward": 9.0, "step": 956000}
{"episode": 2872.0, "episode_reward": 7.7, "eval_time": 9.834785461425781, "mean_episode_reward": 7.7, "best_episode_reward": 9.0, "step": 957000}
{"episode": 2875.0, "episode_reward": 8.8, "eval_time": 9.72154951095581, "mean_episode_reward": 8.8, "best_episode_reward": 10.0, "step": 958000}
{"episode": 2878.0, "episode_reward": 8.8, "eval_time": 9.71904444694519, "mean_episode_reward": 8.8, "best_episode_reward": 11.0, "step": 959000}
{"episode": 2881.0, "episode_reward": 6.0, "eval_time": 9.791099071502686, "mean_episode_reward": 6.0, "best_episode_reward": 9.0, "step": 960000}
{"episode": 2884.0, "episode_reward": 9.0, "eval_time": 9.741458177566528, "mean_episode_reward": 9.0, "best_episode_reward": 12.0, "step": 961000}
{"episode": 2887.0, "episode_reward": 8.3, "eval_time": 9.693295240402222, "mean_episode_reward": 8.3, "best_episode_reward": 10.0, "step": 962000}
{"episode": 2890.0, "episode_reward": 9.1, "eval_time": 9.782017469406128, "mean_episode_reward": 9.1, "best_episode_reward": 13.0, "step": 963000}
{"episode": 2893.0, "episode_reward": 9.6, "eval_time": 9.856133460998535, "mean_episode_reward": 9.6, "best_episode_reward": 16.0, "step": 964000}
{"episode": 2896.0, "episode_reward": 9.4, "eval_time": 9.763477802276611, "mean_episode_reward": 9.4, "best_episode_reward": 12.0, "step": 965000}
{"episode": 2899.0, "episode_reward": 9.9, "eval_time": 9.883303880691528, "mean_episode_reward": 9.9, "best_episode_reward": 17.0, "step": 966000}
{"episode": 2902.0, "episode_reward": 8.7, "eval_time": 9.69701337814331, "mean_episode_reward": 8.7, "best_episode_reward": 12.0, "step": 967000}
{"episode": 2905.0, "episode_reward": 10.1, "eval_time": 9.804736137390137, "mean_episode_reward": 10.1, "best_episode_reward": 18.0, "step": 968000}
{"episode": 2908.0, "episode_reward": 10.2, "eval_time": 9.771068811416626, "mean_episode_reward": 10.2, "best_episode_reward": 19.0, "step": 969000}
{"episode": 2911.0, "episode_reward": 7.0, "eval_time": 9.930375814437866, "mean_episode_reward": 7.0, "best_episode_reward": 9.0, "step": 970000}
{"episode": 2914.0, "episode_reward": 3.8, "eval_time": 10.039095878601074, "mean_episode_reward": 3.8, "best_episode_reward": 6.0, "step": 971000}
{"episode": 2917.0, "episode_reward": 8.8, "eval_time": 9.79146432876587, "mean_episode_reward": 8.8, "best_episode_reward": 12.0, "step": 972000}
{"episode": 2920.0, "episode_reward": 9.2, "eval_time": 9.746264934539795, "mean_episode_reward": 9.2, "best_episode_reward": 11.0, "step": 973000}
{"episode": 2923.0, "episode_reward": 8.7, "eval_time": 9.744037389755249, "mean_episode_reward": 8.7, "best_episode_reward": 10.0, "step": 974000}
{"episode": 2926.0, "episode_reward": 8.0, "eval_time": 9.816447019577026, "mean_episode_reward": 8.0, "best_episode_reward": 9.0, "step": 975000}
{"episode": 2929.0, "episode_reward": 9.9, "eval_time": 9.793707609176636, "mean_episode_reward": 9.9, "best_episode_reward": 16.0, "step": 976000}
{"episode": 2932.0, "episode_reward": 9.7, "eval_time": 9.768186569213867, "mean_episode_reward": 9.7, "best_episode_reward": 15.0, "step": 977000}
{"episode": 2935.0, "episode_reward": 9.6, "eval_time": 9.757264614105225, "mean_episode_reward": 9.6, "best_episode_reward": 12.0, "step": 978000}
{"episode": 2938.0, "episode_reward": 8.4, "eval_time": 9.754050016403198, "mean_episode_reward": 8.4, "best_episode_reward": 10.0, "step": 979000}
{"episode": 2941.0, "episode_reward": 8.6, "eval_time": 9.760038375854492, "mean_episode_reward": 8.6, "best_episode_reward": 11.0, "step": 980000}
{"episode": 2944.0, "episode_reward": 8.5, "eval_time": 9.747349500656128, "mean_episode_reward": 8.5, "best_episode_reward": 12.0, "step": 981000}
{"episode": 2947.0, "episode_reward": 8.1, "eval_time": 9.833636045455933, "mean_episode_reward": 8.1, "best_episode_reward": 10.0, "step": 982000}
{"episode": 2950.0, "episode_reward": 10.0, "eval_time": 9.819162368774414, "mean_episode_reward": 10.0, "best_episode_reward": 17.0, "step": 983000}
{"episode": 2953.0, "episode_reward": 8.6, "eval_time": 9.855217218399048, "mean_episode_reward": 8.6, "best_episode_reward": 9.0, "step": 984000}
{"episode": 2956.0, "episode_reward": 6.6, "eval_time": 9.768412828445435, "mean_episode_reward": 6.6, "best_episode_reward": 9.0, "step": 985000}
{"episode": 2959.0, "episode_reward": 6.8, "eval_time": 9.819598197937012, "mean_episode_reward": 6.8, "best_episode_reward": 9.0, "step": 986000}
{"episode": 2962.0, "episode_reward": 10.0, "eval_time": 9.868549108505249, "mean_episode_reward": 10.0, "best_episode_reward": 16.0, "step": 987000}
{"episode": 2965.0, "episode_reward": 7.7, "eval_time": 9.69893765449524, "mean_episode_reward": 7.7, "best_episode_reward": 12.0, "step": 988000}
{"episode": 2968.0, "episode_reward": 7.2, "eval_time": 9.684096336364746, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 989000}
{"episode": 2971.0, "episode_reward": 8.8, "eval_time": 9.767802476882935, "mean_episode_reward": 8.8, "best_episode_reward": 11.0, "step": 990000}
{"episode": 2974.0, "episode_reward": 7.2, "eval_time": 9.631501197814941, "mean_episode_reward": 7.2, "best_episode_reward": 9.0, "step": 991000}
{"episode": 2977.0, "episode_reward": 8.7, "eval_time": 9.727125644683838, "mean_episode_reward": 8.7, "best_episode_reward": 10.0, "step": 992000}
{"episode": 2980.0, "episode_reward": 8.4, "eval_time": 9.767328262329102, "mean_episode_reward": 8.4, "best_episode_reward": 9.0, "step": 993000}
{"episode": 2983.0, "episode_reward": 7.5, "eval_time": 9.753682613372803, "mean_episode_reward": 7.5, "best_episode_reward": 9.0, "step": 994000}
{"episode": 2986.0, "episode_reward": 10.4, "eval_time": 9.846102952957153, "mean_episode_reward": 10.4, "best_episode_reward": 16.0, "step": 995000}
{"episode": 2989.0, "episode_reward": 8.9, "eval_time": 9.80456256866455, "mean_episode_reward": 8.9, "best_episode_reward": 15.0, "step": 996000}
{"episode": 2992.0, "episode_reward": 9.7, "eval_time": 9.797274827957153, "mean_episode_reward": 9.7, "best_episode_reward": 14.0, "step": 997000}
{"episode": 2995.0, "episode_reward": 7.3, "eval_time": 9.783987760543823, "mean_episode_reward": 7.3, "best_episode_reward": 9.0, "step": 998000}
{"episode": 2998.0, "episode_reward": 9.2, "eval_time": 9.76718258857727, "mean_episode_reward": 9.2, "best_episode_reward": 14.0, "step": 999000}
