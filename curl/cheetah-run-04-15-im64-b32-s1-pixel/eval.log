{"episode": 0.0, "episode_reward": 0.0, "eval_time": 9.95158314704895, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 0}
{"episode": 4.0, "episode_reward": 0.0, "eval_time": 9.685554265975952, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 1000}
{"episode": 7.0, "episode_reward": 0.0, "eval_time": 10.170876264572144, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 2000}
{"episode": 10.0, "episode_reward": 0.0, "eval_time": 10.080480337142944, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 3000}
{"episode": 13.0, "episode_reward": 0.0, "eval_time": 10.112275838851929, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 4000}
{"episode": 16.0, "episode_reward": 0.0, "eval_time": 10.142785787582397, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 5000}
{"episode": 19.0, "episode_reward": 0.0, "eval_time": 10.15349292755127, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 6000}
{"episode": 22.0, "episode_reward": 0.0, "eval_time": 10.162685632705688, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 7000}
{"episode": 25.0, "episode_reward": 0.0, "eval_time": 10.085831880569458, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 8000}
{"episode": 28.0, "episode_reward": 0.0, "eval_time": 10.118689060211182, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 9000}
{"episode": 31.0, "episode_reward": 0.0, "eval_time": 10.084923028945923, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 10000}
{"episode": 34.0, "episode_reward": 0.0, "eval_time": 10.186012268066406, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 11000}
{"episode": 37.0, "episode_reward": 0.0, "eval_time": 10.187237739562988, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 12000}
{"episode": 40.0, "episode_reward": 0.0, "eval_time": 10.210966110229492, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 13000}
{"episode": 43.0, "episode_reward": 0.0, "eval_time": 10.078385353088379, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 14000}
{"episode": 46.0, "episode_reward": 0.0, "eval_time": 10.32383108139038, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 15000}
{"episode": 49.0, "episode_reward": 0.0, "eval_time": 10.03420352935791, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 16000}
{"episode": 52.0, "episode_reward": 0.0, "eval_time": 10.166992902755737, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 17000}
{"episode": 55.0, "episode_reward": 0.0, "eval_time": 10.123882055282593, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 18000}
{"episode": 58.0, "episode_reward": 0.0, "eval_time": 10.188313484191895, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 19000}
{"episode": 61.0, "episode_reward": 0.2, "eval_time": 10.17730975151062, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 20000}
{"episode": 64.0, "episode_reward": 0.0, "eval_time": 10.072590589523315, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 21000}
{"episode": 67.0, "episode_reward": 0.0, "eval_time": 10.135645627975464, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 22000}
{"episode": 70.0, "episode_reward": 2.1, "eval_time": 10.096270561218262, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 23000}
{"episode": 73.0, "episode_reward": 0.0, "eval_time": 10.254057884216309, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 24000}
{"episode": 76.0, "episode_reward": 1.4, "eval_time": 10.008453369140625, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 25000}
{"episode": 79.0, "episode_reward": 0.4, "eval_time": 10.152397394180298, "mean_episode_reward": 0.4, "best_episode_reward": 1.0, "step": 26000}
{"episode": 82.0, "episode_reward": 0.0, "eval_time": 10.078158378601074, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 27000}
{"episode": 85.0, "episode_reward": 0.0, "eval_time": 10.162971496582031, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 28000}
{"episode": 88.0, "episode_reward": 0.5, "eval_time": 10.17556643486023, "mean_episode_reward": 0.5, "best_episode_reward": 1.0, "step": 29000}
{"episode": 91.0, "episode_reward": 0.0, "eval_time": 10.089662313461304, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 30000}
{"episode": 94.0, "episode_reward": 0.0, "eval_time": 10.134649991989136, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 31000}
{"episode": 97.0, "episode_reward": 0.0, "eval_time": 10.178638696670532, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 32000}
{"episode": 100.0, "episode_reward": 0.0, "eval_time": 10.234139204025269, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 33000}
{"episode": 103.0, "episode_reward": -0.2, "eval_time": 10.210084676742554, "mean_episode_reward": -0.2, "best_episode_reward": 2.0, "step": 34000}
{"episode": 106.0, "episode_reward": 0.3, "eval_time": 10.073774099349976, "mean_episode_reward": 0.3, "best_episode_reward": 1.0, "step": 35000}
{"episode": 109.0, "episode_reward": 0.5, "eval_time": 10.00067663192749, "mean_episode_reward": 0.5, "best_episode_reward": 1.0, "step": 36000}
{"episode": 112.0, "episode_reward": 0.6, "eval_time": 10.24486255645752, "mean_episode_reward": 0.6, "best_episode_reward": 3.0, "step": 37000}
{"episode": 115.0, "episode_reward": 0.6, "eval_time": 10.316059827804565, "mean_episode_reward": 0.6, "best_episode_reward": 4.0, "step": 38000}
{"episode": 118.0, "episode_reward": 0.6, "eval_time": 10.706064701080322, "mean_episode_reward": 0.6, "best_episode_reward": 1.0, "step": 39000}
{"episode": 121.0, "episode_reward": 0.0, "eval_time": 10.145785331726074, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 40000}
{"episode": 124.0, "episode_reward": 0.0, "eval_time": 10.010817289352417, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 41000}
{"episode": 127.0, "episode_reward": 0.0, "eval_time": 10.195078372955322, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 42000}
{"episode": 130.0, "episode_reward": 0.0, "eval_time": 10.106706857681274, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 43000}
{"episode": 133.0, "episode_reward": 0.0, "eval_time": 10.142656564712524, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 44000}
{"episode": 136.0, "episode_reward": 0.1, "eval_time": 10.09255599975586, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 45000}
{"episode": 139.0, "episode_reward": 0.2, "eval_time": 10.104219913482666, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 46000}
{"episode": 142.0, "episode_reward": 1.5, "eval_time": 9.952676057815552, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 47000}
{"episode": 145.0, "episode_reward": 0.2, "eval_time": 10.170950174331665, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 48000}
{"episode": 148.0, "episode_reward": 1.2, "eval_time": 9.644888162612915, "mean_episode_reward": 1.2, "best_episode_reward": 5.0, "step": 49000}
{"episode": 151.0, "episode_reward": 0.9, "eval_time": 10.04649567604065, "mean_episode_reward": 0.9, "best_episode_reward": 2.0, "step": 50000}
{"episode": 154.0, "episode_reward": 0.5, "eval_time": 9.809624433517456, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 51000}
{"episode": 157.0, "episode_reward": 1.2, "eval_time": 9.964990854263306, "mean_episode_reward": 1.2, "best_episode_reward": 2.0, "step": 52000}
{"episode": 160.0, "episode_reward": 1.0, "eval_time": 10.049561738967896, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 53000}
{"episode": 163.0, "episode_reward": 0.2, "eval_time": 10.122284650802612, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 54000}
{"episode": 166.0, "episode_reward": 0.1, "eval_time": 10.204226016998291, "mean_episode_reward": 0.1, "best_episode_reward": 1.0, "step": 55000}
{"episode": 169.0, "episode_reward": -0.1, "eval_time": 10.160514116287231, "mean_episode_reward": -0.1, "best_episode_reward": 1.0, "step": 56000}
{"episode": 172.0, "episode_reward": 0.2, "eval_time": 10.100188732147217, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 57000}
{"episode": 175.0, "episode_reward": 0.8, "eval_time": 10.141574144363403, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 58000}
{"episode": 178.0, "episode_reward": 1.4, "eval_time": 9.855368614196777, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 59000}
{"episode": 181.0, "episode_reward": 0.5, "eval_time": 10.1726393699646, "mean_episode_reward": 0.5, "best_episode_reward": 1.0, "step": 60000}
{"episode": 184.0, "episode_reward": 0.8, "eval_time": 10.185213088989258, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 61000}
{"episode": 187.0, "episode_reward": 0.8, "eval_time": 10.505645990371704, "mean_episode_reward": 0.8, "best_episode_reward": 5.0, "step": 62000}
{"episode": 190.0, "episode_reward": 2.3, "eval_time": 9.844655513763428, "mean_episode_reward": 2.3, "best_episode_reward": 6.0, "step": 63000}
{"episode": 193.0, "episode_reward": 2.1, "eval_time": 9.880682706832886, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 64000}
{"episode": 196.0, "episode_reward": 0.4, "eval_time": 9.70038914680481, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 65000}
{"episode": 199.0, "episode_reward": 1.0, "eval_time": 9.952245712280273, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 66000}
{"episode": 202.0, "episode_reward": 0.3, "eval_time": 10.257007837295532, "mean_episode_reward": 0.3, "best_episode_reward": 4.0, "step": 67000}
{"episode": 205.0, "episode_reward": 0.4, "eval_time": 10.080910205841064, "mean_episode_reward": 0.4, "best_episode_reward": 4.0, "step": 68000}
{"episode": 208.0, "episode_reward": 0.6, "eval_time": 9.96912145614624, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 69000}
{"episode": 211.0, "episode_reward": 1.4, "eval_time": 10.263859987258911, "mean_episode_reward": 1.4, "best_episode_reward": 2.0, "step": 70000}
{"episode": 214.0, "episode_reward": 0.9, "eval_time": 10.177594423294067, "mean_episode_reward": 0.9, "best_episode_reward": 4.0, "step": 71000}
{"episode": 217.0, "episode_reward": 2.6, "eval_time": 10.066304206848145, "mean_episode_reward": 2.6, "best_episode_reward": 5.0, "step": 72000}
{"episode": 220.0, "episode_reward": 0.6, "eval_time": 10.151275873184204, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 73000}
{"episode": 223.0, "episode_reward": 0.0, "eval_time": 9.50706958770752, "mean_episode_reward": 0.0, "best_episode_reward": 1.0, "step": 74000}
{"episode": 226.0, "episode_reward": 0.7, "eval_time": 10.09886884689331, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 75000}
{"episode": 229.0, "episode_reward": 1.2, "eval_time": 10.011849641799927, "mean_episode_reward": 1.2, "best_episode_reward": 4.0, "step": 76000}
{"episode": 232.0, "episode_reward": 1.1, "eval_time": 9.690431118011475, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 77000}
{"episode": 235.0, "episode_reward": 1.4, "eval_time": 10.127070665359497, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 78000}
{"episode": 238.0, "episode_reward": 1.5, "eval_time": 9.556142330169678, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 79000}
{"episode": 241.0, "episode_reward": -0.3, "eval_time": 10.117869138717651, "mean_episode_reward": -0.3, "best_episode_reward": 1.0, "step": 80000}
{"episode": 244.0, "episode_reward": 1.0, "eval_time": 9.984068155288696, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 81000}
{"episode": 247.0, "episode_reward": 1.2, "eval_time": 9.962902784347534, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 82000}
{"episode": 250.0, "episode_reward": 1.7, "eval_time": 10.350204944610596, "mean_episode_reward": 1.7, "best_episode_reward": 5.0, "step": 83000}
{"episode": 253.0, "episode_reward": 0.5, "eval_time": 10.275909185409546, "mean_episode_reward": 0.5, "best_episode_reward": 3.0, "step": 84000}
{"episode": 256.0, "episode_reward": 0.7, "eval_time": 10.461035251617432, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 85000}
{"episode": 259.0, "episode_reward": 0.6, "eval_time": 9.981664896011353, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 86000}
{"episode": 262.0, "episode_reward": 0.8, "eval_time": 10.148395776748657, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 87000}
{"episode": 265.0, "episode_reward": 0.9, "eval_time": 10.193150997161865, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 88000}
{"episode": 268.0, "episode_reward": 0.8, "eval_time": 10.0250244140625, "mean_episode_reward": 0.8, "best_episode_reward": 4.0, "step": 89000}
{"episode": 271.0, "episode_reward": 1.7, "eval_time": 10.037785530090332, "mean_episode_reward": 1.7, "best_episode_reward": 5.0, "step": 90000}
{"episode": 274.0, "episode_reward": 2.2, "eval_time": 10.090362310409546, "mean_episode_reward": 2.2, "best_episode_reward": 3.0, "step": 91000}
{"episode": 277.0, "episode_reward": 0.3, "eval_time": 10.032598733901978, "mean_episode_reward": 0.3, "best_episode_reward": 2.0, "step": 92000}
{"episode": 280.0, "episode_reward": 2.5, "eval_time": 10.160737991333008, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 93000}
{"episode": 283.0, "episode_reward": 1.3, "eval_time": 10.209367036819458, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 94000}
{"episode": 286.0, "episode_reward": 2.2, "eval_time": 10.099926471710205, "mean_episode_reward": 2.2, "best_episode_reward": 5.0, "step": 95000}
{"episode": 289.0, "episode_reward": 1.4, "eval_time": 10.127837181091309, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 96000}
{"episode": 292.0, "episode_reward": 1.6, "eval_time": 10.022264003753662, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 97000}
{"episode": 295.0, "episode_reward": 1.9, "eval_time": 10.188727378845215, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 98000}
{"episode": 298.0, "episode_reward": 1.2, "eval_time": 9.98697805404663, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 99000}
{"episode": 301.0, "episode_reward": 1.8, "eval_time": 10.153073072433472, "mean_episode_reward": 1.8, "best_episode_reward": 3.0, "step": 100000}
{"episode": 304.0, "episode_reward": 1.7, "eval_time": 10.10438323020935, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 101000}
{"episode": 307.0, "episode_reward": 2.2, "eval_time": 9.979950428009033, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 102000}
{"episode": 310.0, "episode_reward": 1.8, "eval_time": 9.947450160980225, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 103000}
{"episode": 313.0, "episode_reward": 0.9, "eval_time": 10.307210445404053, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 104000}
{"episode": 316.0, "episode_reward": 1.4, "eval_time": 10.30327844619751, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 105000}
{"episode": 319.0, "episode_reward": 1.4, "eval_time": 10.216503620147705, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 106000}
{"episode": 322.0, "episode_reward": 0.6, "eval_time": 10.580631256103516, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 107000}
{"episode": 325.0, "episode_reward": 1.7, "eval_time": 10.21814751625061, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 108000}
{"episode": 328.0, "episode_reward": 0.2, "eval_time": 10.555172681808472, "mean_episode_reward": 0.2, "best_episode_reward": 2.0, "step": 109000}
{"episode": 331.0, "episode_reward": 0.8, "eval_time": 10.398853778839111, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 110000}
{"episode": 334.0, "episode_reward": 0.4, "eval_time": 10.689221382141113, "mean_episode_reward": 0.4, "best_episode_reward": 1.0, "step": 111000}
{"episode": 337.0, "episode_reward": 1.2, "eval_time": 10.251193761825562, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 112000}
{"episode": 340.0, "episode_reward": 0.4, "eval_time": 10.085724830627441, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 113000}
{"episode": 343.0, "episode_reward": 0.6, "eval_time": 10.521488189697266, "mean_episode_reward": 0.6, "best_episode_reward": 1.0, "step": 114000}
{"episode": 346.0, "episode_reward": 1.2, "eval_time": 10.185658931732178, "mean_episode_reward": 1.2, "best_episode_reward": 5.0, "step": 115000}
{"episode": 349.0, "episode_reward": 0.4, "eval_time": 10.328761577606201, "mean_episode_reward": 0.4, "best_episode_reward": 3.0, "step": 116000}
{"episode": 352.0, "episode_reward": 1.7, "eval_time": 9.942888021469116, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 117000}
{"episode": 355.0, "episode_reward": 1.2, "eval_time": 10.393748998641968, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 118000}
{"episode": 358.0, "episode_reward": 1.2, "eval_time": 10.347650527954102, "mean_episode_reward": 1.2, "best_episode_reward": 2.0, "step": 119000}
{"episode": 361.0, "episode_reward": 0.5, "eval_time": 10.20895504951477, "mean_episode_reward": 0.5, "best_episode_reward": 3.0, "step": 120000}
{"episode": 364.0, "episode_reward": 0.0, "eval_time": 10.425060749053955, "mean_episode_reward": 0.0, "best_episode_reward": 2.0, "step": 121000}
{"episode": 367.0, "episode_reward": 1.6, "eval_time": 10.008958339691162, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 122000}
{"episode": 370.0, "episode_reward": 1.4, "eval_time": 10.124197244644165, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 123000}
{"episode": 373.0, "episode_reward": 1.2, "eval_time": 10.177618265151978, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 124000}
{"episode": 376.0, "episode_reward": 0.2, "eval_time": 10.327980041503906, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 125000}
{"episode": 379.0, "episode_reward": 0.3, "eval_time": 10.530693531036377, "mean_episode_reward": 0.3, "best_episode_reward": 1.0, "step": 126000}
{"episode": 382.0, "episode_reward": 0.9, "eval_time": 10.368114233016968, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 127000}
{"episode": 385.0, "episode_reward": 1.1, "eval_time": 10.217025756835938, "mean_episode_reward": 1.1, "best_episode_reward": 5.0, "step": 128000}
{"episode": 388.0, "episode_reward": 1.1, "eval_time": 10.355594396591187, "mean_episode_reward": 1.1, "best_episode_reward": 2.0, "step": 129000}
{"episode": 391.0, "episode_reward": 1.2, "eval_time": 10.222322225570679, "mean_episode_reward": 1.2, "best_episode_reward": 5.0, "step": 130000}
{"episode": 394.0, "episode_reward": 1.7, "eval_time": 10.101720809936523, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 131000}
{"episode": 397.0, "episode_reward": 1.0, "eval_time": 10.108329772949219, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 132000}
{"episode": 400.0, "episode_reward": 0.9, "eval_time": 9.998170614242554, "mean_episode_reward": 0.9, "best_episode_reward": 2.0, "step": 133000}
{"episode": 403.0, "episode_reward": 1.2, "eval_time": 9.9719398021698, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 134000}
{"episode": 406.0, "episode_reward": 0.6, "eval_time": 10.145657539367676, "mean_episode_reward": 0.6, "best_episode_reward": 3.0, "step": 135000}
{"episode": 409.0, "episode_reward": 0.9, "eval_time": 10.028770446777344, "mean_episode_reward": 0.9, "best_episode_reward": 4.0, "step": 136000}
{"episode": 412.0, "episode_reward": 0.9, "eval_time": 9.984727382659912, "mean_episode_reward": 0.9, "best_episode_reward": 5.0, "step": 137000}
{"episode": 415.0, "episode_reward": 2.1, "eval_time": 10.09817624092102, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 138000}
{"episode": 418.0, "episode_reward": 1.2, "eval_time": 10.183666944503784, "mean_episode_reward": 1.2, "best_episode_reward": 4.0, "step": 139000}
{"episode": 421.0, "episode_reward": 1.6, "eval_time": 10.099972486495972, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 140000}
{"episode": 424.0, "episode_reward": 1.3, "eval_time": 10.146522283554077, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 141000}
{"episode": 427.0, "episode_reward": 0.6, "eval_time": 10.129479885101318, "mean_episode_reward": 0.6, "best_episode_reward": 4.0, "step": 142000}
{"episode": 430.0, "episode_reward": 1.5, "eval_time": 10.313415765762329, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 143000}
{"episode": 433.0, "episode_reward": 1.3, "eval_time": 10.20197081565857, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 144000}
{"episode": 436.0, "episode_reward": 1.3, "eval_time": 10.190827369689941, "mean_episode_reward": 1.3, "best_episode_reward": 5.0, "step": 145000}
{"episode": 439.0, "episode_reward": 1.9, "eval_time": 10.153114080429077, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 146000}
{"episode": 442.0, "episode_reward": 0.5, "eval_time": 10.115118980407715, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 147000}
{"episode": 445.0, "episode_reward": 1.2, "eval_time": 10.234375715255737, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 148000}
{"episode": 448.0, "episode_reward": 2.5, "eval_time": 10.038189172744751, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 149000}
{"episode": 451.0, "episode_reward": 2.3, "eval_time": 10.085274934768677, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 150000}
{"episode": 454.0, "episode_reward": 0.7, "eval_time": 10.314978122711182, "mean_episode_reward": 0.7, "best_episode_reward": 3.0, "step": 151000}
{"episode": 457.0, "episode_reward": 2.1, "eval_time": 10.061070680618286, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 152000}
{"episode": 460.0, "episode_reward": 1.9, "eval_time": 10.303141117095947, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 153000}
{"episode": 463.0, "episode_reward": 1.6, "eval_time": 10.058482646942139, "mean_episode_reward": 1.6, "best_episode_reward": 5.0, "step": 154000}
{"episode": 466.0, "episode_reward": 1.9, "eval_time": 9.973952770233154, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 155000}
{"episode": 469.0, "episode_reward": 1.9, "eval_time": 9.975716590881348, "mean_episode_reward": 1.9, "best_episode_reward": 6.0, "step": 156000}
{"episode": 472.0, "episode_reward": 0.9, "eval_time": 10.257826805114746, "mean_episode_reward": 0.9, "best_episode_reward": 2.0, "step": 157000}
{"episode": 475.0, "episode_reward": 1.5, "eval_time": 10.027470588684082, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 158000}
{"episode": 478.0, "episode_reward": 2.4, "eval_time": 9.82795763015747, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 159000}
{"episode": 481.0, "episode_reward": 0.8, "eval_time": 10.070977449417114, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 160000}
{"episode": 484.0, "episode_reward": 2.4, "eval_time": 9.960798740386963, "mean_episode_reward": 2.4, "best_episode_reward": 6.0, "step": 161000}
{"episode": 487.0, "episode_reward": 1.1, "eval_time": 9.91016435623169, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 162000}
{"episode": 490.0, "episode_reward": 2.4, "eval_time": 9.948663234710693, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 163000}
{"episode": 493.0, "episode_reward": 1.7, "eval_time": 10.058105707168579, "mean_episode_reward": 1.7, "best_episode_reward": 5.0, "step": 164000}
{"episode": 496.0, "episode_reward": 1.0, "eval_time": 10.182945966720581, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 165000}
{"episode": 499.0, "episode_reward": 1.9, "eval_time": 10.030107736587524, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 166000}
{"episode": 502.0, "episode_reward": 2.4, "eval_time": 10.239782333374023, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 167000}
{"episode": 505.0, "episode_reward": 0.9, "eval_time": 10.066993236541748, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 168000}
{"episode": 508.0, "episode_reward": 1.3, "eval_time": 10.044799327850342, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 169000}
{"episode": 511.0, "episode_reward": 3.1, "eval_time": 9.889734029769897, "mean_episode_reward": 3.1, "best_episode_reward": 5.0, "step": 170000}
{"episode": 514.0, "episode_reward": 1.1, "eval_time": 9.997362852096558, "mean_episode_reward": 1.1, "best_episode_reward": 5.0, "step": 171000}
{"episode": 517.0, "episode_reward": 1.1, "eval_time": 10.113703966140747, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 172000}
{"episode": 520.0, "episode_reward": 2.0, "eval_time": 9.90879225730896, "mean_episode_reward": 2.0, "best_episode_reward": 4.0, "step": 173000}
{"episode": 523.0, "episode_reward": 2.4, "eval_time": 9.820520401000977, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 174000}
{"episode": 526.0, "episode_reward": 1.7, "eval_time": 10.12649154663086, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 175000}
{"episode": 529.0, "episode_reward": 1.1, "eval_time": 10.16547179222107, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 176000}
{"episode": 532.0, "episode_reward": 1.8, "eval_time": 10.067937850952148, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 177000}
{"episode": 535.0, "episode_reward": 0.9, "eval_time": 10.208906173706055, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 178000}
{"episode": 538.0, "episode_reward": 0.7, "eval_time": 11.221611022949219, "mean_episode_reward": 0.7, "best_episode_reward": 3.0, "step": 179000}
{"episode": 541.0, "episode_reward": 1.5, "eval_time": 10.004081964492798, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 180000}
{"episode": 544.0, "episode_reward": 0.8, "eval_time": 10.426440477371216, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 181000}
{"episode": 547.0, "episode_reward": 1.2, "eval_time": 9.99276876449585, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 182000}
{"episode": 550.0, "episode_reward": 1.5, "eval_time": 10.172753810882568, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 183000}
{"episode": 553.0, "episode_reward": 0.4, "eval_time": 10.215348720550537, "mean_episode_reward": 0.4, "best_episode_reward": 3.0, "step": 184000}
{"episode": 556.0, "episode_reward": 1.0, "eval_time": 9.671134948730469, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 185000}
{"episode": 559.0, "episode_reward": 1.1, "eval_time": 10.56895112991333, "mean_episode_reward": 1.1, "best_episode_reward": 2.0, "step": 186000}
{"episode": 562.0, "episode_reward": 1.5, "eval_time": 10.287351369857788, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 187000}
{"episode": 565.0, "episode_reward": 1.6, "eval_time": 10.226469039916992, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 188000}
{"episode": 568.0, "episode_reward": 1.0, "eval_time": 9.95957612991333, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 189000}
{"episode": 571.0, "episode_reward": 1.0, "eval_time": 9.963486433029175, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 190000}
{"episode": 574.0, "episode_reward": 0.9, "eval_time": 10.790958642959595, "mean_episode_reward": 0.9, "best_episode_reward": 2.0, "step": 191000}
{"episode": 577.0, "episode_reward": 1.6, "eval_time": 10.65501093864441, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 192000}
{"episode": 580.0, "episode_reward": 0.4, "eval_time": 9.98047947883606, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 193000}
{"episode": 583.0, "episode_reward": 0.7, "eval_time": 10.53917932510376, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 194000}
{"episode": 586.0, "episode_reward": 1.6, "eval_time": 10.515860080718994, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 195000}
{"episode": 589.0, "episode_reward": 2.1, "eval_time": 10.270980834960938, "mean_episode_reward": 2.1, "best_episode_reward": 3.0, "step": 196000}
{"episode": 592.0, "episode_reward": 1.0, "eval_time": 10.516339302062988, "mean_episode_reward": 1.0, "best_episode_reward": 4.0, "step": 197000}
{"episode": 595.0, "episode_reward": 0.5, "eval_time": 10.538594245910645, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 198000}
{"episode": 598.0, "episode_reward": 0.3, "eval_time": 10.242470026016235, "mean_episode_reward": 0.3, "best_episode_reward": 2.0, "step": 199000}
{"episode": 601.0, "episode_reward": 0.9, "eval_time": 10.908991575241089, "mean_episode_reward": 0.9, "best_episode_reward": 4.0, "step": 200000}
{"episode": 604.0, "episode_reward": 1.3, "eval_time": 10.30657696723938, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 201000}
{"episode": 607.0, "episode_reward": 0.7, "eval_time": 10.701869010925293, "mean_episode_reward": 0.7, "best_episode_reward": 4.0, "step": 202000}
{"episode": 610.0, "episode_reward": 0.8, "eval_time": 10.718194723129272, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 203000}
{"episode": 613.0, "episode_reward": 1.6, "eval_time": 10.25802731513977, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 204000}
{"episode": 616.0, "episode_reward": 1.1, "eval_time": 10.317493915557861, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 205000}
{"episode": 619.0, "episode_reward": 2.0, "eval_time": 9.970446348190308, "mean_episode_reward": 2.0, "best_episode_reward": 4.0, "step": 206000}
{"episode": 622.0, "episode_reward": 1.0, "eval_time": 10.502137184143066, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 207000}
{"episode": 625.0, "episode_reward": 3.2, "eval_time": 10.002714395523071, "mean_episode_reward": 3.2, "best_episode_reward": 5.0, "step": 208000}
{"episode": 628.0, "episode_reward": 0.5, "eval_time": 10.219765424728394, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 209000}
{"episode": 631.0, "episode_reward": 2.1, "eval_time": 9.630719184875488, "mean_episode_reward": 2.1, "best_episode_reward": 7.0, "step": 210000}
{"episode": 634.0, "episode_reward": 0.6, "eval_time": 10.123491287231445, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 211000}
{"episode": 637.0, "episode_reward": 1.2, "eval_time": 10.320988893508911, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 212000}
{"episode": 640.0, "episode_reward": 0.5, "eval_time": 9.852758169174194, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 213000}
{"episode": 643.0, "episode_reward": 0.3, "eval_time": 10.080548286437988, "mean_episode_reward": 0.3, "best_episode_reward": 2.0, "step": 214000}
{"episode": 646.0, "episode_reward": 0.2, "eval_time": 10.255113124847412, "mean_episode_reward": 0.2, "best_episode_reward": 2.0, "step": 215000}
{"episode": 649.0, "episode_reward": 1.1, "eval_time": 10.08989691734314, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 216000}
{"episode": 652.0, "episode_reward": 0.2, "eval_time": 10.42160964012146, "mean_episode_reward": 0.2, "best_episode_reward": 2.0, "step": 217000}
{"episode": 655.0, "episode_reward": 1.3, "eval_time": 10.264872789382935, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 218000}
{"episode": 658.0, "episode_reward": 0.4, "eval_time": 10.304986476898193, "mean_episode_reward": 0.4, "best_episode_reward": 2.0, "step": 219000}
{"episode": 661.0, "episode_reward": 1.2, "eval_time": 10.000087261199951, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 220000}
{"episode": 664.0, "episode_reward": 0.5, "eval_time": 10.001174688339233, "mean_episode_reward": 0.5, "best_episode_reward": 1.0, "step": 221000}
{"episode": 667.0, "episode_reward": 1.3, "eval_time": 9.968032121658325, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 222000}
{"episode": 670.0, "episode_reward": 0.7, "eval_time": 9.939181327819824, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 223000}
{"episode": 673.0, "episode_reward": 1.5, "eval_time": 10.053176403045654, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 224000}
{"episode": 676.0, "episode_reward": 1.6, "eval_time": 10.061372756958008, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 225000}
{"episode": 679.0, "episode_reward": 1.9, "eval_time": 10.046043395996094, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 226000}
{"episode": 682.0, "episode_reward": 3.1, "eval_time": 9.992831230163574, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 227000}
{"episode": 685.0, "episode_reward": 2.2, "eval_time": 9.97488260269165, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 228000}
{"episode": 688.0, "episode_reward": 1.2, "eval_time": 10.000122547149658, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 229000}
{"episode": 691.0, "episode_reward": 3.0, "eval_time": 10.043062448501587, "mean_episode_reward": 3.0, "best_episode_reward": 5.0, "step": 230000}
{"episode": 694.0, "episode_reward": 2.4, "eval_time": 10.101266145706177, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 231000}
{"episode": 697.0, "episode_reward": 2.4, "eval_time": 10.021684169769287, "mean_episode_reward": 2.4, "best_episode_reward": 7.0, "step": 232000}
{"episode": 700.0, "episode_reward": 2.8, "eval_time": 9.917918682098389, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 233000}
{"episode": 703.0, "episode_reward": 2.5, "eval_time": 10.071115493774414, "mean_episode_reward": 2.5, "best_episode_reward": 4.0, "step": 234000}
{"episode": 706.0, "episode_reward": 1.6, "eval_time": 10.017098903656006, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 235000}
{"episode": 709.0, "episode_reward": 2.4, "eval_time": 10.03175663948059, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 236000}
{"episode": 712.0, "episode_reward": 3.3, "eval_time": 9.958200931549072, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 237000}
{"episode": 715.0, "episode_reward": 4.3, "eval_time": 9.849984884262085, "mean_episode_reward": 4.3, "best_episode_reward": 7.0, "step": 238000}
{"episode": 718.0, "episode_reward": 3.2, "eval_time": 10.090738296508789, "mean_episode_reward": 3.2, "best_episode_reward": 7.0, "step": 239000}
{"episode": 721.0, "episode_reward": 2.7, "eval_time": 9.913679838180542, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 240000}
{"episode": 724.0, "episode_reward": 1.1, "eval_time": 10.137012481689453, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 241000}
{"episode": 727.0, "episode_reward": 4.3, "eval_time": 9.97468614578247, "mean_episode_reward": 4.3, "best_episode_reward": 7.0, "step": 242000}
{"episode": 730.0, "episode_reward": 4.4, "eval_time": 9.907081604003906, "mean_episode_reward": 4.4, "best_episode_reward": 8.0, "step": 243000}
{"episode": 733.0, "episode_reward": 3.3, "eval_time": 9.814135313034058, "mean_episode_reward": 3.3, "best_episode_reward": 7.0, "step": 244000}
{"episode": 736.0, "episode_reward": 2.8, "eval_time": 9.86378288269043, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 245000}
{"episode": 739.0, "episode_reward": 4.2, "eval_time": 9.86103892326355, "mean_episode_reward": 4.2, "best_episode_reward": 7.0, "step": 246000}
{"episode": 742.0, "episode_reward": 4.5, "eval_time": 9.889600992202759, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 247000}
{"episode": 745.0, "episode_reward": 4.8, "eval_time": 9.7765371799469, "mean_episode_reward": 4.8, "best_episode_reward": 8.0, "step": 248000}
{"episode": 748.0, "episode_reward": 4.8, "eval_time": 9.886497020721436, "mean_episode_reward": 4.8, "best_episode_reward": 8.0, "step": 249000}
{"episode": 751.0, "episode_reward": 4.0, "eval_time": 9.815326690673828, "mean_episode_reward": 4.0, "best_episode_reward": 7.0, "step": 250000}
{"episode": 754.0, "episode_reward": 3.7, "eval_time": 9.925004243850708, "mean_episode_reward": 3.7, "best_episode_reward": 5.0, "step": 251000}
{"episode": 757.0, "episode_reward": 5.1, "eval_time": 9.836487293243408, "mean_episode_reward": 5.1, "best_episode_reward": 7.0, "step": 252000}
{"episode": 760.0, "episode_reward": 3.0, "eval_time": 9.915518760681152, "mean_episode_reward": 3.0, "best_episode_reward": 6.0, "step": 253000}
{"episode": 763.0, "episode_reward": 4.4, "eval_time": 9.663348913192749, "mean_episode_reward": 4.4, "best_episode_reward": 8.0, "step": 254000}
{"episode": 766.0, "episode_reward": 2.7, "eval_time": 10.013790607452393, "mean_episode_reward": 2.7, "best_episode_reward": 6.0, "step": 255000}
{"episode": 769.0, "episode_reward": 3.7, "eval_time": 9.854647874832153, "mean_episode_reward": 3.7, "best_episode_reward": 8.0, "step": 256000}
{"episode": 772.0, "episode_reward": 0.9, "eval_time": 10.019397020339966, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 257000}
{"episode": 775.0, "episode_reward": 4.7, "eval_time": 9.82877516746521, "mean_episode_reward": 4.7, "best_episode_reward": 9.0, "step": 258000}
{"episode": 778.0, "episode_reward": 3.2, "eval_time": 9.963377237319946, "mean_episode_reward": 3.2, "best_episode_reward": 5.0, "step": 259000}
{"episode": 781.0, "episode_reward": 2.3, "eval_time": 9.902618408203125, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 260000}
{"episode": 784.0, "episode_reward": 2.2, "eval_time": 9.979592561721802, "mean_episode_reward": 2.2, "best_episode_reward": 5.0, "step": 261000}
{"episode": 787.0, "episode_reward": 1.3, "eval_time": 9.839048862457275, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 262000}
{"episode": 790.0, "episode_reward": 3.1, "eval_time": 9.615128517150879, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 263000}
{"episode": 793.0, "episode_reward": 3.4, "eval_time": 9.575209140777588, "mean_episode_reward": 3.4, "best_episode_reward": 7.0, "step": 264000}
{"episode": 796.0, "episode_reward": 1.4, "eval_time": 9.86619520187378, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 265000}
{"episode": 799.0, "episode_reward": 2.7, "eval_time": 9.880539417266846, "mean_episode_reward": 2.7, "best_episode_reward": 6.0, "step": 266000}
{"episode": 802.0, "episode_reward": 3.2, "eval_time": 9.832737445831299, "mean_episode_reward": 3.2, "best_episode_reward": 5.0, "step": 267000}
{"episode": 805.0, "episode_reward": 1.5, "eval_time": 9.969316005706787, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 268000}
{"episode": 808.0, "episode_reward": 1.6, "eval_time": 9.910526275634766, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 269000}
{"episode": 811.0, "episode_reward": 2.1, "eval_time": 9.920697212219238, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 270000}
{"episode": 814.0, "episode_reward": 1.3, "eval_time": 10.111484050750732, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 271000}
{"episode": 817.0, "episode_reward": 3.4, "eval_time": 9.811991453170776, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 272000}
{"episode": 820.0, "episode_reward": 1.3, "eval_time": 9.952753782272339, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 273000}
{"episode": 823.0, "episode_reward": 2.3, "eval_time": 9.880599021911621, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 274000}
{"episode": 826.0, "episode_reward": 3.5, "eval_time": 9.821857929229736, "mean_episode_reward": 3.5, "best_episode_reward": 6.0, "step": 275000}
{"episode": 829.0, "episode_reward": 1.8, "eval_time": 10.127945184707642, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 276000}
{"episode": 832.0, "episode_reward": 3.4, "eval_time": 9.843841791152954, "mean_episode_reward": 3.4, "best_episode_reward": 7.0, "step": 277000}
{"episode": 835.0, "episode_reward": 1.8, "eval_time": 9.83812689781189, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 278000}
{"episode": 838.0, "episode_reward": 2.5, "eval_time": 9.876262664794922, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 279000}
{"episode": 841.0, "episode_reward": 1.6, "eval_time": 9.872404098510742, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 280000}
{"episode": 844.0, "episode_reward": 2.6, "eval_time": 9.893489122390747, "mean_episode_reward": 2.6, "best_episode_reward": 5.0, "step": 281000}
{"episode": 847.0, "episode_reward": 3.1, "eval_time": 9.714472770690918, "mean_episode_reward": 3.1, "best_episode_reward": 7.0, "step": 282000}
{"episode": 850.0, "episode_reward": 3.7, "eval_time": 9.850811243057251, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 283000}
{"episode": 853.0, "episode_reward": 1.9, "eval_time": 9.866791248321533, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 284000}
{"episode": 856.0, "episode_reward": 2.1, "eval_time": 9.865382432937622, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 285000}
{"episode": 859.0, "episode_reward": 3.0, "eval_time": 9.819006443023682, "mean_episode_reward": 3.0, "best_episode_reward": 6.0, "step": 286000}
{"episode": 862.0, "episode_reward": 3.4, "eval_time": 9.818536043167114, "mean_episode_reward": 3.4, "best_episode_reward": 6.0, "step": 287000}
{"episode": 865.0, "episode_reward": 4.2, "eval_time": 9.863837003707886, "mean_episode_reward": 4.2, "best_episode_reward": 5.0, "step": 288000}
{"episode": 868.0, "episode_reward": 1.6, "eval_time": 9.905572414398193, "mean_episode_reward": 1.6, "best_episode_reward": 6.0, "step": 289000}
{"episode": 871.0, "episode_reward": 4.4, "eval_time": 9.897635221481323, "mean_episode_reward": 4.4, "best_episode_reward": 7.0, "step": 290000}
{"episode": 874.0, "episode_reward": 4.9, "eval_time": 9.773846626281738, "mean_episode_reward": 4.9, "best_episode_reward": 7.0, "step": 291000}
{"episode": 877.0, "episode_reward": 4.1, "eval_time": 9.787517309188843, "mean_episode_reward": 4.1, "best_episode_reward": 6.0, "step": 292000}
{"episode": 880.0, "episode_reward": 3.6, "eval_time": 9.770994424819946, "mean_episode_reward": 3.6, "best_episode_reward": 8.0, "step": 293000}
{"episode": 883.0, "episode_reward": 3.6, "eval_time": 9.8492431640625, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 294000}
{"episode": 886.0, "episode_reward": 1.5, "eval_time": 9.752804279327393, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 295000}
{"episode": 889.0, "episode_reward": 3.6, "eval_time": 9.787428140640259, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 296000}
{"episode": 892.0, "episode_reward": 0.6, "eval_time": 9.856504917144775, "mean_episode_reward": 0.6, "best_episode_reward": 3.0, "step": 297000}
{"episode": 895.0, "episode_reward": 1.8, "eval_time": 9.715770244598389, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 298000}
{"episode": 898.0, "episode_reward": 2.4, "eval_time": 9.887720346450806, "mean_episode_reward": 2.4, "best_episode_reward": 7.0, "step": 299000}
{"episode": 901.0, "episode_reward": 3.9, "eval_time": 9.839906930923462, "mean_episode_reward": 3.9, "best_episode_reward": 7.0, "step": 300000}
{"episode": 904.0, "episode_reward": 5.0, "eval_time": 9.822523832321167, "mean_episode_reward": 5.0, "best_episode_reward": 9.0, "step": 301000}
{"episode": 907.0, "episode_reward": 5.4, "eval_time": 9.670790433883667, "mean_episode_reward": 5.4, "best_episode_reward": 7.0, "step": 302000}
{"episode": 910.0, "episode_reward": 4.8, "eval_time": 9.779976844787598, "mean_episode_reward": 4.8, "best_episode_reward": 8.0, "step": 303000}
{"episode": 913.0, "episode_reward": 4.0, "eval_time": 9.82940673828125, "mean_episode_reward": 4.0, "best_episode_reward": 7.0, "step": 304000}
{"episode": 916.0, "episode_reward": 2.2, "eval_time": 10.112054824829102, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 305000}
{"episode": 919.0, "episode_reward": 1.2, "eval_time": 10.147155046463013, "mean_episode_reward": 1.2, "best_episode_reward": 2.0, "step": 306000}
{"episode": 922.0, "episode_reward": 1.7, "eval_time": 10.165233850479126, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 307000}
{"episode": 925.0, "episode_reward": 1.5, "eval_time": 10.001067876815796, "mean_episode_reward": 1.5, "best_episode_reward": 5.0, "step": 308000}
{"episode": 928.0, "episode_reward": 4.7, "eval_time": 9.682413339614868, "mean_episode_reward": 4.7, "best_episode_reward": 6.0, "step": 309000}
{"episode": 931.0, "episode_reward": 3.0, "eval_time": 9.781189680099487, "mean_episode_reward": 3.0, "best_episode_reward": 6.0, "step": 310000}
{"episode": 934.0, "episode_reward": 1.4, "eval_time": 9.930134296417236, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 311000}
{"episode": 937.0, "episode_reward": 1.4, "eval_time": 10.06065559387207, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 312000}
{"episode": 940.0, "episode_reward": 1.1, "eval_time": 9.71952772140503, "mean_episode_reward": 1.1, "best_episode_reward": 5.0, "step": 313000}
{"episode": 943.0, "episode_reward": 2.5, "eval_time": 9.929710626602173, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 314000}
{"episode": 946.0, "episode_reward": 2.6, "eval_time": 9.750609874725342, "mean_episode_reward": 2.6, "best_episode_reward": 7.0, "step": 315000}
{"episode": 949.0, "episode_reward": 1.2, "eval_time": 9.925271034240723, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 316000}
{"episode": 952.0, "episode_reward": 2.9, "eval_time": 9.907438039779663, "mean_episode_reward": 2.9, "best_episode_reward": 4.0, "step": 317000}
{"episode": 955.0, "episode_reward": 1.4, "eval_time": 9.777883768081665, "mean_episode_reward": 1.4, "best_episode_reward": 4.0, "step": 318000}
{"episode": 958.0, "episode_reward": 2.6, "eval_time": 9.876108884811401, "mean_episode_reward": 2.6, "best_episode_reward": 6.0, "step": 319000}
{"episode": 961.0, "episode_reward": 1.9, "eval_time": 9.879918336868286, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 320000}
{"episode": 964.0, "episode_reward": 2.4, "eval_time": 10.02941083908081, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 321000}
{"episode": 967.0, "episode_reward": 1.4, "eval_time": 9.94157600402832, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 322000}
{"episode": 970.0, "episode_reward": 2.1, "eval_time": 9.918481349945068, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 323000}
{"episode": 973.0, "episode_reward": 3.3, "eval_time": 9.806891918182373, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 324000}
{"episode": 976.0, "episode_reward": 2.9, "eval_time": 9.90546178817749, "mean_episode_reward": 2.9, "best_episode_reward": 7.0, "step": 325000}
{"episode": 979.0, "episode_reward": 0.2, "eval_time": 10.05798602104187, "mean_episode_reward": 0.2, "best_episode_reward": 3.0, "step": 326000}
{"episode": 982.0, "episode_reward": 2.0, "eval_time": 9.956557989120483, "mean_episode_reward": 2.0, "best_episode_reward": 3.0, "step": 327000}
{"episode": 985.0, "episode_reward": 4.0, "eval_time": 9.853959798812866, "mean_episode_reward": 4.0, "best_episode_reward": 8.0, "step": 328000}
{"episode": 988.0, "episode_reward": 2.3, "eval_time": 9.93926477432251, "mean_episode_reward": 2.3, "best_episode_reward": 7.0, "step": 329000}
{"episode": 991.0, "episode_reward": 3.1, "eval_time": 9.98534631729126, "mean_episode_reward": 3.1, "best_episode_reward": 7.0, "step": 330000}
{"episode": 994.0, "episode_reward": 2.2, "eval_time": 9.878795623779297, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 331000}
{"episode": 997.0, "episode_reward": 3.0, "eval_time": 9.971287250518799, "mean_episode_reward": 3.0, "best_episode_reward": 5.0, "step": 332000}
{"episode": 1000.0, "episode_reward": 5.5, "eval_time": 9.89356017112732, "mean_episode_reward": 5.5, "best_episode_reward": 9.0, "step": 333000}
{"episode": 1003.0, "episode_reward": 2.5, "eval_time": 9.847933769226074, "mean_episode_reward": 2.5, "best_episode_reward": 7.0, "step": 334000}
{"episode": 1006.0, "episode_reward": 3.9, "eval_time": 9.881520986557007, "mean_episode_reward": 3.9, "best_episode_reward": 6.0, "step": 335000}
{"episode": 1009.0, "episode_reward": 2.0, "eval_time": 9.952382802963257, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 336000}
{"episode": 1012.0, "episode_reward": 3.4, "eval_time": 10.01233196258545, "mean_episode_reward": 3.4, "best_episode_reward": 6.0, "step": 337000}
{"episode": 1015.0, "episode_reward": 2.3, "eval_time": 9.909636974334717, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 338000}
{"episode": 1018.0, "episode_reward": 4.1, "eval_time": 9.888956546783447, "mean_episode_reward": 4.1, "best_episode_reward": 6.0, "step": 339000}
{"episode": 1021.0, "episode_reward": 2.7, "eval_time": 9.787086725234985, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 340000}
{"episode": 1024.0, "episode_reward": 2.7, "eval_time": 9.698043823242188, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 341000}
{"episode": 1027.0, "episode_reward": 2.3, "eval_time": 9.876739740371704, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 342000}
{"episode": 1030.0, "episode_reward": 2.9, "eval_time": 9.784392356872559, "mean_episode_reward": 2.9, "best_episode_reward": 5.0, "step": 343000}
{"episode": 1033.0, "episode_reward": 2.1, "eval_time": 9.821709632873535, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 344000}
{"episode": 1036.0, "episode_reward": 2.8, "eval_time": 9.806315660476685, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 345000}
{"episode": 1039.0, "episode_reward": 2.3, "eval_time": 9.694412469863892, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 346000}
{"episode": 1042.0, "episode_reward": 2.9, "eval_time": 9.820854902267456, "mean_episode_reward": 2.9, "best_episode_reward": 5.0, "step": 347000}
{"episode": 1045.0, "episode_reward": 3.5, "eval_time": 9.820913553237915, "mean_episode_reward": 3.5, "best_episode_reward": 7.0, "step": 348000}
{"episode": 1048.0, "episode_reward": 3.1, "eval_time": 9.888083696365356, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 349000}
{"episode": 1051.0, "episode_reward": 1.6, "eval_time": 9.893446683883667, "mean_episode_reward": 1.6, "best_episode_reward": 5.0, "step": 350000}
{"episode": 1054.0, "episode_reward": 2.8, "eval_time": 9.761651039123535, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 351000}
{"episode": 1057.0, "episode_reward": 2.7, "eval_time": 9.732303619384766, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 352000}
{"episode": 1060.0, "episode_reward": 2.0, "eval_time": 9.868134021759033, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 353000}
{"episode": 1063.0, "episode_reward": 2.4, "eval_time": 9.66046929359436, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 354000}
{"episode": 1066.0, "episode_reward": 1.6, "eval_time": 10.070005893707275, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 355000}
{"episode": 1069.0, "episode_reward": 4.5, "eval_time": 9.797188520431519, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 356000}
{"episode": 1072.0, "episode_reward": 1.7, "eval_time": 9.878215551376343, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 357000}
{"episode": 1075.0, "episode_reward": 0.9, "eval_time": 9.783268690109253, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 358000}
{"episode": 1078.0, "episode_reward": 0.7, "eval_time": 9.859113454818726, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 359000}
{"episode": 1081.0, "episode_reward": 0.7, "eval_time": 9.838162899017334, "mean_episode_reward": 0.7, "best_episode_reward": 2.0, "step": 360000}
{"episode": 1084.0, "episode_reward": 0.5, "eval_time": 9.94921064376831, "mean_episode_reward": 0.5, "best_episode_reward": 2.0, "step": 361000}
{"episode": 1087.0, "episode_reward": 2.8, "eval_time": 9.785908937454224, "mean_episode_reward": 2.8, "best_episode_reward": 7.0, "step": 362000}
{"episode": 1090.0, "episode_reward": 2.5, "eval_time": 9.974335193634033, "mean_episode_reward": 2.5, "best_episode_reward": 8.0, "step": 363000}
{"episode": 1093.0, "episode_reward": 1.4, "eval_time": 9.90898323059082, "mean_episode_reward": 1.4, "best_episode_reward": 6.0, "step": 364000}
{"episode": 1096.0, "episode_reward": 2.3, "eval_time": 9.885997772216797, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 365000}
{"episode": 1099.0, "episode_reward": 2.2, "eval_time": 9.827979326248169, "mean_episode_reward": 2.2, "best_episode_reward": 6.0, "step": 366000}
{"episode": 1102.0, "episode_reward": 2.9, "eval_time": 9.839194774627686, "mean_episode_reward": 2.9, "best_episode_reward": 5.0, "step": 367000}
{"episode": 1105.0, "episode_reward": 1.6, "eval_time": 9.730852365493774, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 368000}
{"episode": 1108.0, "episode_reward": 1.8, "eval_time": 9.616856098175049, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 369000}
{"episode": 1111.0, "episode_reward": 4.2, "eval_time": 9.693759679794312, "mean_episode_reward": 4.2, "best_episode_reward": 8.0, "step": 370000}
{"episode": 1114.0, "episode_reward": 4.5, "eval_time": 9.814728498458862, "mean_episode_reward": 4.5, "best_episode_reward": 6.0, "step": 371000}
{"episode": 1117.0, "episode_reward": 4.7, "eval_time": 9.865558862686157, "mean_episode_reward": 4.7, "best_episode_reward": 8.0, "step": 372000}
{"episode": 1120.0, "episode_reward": 3.0, "eval_time": 9.733078002929688, "mean_episode_reward": 3.0, "best_episode_reward": 6.0, "step": 373000}
{"episode": 1123.0, "episode_reward": 3.3, "eval_time": 9.668403625488281, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 374000}
{"episode": 1126.0, "episode_reward": 4.3, "eval_time": 9.732213258743286, "mean_episode_reward": 4.3, "best_episode_reward": 7.0, "step": 375000}
{"episode": 1129.0, "episode_reward": 4.1, "eval_time": 9.729753732681274, "mean_episode_reward": 4.1, "best_episode_reward": 6.0, "step": 376000}
{"episode": 1132.0, "episode_reward": 3.5, "eval_time": 9.909605979919434, "mean_episode_reward": 3.5, "best_episode_reward": 7.0, "step": 377000}
{"episode": 1135.0, "episode_reward": 3.1, "eval_time": 9.639723777770996, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 378000}
{"episode": 1138.0, "episode_reward": 3.4, "eval_time": 9.813429594039917, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 379000}
{"episode": 1141.0, "episode_reward": 1.9, "eval_time": 9.606921911239624, "mean_episode_reward": 1.9, "best_episode_reward": 6.0, "step": 380000}
{"episode": 1144.0, "episode_reward": 4.7, "eval_time": 9.711827754974365, "mean_episode_reward": 4.7, "best_episode_reward": 9.0, "step": 381000}
{"episode": 1147.0, "episode_reward": 3.3, "eval_time": 9.80709719657898, "mean_episode_reward": 3.3, "best_episode_reward": 7.0, "step": 382000}
{"episode": 1150.0, "episode_reward": 1.4, "eval_time": 9.222994804382324, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 383000}
{"episode": 1153.0, "episode_reward": 5.4, "eval_time": 9.717156648635864, "mean_episode_reward": 5.4, "best_episode_reward": 8.0, "step": 384000}
{"episode": 1156.0, "episode_reward": 2.8, "eval_time": 9.941482543945312, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 385000}
{"episode": 1159.0, "episode_reward": 4.5, "eval_time": 9.641915321350098, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 386000}
{"episode": 1162.0, "episode_reward": 1.9, "eval_time": 10.092973709106445, "mean_episode_reward": 1.9, "best_episode_reward": 3.0, "step": 387000}
{"episode": 1165.0, "episode_reward": 4.3, "eval_time": 9.766172647476196, "mean_episode_reward": 4.3, "best_episode_reward": 6.0, "step": 388000}
{"episode": 1168.0, "episode_reward": 4.1, "eval_time": 9.706961631774902, "mean_episode_reward": 4.1, "best_episode_reward": 6.0, "step": 389000}
{"episode": 1171.0, "episode_reward": 3.8, "eval_time": 9.751603603363037, "mean_episode_reward": 3.8, "best_episode_reward": 7.0, "step": 390000}
{"episode": 1174.0, "episode_reward": 3.2, "eval_time": 9.801113843917847, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 391000}
{"episode": 1177.0, "episode_reward": 3.7, "eval_time": 9.721235513687134, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 392000}
{"episode": 1180.0, "episode_reward": 2.2, "eval_time": 9.958623886108398, "mean_episode_reward": 2.2, "best_episode_reward": 5.0, "step": 393000}
{"episode": 1183.0, "episode_reward": 3.2, "eval_time": 9.956944704055786, "mean_episode_reward": 3.2, "best_episode_reward": 8.0, "step": 394000}
{"episode": 1186.0, "episode_reward": 4.1, "eval_time": 9.76454472541809, "mean_episode_reward": 4.1, "best_episode_reward": 8.0, "step": 395000}
{"episode": 1189.0, "episode_reward": 1.5, "eval_time": 9.586394786834717, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 396000}
{"episode": 1192.0, "episode_reward": 1.6, "eval_time": 9.649617195129395, "mean_episode_reward": 1.6, "best_episode_reward": 6.0, "step": 397000}
{"episode": 1195.0, "episode_reward": 1.7, "eval_time": 9.747977495193481, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 398000}
{"episode": 1198.0, "episode_reward": 2.7, "eval_time": 9.681639432907104, "mean_episode_reward": 2.7, "best_episode_reward": 4.0, "step": 399000}
{"episode": 1201.0, "episode_reward": 1.5, "eval_time": 9.742385387420654, "mean_episode_reward": 1.5, "best_episode_reward": 5.0, "step": 400000}
{"episode": 1204.0, "episode_reward": 0.9, "eval_time": 9.74642539024353, "mean_episode_reward": 0.9, "best_episode_reward": 5.0, "step": 401000}
{"episode": 1207.0, "episode_reward": 1.5, "eval_time": 9.624498844146729, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 402000}
{"episode": 1210.0, "episode_reward": 2.6, "eval_time": 9.834354877471924, "mean_episode_reward": 2.6, "best_episode_reward": 6.0, "step": 403000}
{"episode": 1213.0, "episode_reward": 2.8, "eval_time": 9.648526906967163, "mean_episode_reward": 2.8, "best_episode_reward": 6.0, "step": 404000}
{"episode": 1216.0, "episode_reward": 2.0, "eval_time": 9.772407293319702, "mean_episode_reward": 2.0, "best_episode_reward": 6.0, "step": 405000}
{"episode": 1219.0, "episode_reward": 1.8, "eval_time": 9.5674147605896, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 406000}
{"episode": 1222.0, "episode_reward": 1.6, "eval_time": 9.761273622512817, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 407000}
{"episode": 1225.0, "episode_reward": 1.5, "eval_time": 9.709659099578857, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 408000}
{"episode": 1228.0, "episode_reward": 1.5, "eval_time": 9.972011089324951, "mean_episode_reward": 1.5, "best_episode_reward": 2.0, "step": 409000}
{"episode": 1231.0, "episode_reward": 1.4, "eval_time": 9.803559064865112, "mean_episode_reward": 1.4, "best_episode_reward": 6.0, "step": 410000}
{"episode": 1234.0, "episode_reward": 2.3, "eval_time": 9.750692367553711, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 411000}
{"episode": 1237.0, "episode_reward": 1.6, "eval_time": 9.853276252746582, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 412000}
{"episode": 1240.0, "episode_reward": 2.4, "eval_time": 9.82723069190979, "mean_episode_reward": 2.4, "best_episode_reward": 6.0, "step": 413000}
{"episode": 1243.0, "episode_reward": 1.9, "eval_time": 9.982994794845581, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 414000}
{"episode": 1246.0, "episode_reward": 2.7, "eval_time": 10.017409086227417, "mean_episode_reward": 2.7, "best_episode_reward": 8.0, "step": 415000}
{"episode": 1249.0, "episode_reward": 1.5, "eval_time": 9.991830825805664, "mean_episode_reward": 1.5, "best_episode_reward": 4.0, "step": 416000}
{"episode": 1252.0, "episode_reward": 1.1, "eval_time": 9.97954535484314, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 417000}
{"episode": 1255.0, "episode_reward": 1.3, "eval_time": 9.910102605819702, "mean_episode_reward": 1.3, "best_episode_reward": 2.0, "step": 418000}
{"episode": 1258.0, "episode_reward": 1.9, "eval_time": 9.3311607837677, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 419000}
{"episode": 1261.0, "episode_reward": 3.5, "eval_time": 9.761101245880127, "mean_episode_reward": 3.5, "best_episode_reward": 6.0, "step": 420000}
{"episode": 1264.0, "episode_reward": 3.3, "eval_time": 9.802138566970825, "mean_episode_reward": 3.3, "best_episode_reward": 7.0, "step": 421000}
{"episode": 1267.0, "episode_reward": 3.0, "eval_time": 9.769121170043945, "mean_episode_reward": 3.0, "best_episode_reward": 5.0, "step": 422000}
{"episode": 1270.0, "episode_reward": 5.0, "eval_time": 9.767199516296387, "mean_episode_reward": 5.0, "best_episode_reward": 10.0, "step": 423000}
{"episode": 1273.0, "episode_reward": 1.6, "eval_time": 9.83381462097168, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 424000}
{"episode": 1276.0, "episode_reward": 0.6, "eval_time": 9.77846908569336, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 425000}
{"episode": 1279.0, "episode_reward": 3.1, "eval_time": 9.890916109085083, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 426000}
{"episode": 1282.0, "episode_reward": 2.7, "eval_time": 9.85006594657898, "mean_episode_reward": 2.7, "best_episode_reward": 5.0, "step": 427000}
{"episode": 1285.0, "episode_reward": 4.1, "eval_time": 9.702236890792847, "mean_episode_reward": 4.1, "best_episode_reward": 8.0, "step": 428000}
{"episode": 1288.0, "episode_reward": 1.8, "eval_time": 9.95623779296875, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 429000}
{"episode": 1291.0, "episode_reward": 1.8, "eval_time": 10.13765811920166, "mean_episode_reward": 1.8, "best_episode_reward": 3.0, "step": 430000}
{"episode": 1294.0, "episode_reward": 3.1, "eval_time": 10.088805437088013, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 431000}
{"episode": 1297.0, "episode_reward": 2.3, "eval_time": 9.985735177993774, "mean_episode_reward": 2.3, "best_episode_reward": 5.0, "step": 432000}
{"episode": 1300.0, "episode_reward": 3.5, "eval_time": 9.683565378189087, "mean_episode_reward": 3.5, "best_episode_reward": 5.0, "step": 433000}
{"episode": 1303.0, "episode_reward": 2.2, "eval_time": 9.604001998901367, "mean_episode_reward": 2.2, "best_episode_reward": 6.0, "step": 434000}
{"episode": 1306.0, "episode_reward": 5.0, "eval_time": 10.216679573059082, "mean_episode_reward": 5.0, "best_episode_reward": 8.0, "step": 435000}
{"episode": 1309.0, "episode_reward": 4.8, "eval_time": 10.469579935073853, "mean_episode_reward": 4.8, "best_episode_reward": 9.0, "step": 436000}
{"episode": 1312.0, "episode_reward": 0.9, "eval_time": 10.961030960083008, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 437000}
{"episode": 1315.0, "episode_reward": 1.1, "eval_time": 10.185956239700317, "mean_episode_reward": 1.1, "best_episode_reward": 4.0, "step": 438000}
{"episode": 1318.0, "episode_reward": 2.0, "eval_time": 9.974258422851562, "mean_episode_reward": 2.0, "best_episode_reward": 4.0, "step": 439000}
{"episode": 1321.0, "episode_reward": 2.1, "eval_time": 9.993843793869019, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 440000}
{"episode": 1324.0, "episode_reward": 3.6, "eval_time": 10.226270914077759, "mean_episode_reward": 3.6, "best_episode_reward": 8.0, "step": 441000}
{"episode": 1327.0, "episode_reward": 1.6, "eval_time": 10.064424991607666, "mean_episode_reward": 1.6, "best_episode_reward": 4.0, "step": 442000}
{"episode": 1330.0, "episode_reward": 2.6, "eval_time": 10.299036979675293, "mean_episode_reward": 2.6, "best_episode_reward": 6.0, "step": 443000}
{"episode": 1333.0, "episode_reward": 3.7, "eval_time": 9.939184427261353, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 444000}
{"episode": 1336.0, "episode_reward": 1.0, "eval_time": 9.86610746383667, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 445000}
{"episode": 1339.0, "episode_reward": 3.6, "eval_time": 9.911557674407959, "mean_episode_reward": 3.6, "best_episode_reward": 7.0, "step": 446000}
{"episode": 1342.0, "episode_reward": 3.2, "eval_time": 9.86379098892212, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 447000}
{"episode": 1345.0, "episode_reward": 2.4, "eval_time": 9.937587022781372, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 448000}
{"episode": 1348.0, "episode_reward": 2.1, "eval_time": 9.867969751358032, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 449000}
{"episode": 1351.0, "episode_reward": 2.8, "eval_time": 9.894702196121216, "mean_episode_reward": 2.8, "best_episode_reward": 7.0, "step": 450000}
{"episode": 1354.0, "episode_reward": 3.2, "eval_time": 9.899725198745728, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 451000}
{"episode": 1357.0, "episode_reward": 2.5, "eval_time": 9.840855836868286, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 452000}
{"episode": 1360.0, "episode_reward": 1.9, "eval_time": 9.81729245185852, "mean_episode_reward": 1.9, "best_episode_reward": 7.0, "step": 453000}
{"episode": 1363.0, "episode_reward": 3.9, "eval_time": 9.851598978042603, "mean_episode_reward": 3.9, "best_episode_reward": 7.0, "step": 454000}
{"episode": 1366.0, "episode_reward": 4.1, "eval_time": 9.868227005004883, "mean_episode_reward": 4.1, "best_episode_reward": 7.0, "step": 455000}
{"episode": 1369.0, "episode_reward": 3.8, "eval_time": 9.845524549484253, "mean_episode_reward": 3.8, "best_episode_reward": 8.0, "step": 456000}
{"episode": 1372.0, "episode_reward": 2.4, "eval_time": 9.837446689605713, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 457000}
{"episode": 1375.0, "episode_reward": 3.5, "eval_time": 9.694178819656372, "mean_episode_reward": 3.5, "best_episode_reward": 6.0, "step": 458000}
{"episode": 1378.0, "episode_reward": 2.0, "eval_time": 9.899708986282349, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 459000}
{"episode": 1381.0, "episode_reward": 4.1, "eval_time": 9.82863473892212, "mean_episode_reward": 4.1, "best_episode_reward": 7.0, "step": 460000}
{"episode": 1384.0, "episode_reward": 4.4, "eval_time": 9.82003664970398, "mean_episode_reward": 4.4, "best_episode_reward": 8.0, "step": 461000}
{"episode": 1387.0, "episode_reward": 4.9, "eval_time": 9.783678531646729, "mean_episode_reward": 4.9, "best_episode_reward": 8.0, "step": 462000}
{"episode": 1390.0, "episode_reward": 3.2, "eval_time": 9.835776805877686, "mean_episode_reward": 3.2, "best_episode_reward": 8.0, "step": 463000}
{"episode": 1393.0, "episode_reward": 2.2, "eval_time": 9.925674676895142, "mean_episode_reward": 2.2, "best_episode_reward": 3.0, "step": 464000}
{"episode": 1396.0, "episode_reward": 4.1, "eval_time": 9.76500391960144, "mean_episode_reward": 4.1, "best_episode_reward": 7.0, "step": 465000}
{"episode": 1399.0, "episode_reward": 2.8, "eval_time": 9.794069051742554, "mean_episode_reward": 2.8, "best_episode_reward": 7.0, "step": 466000}
{"episode": 1402.0, "episode_reward": 4.1, "eval_time": 9.855885744094849, "mean_episode_reward": 4.1, "best_episode_reward": 8.0, "step": 467000}
{"episode": 1405.0, "episode_reward": 2.9, "eval_time": 9.82578730583191, "mean_episode_reward": 2.9, "best_episode_reward": 6.0, "step": 468000}
{"episode": 1408.0, "episode_reward": 4.2, "eval_time": 9.955166816711426, "mean_episode_reward": 4.2, "best_episode_reward": 6.0, "step": 469000}
{"episode": 1411.0, "episode_reward": 1.3, "eval_time": 10.094704866409302, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 470000}
{"episode": 1414.0, "episode_reward": 3.9, "eval_time": 9.982197046279907, "mean_episode_reward": 3.9, "best_episode_reward": 6.0, "step": 471000}
{"episode": 1417.0, "episode_reward": 2.9, "eval_time": 9.940286874771118, "mean_episode_reward": 2.9, "best_episode_reward": 6.0, "step": 472000}
{"episode": 1420.0, "episode_reward": 4.2, "eval_time": 9.931777477264404, "mean_episode_reward": 4.2, "best_episode_reward": 7.0, "step": 473000}
{"episode": 1423.0, "episode_reward": 3.4, "eval_time": 9.826584815979004, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 474000}
{"episode": 1426.0, "episode_reward": 2.5, "eval_time": 9.901448488235474, "mean_episode_reward": 2.5, "best_episode_reward": 6.0, "step": 475000}
{"episode": 1429.0, "episode_reward": 3.6, "eval_time": 9.832995176315308, "mean_episode_reward": 3.6, "best_episode_reward": 7.0, "step": 476000}
{"episode": 1432.0, "episode_reward": 3.9, "eval_time": 9.776765823364258, "mean_episode_reward": 3.9, "best_episode_reward": 5.0, "step": 477000}
{"episode": 1435.0, "episode_reward": 4.2, "eval_time": 9.795673131942749, "mean_episode_reward": 4.2, "best_episode_reward": 7.0, "step": 478000}
{"episode": 1438.0, "episode_reward": 4.3, "eval_time": 9.8032546043396, "mean_episode_reward": 4.3, "best_episode_reward": 8.0, "step": 479000}
{"episode": 1441.0, "episode_reward": 2.7, "eval_time": 9.759361267089844, "mean_episode_reward": 2.7, "best_episode_reward": 6.0, "step": 480000}
{"episode": 1444.0, "episode_reward": 4.2, "eval_time": 9.792927026748657, "mean_episode_reward": 4.2, "best_episode_reward": 6.0, "step": 481000}
{"episode": 1447.0, "episode_reward": 3.2, "eval_time": 9.796228170394897, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 482000}
{"episode": 1450.0, "episode_reward": 3.6, "eval_time": 9.892571926116943, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 483000}
{"episode": 1453.0, "episode_reward": 3.9, "eval_time": 9.816572427749634, "mean_episode_reward": 3.9, "best_episode_reward": 8.0, "step": 484000}
{"episode": 1456.0, "episode_reward": 3.1, "eval_time": 9.928112506866455, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 485000}
{"episode": 1459.0, "episode_reward": 3.6, "eval_time": 9.771151304244995, "mean_episode_reward": 3.6, "best_episode_reward": 7.0, "step": 486000}
{"episode": 1462.0, "episode_reward": 4.0, "eval_time": 9.799493789672852, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 487000}
{"episode": 1465.0, "episode_reward": 4.6, "eval_time": 9.84496521949768, "mean_episode_reward": 4.6, "best_episode_reward": 8.0, "step": 488000}
{"episode": 1468.0, "episode_reward": 3.2, "eval_time": 9.977275848388672, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 489000}
{"episode": 1471.0, "episode_reward": 3.0, "eval_time": 9.739030838012695, "mean_episode_reward": 3.0, "best_episode_reward": 5.0, "step": 490000}
{"episode": 1474.0, "episode_reward": 3.8, "eval_time": 10.017088174819946, "mean_episode_reward": 3.8, "best_episode_reward": 7.0, "step": 491000}
{"episode": 1477.0, "episode_reward": 1.9, "eval_time": 9.919406414031982, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 492000}
{"episode": 1480.0, "episode_reward": 2.8, "eval_time": 9.98445177078247, "mean_episode_reward": 2.8, "best_episode_reward": 4.0, "step": 493000}
{"episode": 1483.0, "episode_reward": 2.4, "eval_time": 9.998810768127441, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 494000}
{"episode": 1486.0, "episode_reward": 1.6, "eval_time": 10.013053178787231, "mean_episode_reward": 1.6, "best_episode_reward": 5.0, "step": 495000}
{"episode": 1489.0, "episode_reward": 2.3, "eval_time": 9.850949048995972, "mean_episode_reward": 2.3, "best_episode_reward": 4.0, "step": 496000}
{"episode": 1492.0, "episode_reward": 4.0, "eval_time": 9.868290662765503, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 497000}
{"episode": 1495.0, "episode_reward": 2.5, "eval_time": 9.914611339569092, "mean_episode_reward": 2.5, "best_episode_reward": 6.0, "step": 498000}
{"episode": 1498.0, "episode_reward": 3.1, "eval_time": 9.845600605010986, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 499000}
{"episode": 1501.0, "episode_reward": 1.7, "eval_time": 9.957737922668457, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 500000}
{"episode": 1504.0, "episode_reward": 2.9, "eval_time": 9.902549505233765, "mean_episode_reward": 2.9, "best_episode_reward": 6.0, "step": 501000}
{"episode": 1507.0, "episode_reward": 2.6, "eval_time": 9.929303407669067, "mean_episode_reward": 2.6, "best_episode_reward": 5.0, "step": 502000}
{"episode": 1510.0, "episode_reward": 2.1, "eval_time": 9.652864456176758, "mean_episode_reward": 2.1, "best_episode_reward": 6.0, "step": 503000}
{"episode": 1513.0, "episode_reward": 1.5, "eval_time": 9.905805826187134, "mean_episode_reward": 1.5, "best_episode_reward": 2.0, "step": 504000}
{"episode": 1516.0, "episode_reward": 2.7, "eval_time": 9.850128889083862, "mean_episode_reward": 2.7, "best_episode_reward": 6.0, "step": 505000}
{"episode": 1519.0, "episode_reward": 2.1, "eval_time": 9.904962539672852, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 506000}
{"episode": 1522.0, "episode_reward": 4.4, "eval_time": 9.801858901977539, "mean_episode_reward": 4.4, "best_episode_reward": 7.0, "step": 507000}
{"episode": 1525.0, "episode_reward": 1.8, "eval_time": 9.757236003875732, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 508000}
{"episode": 1528.0, "episode_reward": 2.2, "eval_time": 9.480815172195435, "mean_episode_reward": 2.2, "best_episode_reward": 5.0, "step": 509000}
{"episode": 1531.0, "episode_reward": 3.4, "eval_time": 9.654881238937378, "mean_episode_reward": 3.4, "best_episode_reward": 7.0, "step": 510000}
{"episode": 1534.0, "episode_reward": 3.7, "eval_time": 9.873356103897095, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 511000}
{"episode": 1537.0, "episode_reward": 3.0, "eval_time": 9.792556762695312, "mean_episode_reward": 3.0, "best_episode_reward": 7.0, "step": 512000}
{"episode": 1540.0, "episode_reward": 3.2, "eval_time": 9.90617322921753, "mean_episode_reward": 3.2, "best_episode_reward": 5.0, "step": 513000}
{"episode": 1543.0, "episode_reward": 3.0, "eval_time": 9.840232849121094, "mean_episode_reward": 3.0, "best_episode_reward": 6.0, "step": 514000}
{"episode": 1546.0, "episode_reward": 3.7, "eval_time": 9.907416582107544, "mean_episode_reward": 3.7, "best_episode_reward": 5.0, "step": 515000}
{"episode": 1549.0, "episode_reward": 1.4, "eval_time": 9.845957040786743, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 516000}
{"episode": 1552.0, "episode_reward": 1.3, "eval_time": 9.665954351425171, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 517000}
{"episode": 1555.0, "episode_reward": 3.0, "eval_time": 9.616110801696777, "mean_episode_reward": 3.0, "best_episode_reward": 6.0, "step": 518000}
{"episode": 1558.0, "episode_reward": 3.2, "eval_time": 9.54001259803772, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 519000}
{"episode": 1561.0, "episode_reward": 3.8, "eval_time": 9.727807521820068, "mean_episode_reward": 3.8, "best_episode_reward": 6.0, "step": 520000}
{"episode": 1564.0, "episode_reward": 3.6, "eval_time": 9.853495121002197, "mean_episode_reward": 3.6, "best_episode_reward": 7.0, "step": 521000}
{"episode": 1567.0, "episode_reward": 5.0, "eval_time": 9.622545003890991, "mean_episode_reward": 5.0, "best_episode_reward": 7.0, "step": 522000}
{"episode": 1570.0, "episode_reward": 3.3, "eval_time": 9.883480072021484, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 523000}
{"episode": 1573.0, "episode_reward": 5.4, "eval_time": 9.774498224258423, "mean_episode_reward": 5.4, "best_episode_reward": 7.0, "step": 524000}
{"episode": 1576.0, "episode_reward": 3.3, "eval_time": 9.805608034133911, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 525000}
{"episode": 1579.0, "episode_reward": 3.9, "eval_time": 9.74582314491272, "mean_episode_reward": 3.9, "best_episode_reward": 7.0, "step": 526000}
{"episode": 1582.0, "episode_reward": 1.7, "eval_time": 9.68142819404602, "mean_episode_reward": 1.7, "best_episode_reward": 6.0, "step": 527000}
{"episode": 1585.0, "episode_reward": 3.7, "eval_time": 9.958180904388428, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 528000}
{"episode": 1588.0, "episode_reward": 3.5, "eval_time": 9.651610612869263, "mean_episode_reward": 3.5, "best_episode_reward": 7.0, "step": 529000}
{"episode": 1591.0, "episode_reward": 2.8, "eval_time": 9.505228519439697, "mean_episode_reward": 2.8, "best_episode_reward": 7.0, "step": 530000}
{"episode": 1594.0, "episode_reward": 1.5, "eval_time": 9.877873420715332, "mean_episode_reward": 1.5, "best_episode_reward": 3.0, "step": 531000}
{"episode": 1597.0, "episode_reward": 1.2, "eval_time": 9.956429243087769, "mean_episode_reward": 1.2, "best_episode_reward": 4.0, "step": 532000}
{"episode": 1600.0, "episode_reward": 1.9, "eval_time": 9.942442893981934, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 533000}
{"episode": 1603.0, "episode_reward": 3.2, "eval_time": 9.889971256256104, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 534000}
{"episode": 1606.0, "episode_reward": 3.1, "eval_time": 9.575069427490234, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 535000}
{"episode": 1609.0, "episode_reward": 3.6, "eval_time": 9.745929718017578, "mean_episode_reward": 3.6, "best_episode_reward": 8.0, "step": 536000}
{"episode": 1612.0, "episode_reward": 4.5, "eval_time": 9.685297966003418, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 537000}
{"episode": 1615.0, "episode_reward": 3.9, "eval_time": 9.745349407196045, "mean_episode_reward": 3.9, "best_episode_reward": 7.0, "step": 538000}
{"episode": 1618.0, "episode_reward": 2.4, "eval_time": 9.263302087783813, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 539000}
{"episode": 1621.0, "episode_reward": 2.1, "eval_time": 9.520610570907593, "mean_episode_reward": 2.1, "best_episode_reward": 3.0, "step": 540000}
{"episode": 1624.0, "episode_reward": 3.2, "eval_time": 9.607435464859009, "mean_episode_reward": 3.2, "best_episode_reward": 7.0, "step": 541000}
{"episode": 1627.0, "episode_reward": 2.2, "eval_time": 9.305313110351562, "mean_episode_reward": 2.2, "best_episode_reward": 7.0, "step": 542000}
{"episode": 1630.0, "episode_reward": 2.9, "eval_time": 9.738041162490845, "mean_episode_reward": 2.9, "best_episode_reward": 6.0, "step": 543000}
{"episode": 1633.0, "episode_reward": 3.9, "eval_time": 9.942001819610596, "mean_episode_reward": 3.9, "best_episode_reward": 7.0, "step": 544000}
{"episode": 1636.0, "episode_reward": 4.6, "eval_time": 9.781830787658691, "mean_episode_reward": 4.6, "best_episode_reward": 7.0, "step": 545000}
{"episode": 1639.0, "episode_reward": 3.6, "eval_time": 9.938541412353516, "mean_episode_reward": 3.6, "best_episode_reward": 9.0, "step": 546000}
{"episode": 1642.0, "episode_reward": 5.1, "eval_time": 9.738659620285034, "mean_episode_reward": 5.1, "best_episode_reward": 9.0, "step": 547000}
{"episode": 1645.0, "episode_reward": 3.6, "eval_time": 9.628803968429565, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 548000}
{"episode": 1648.0, "episode_reward": 4.8, "eval_time": 9.688750267028809, "mean_episode_reward": 4.8, "best_episode_reward": 7.0, "step": 549000}
{"episode": 1651.0, "episode_reward": 5.1, "eval_time": 9.867239475250244, "mean_episode_reward": 5.1, "best_episode_reward": 9.0, "step": 550000}
{"episode": 1654.0, "episode_reward": 4.7, "eval_time": 9.870818138122559, "mean_episode_reward": 4.7, "best_episode_reward": 9.0, "step": 551000}
{"episode": 1657.0, "episode_reward": 5.3, "eval_time": 9.893220663070679, "mean_episode_reward": 5.3, "best_episode_reward": 8.0, "step": 552000}
{"episode": 1660.0, "episode_reward": 4.9, "eval_time": 9.803136110305786, "mean_episode_reward": 4.9, "best_episode_reward": 8.0, "step": 553000}
{"episode": 1663.0, "episode_reward": 3.8, "eval_time": 9.843041896820068, "mean_episode_reward": 3.8, "best_episode_reward": 6.0, "step": 554000}
{"episode": 1666.0, "episode_reward": 2.5, "eval_time": 9.606464147567749, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 555000}
{"episode": 1669.0, "episode_reward": 3.7, "eval_time": 9.74745488166809, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 556000}
{"episode": 1672.0, "episode_reward": 4.0, "eval_time": 9.664302110671997, "mean_episode_reward": 4.0, "best_episode_reward": 7.0, "step": 557000}
{"episode": 1675.0, "episode_reward": 3.4, "eval_time": 9.521836519241333, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 558000}
{"episode": 1678.0, "episode_reward": 3.1, "eval_time": 9.794716119766235, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 559000}
{"episode": 1681.0, "episode_reward": 2.0, "eval_time": 9.568495035171509, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 560000}
{"episode": 1684.0, "episode_reward": 2.8, "eval_time": 9.689241170883179, "mean_episode_reward": 2.8, "best_episode_reward": 6.0, "step": 561000}
{"episode": 1687.0, "episode_reward": 2.5, "eval_time": 9.491275310516357, "mean_episode_reward": 2.5, "best_episode_reward": 6.0, "step": 562000}
{"episode": 1690.0, "episode_reward": 4.0, "eval_time": 9.478590726852417, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 563000}
{"episode": 1693.0, "episode_reward": 6.7, "eval_time": 9.574953079223633, "mean_episode_reward": 6.7, "best_episode_reward": 10.0, "step": 564000}
{"episode": 1696.0, "episode_reward": 2.9, "eval_time": 9.515166282653809, "mean_episode_reward": 2.9, "best_episode_reward": 6.0, "step": 565000}
{"episode": 1699.0, "episode_reward": 3.7, "eval_time": 9.76297926902771, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 566000}
{"episode": 1702.0, "episode_reward": 4.7, "eval_time": 9.818170070648193, "mean_episode_reward": 4.7, "best_episode_reward": 7.0, "step": 567000}
{"episode": 1705.0, "episode_reward": 2.5, "eval_time": 9.993678092956543, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 568000}
{"episode": 1708.0, "episode_reward": 3.9, "eval_time": 9.720274209976196, "mean_episode_reward": 3.9, "best_episode_reward": 9.0, "step": 569000}
{"episode": 1711.0, "episode_reward": 4.9, "eval_time": 9.898233413696289, "mean_episode_reward": 4.9, "best_episode_reward": 8.0, "step": 570000}
{"episode": 1714.0, "episode_reward": 3.1, "eval_time": 9.844159364700317, "mean_episode_reward": 3.1, "best_episode_reward": 6.0, "step": 571000}
{"episode": 1717.0, "episode_reward": 1.9, "eval_time": 9.900544881820679, "mean_episode_reward": 1.9, "best_episode_reward": 4.0, "step": 572000}
{"episode": 1720.0, "episode_reward": 2.1, "eval_time": 9.843650341033936, "mean_episode_reward": 2.1, "best_episode_reward": 4.0, "step": 573000}
{"episode": 1723.0, "episode_reward": 2.4, "eval_time": 9.884078025817871, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 574000}
{"episode": 1726.0, "episode_reward": 4.5, "eval_time": 9.69250774383545, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 575000}
{"episode": 1729.0, "episode_reward": 2.0, "eval_time": 9.924163341522217, "mean_episode_reward": 2.0, "best_episode_reward": 3.0, "step": 576000}
{"episode": 1732.0, "episode_reward": 2.0, "eval_time": 9.325217962265015, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 577000}
{"episode": 1735.0, "episode_reward": 1.7, "eval_time": 9.546235084533691, "mean_episode_reward": 1.7, "best_episode_reward": 4.0, "step": 578000}
{"episode": 1738.0, "episode_reward": 3.1, "eval_time": 9.584272384643555, "mean_episode_reward": 3.1, "best_episode_reward": 5.0, "step": 579000}
{"episode": 1741.0, "episode_reward": 3.1, "eval_time": 9.593354225158691, "mean_episode_reward": 3.1, "best_episode_reward": 5.0, "step": 580000}
{"episode": 1744.0, "episode_reward": 3.6, "eval_time": 9.7569899559021, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 581000}
{"episode": 1747.0, "episode_reward": 4.5, "eval_time": 9.936689138412476, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 582000}
{"episode": 1750.0, "episode_reward": 3.1, "eval_time": 10.0924072265625, "mean_episode_reward": 3.1, "best_episode_reward": 7.0, "step": 583000}
{"episode": 1753.0, "episode_reward": 1.7, "eval_time": 10.042814016342163, "mean_episode_reward": 1.7, "best_episode_reward": 3.0, "step": 584000}
{"episode": 1756.0, "episode_reward": 2.2, "eval_time": 9.912862777709961, "mean_episode_reward": 2.2, "best_episode_reward": 4.0, "step": 585000}
{"episode": 1759.0, "episode_reward": 2.5, "eval_time": 9.887236833572388, "mean_episode_reward": 2.5, "best_episode_reward": 4.0, "step": 586000}
{"episode": 1762.0, "episode_reward": 3.7, "eval_time": 9.893345832824707, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 587000}
{"episode": 1765.0, "episode_reward": 3.6, "eval_time": 9.90439224243164, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 588000}
{"episode": 1768.0, "episode_reward": 2.5, "eval_time": 9.985246896743774, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 589000}
{"episode": 1771.0, "episode_reward": 3.3, "eval_time": 9.72758173942566, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 590000}
{"episode": 1774.0, "episode_reward": 3.9, "eval_time": 9.81697702407837, "mean_episode_reward": 3.9, "best_episode_reward": 6.0, "step": 591000}
{"episode": 1777.0, "episode_reward": 3.6, "eval_time": 9.968426942825317, "mean_episode_reward": 3.6, "best_episode_reward": 6.0, "step": 592000}
{"episode": 1780.0, "episode_reward": 4.1, "eval_time": 9.837573051452637, "mean_episode_reward": 4.1, "best_episode_reward": 8.0, "step": 593000}
{"episode": 1783.0, "episode_reward": 3.7, "eval_time": 9.665275812149048, "mean_episode_reward": 3.7, "best_episode_reward": 6.0, "step": 594000}
{"episode": 1786.0, "episode_reward": 3.2, "eval_time": 9.852423191070557, "mean_episode_reward": 3.2, "best_episode_reward": 7.0, "step": 595000}
{"episode": 1789.0, "episode_reward": 3.5, "eval_time": 9.748918056488037, "mean_episode_reward": 3.5, "best_episode_reward": 8.0, "step": 596000}
{"episode": 1792.0, "episode_reward": 3.7, "eval_time": 9.671288013458252, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 597000}
{"episode": 1795.0, "episode_reward": 4.4, "eval_time": 9.78653073310852, "mean_episode_reward": 4.4, "best_episode_reward": 9.0, "step": 598000}
{"episode": 1798.0, "episode_reward": 3.1, "eval_time": 9.741600513458252, "mean_episode_reward": 3.1, "best_episode_reward": 5.0, "step": 599000}
{"episode": 1801.0, "episode_reward": 0.2, "eval_time": 9.36558198928833, "mean_episode_reward": 0.2, "best_episode_reward": 1.0, "step": 600000}
{"episode": 1804.0, "episode_reward": 1.4, "eval_time": 9.144726991653442, "mean_episode_reward": 1.4, "best_episode_reward": 5.0, "step": 601000}
{"episode": 1807.0, "episode_reward": 1.2, "eval_time": 9.977089405059814, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 602000}
{"episode": 1810.0, "episode_reward": 5.5, "eval_time": 9.731540203094482, "mean_episode_reward": 5.5, "best_episode_reward": 9.0, "step": 603000}
{"episode": 1813.0, "episode_reward": 5.5, "eval_time": 9.725673198699951, "mean_episode_reward": 5.5, "best_episode_reward": 7.0, "step": 604000}
{"episode": 1816.0, "episode_reward": 0.6, "eval_time": 9.485599040985107, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 605000}
{"episode": 1819.0, "episode_reward": 1.0, "eval_time": 9.659298419952393, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 606000}
{"episode": 1822.0, "episode_reward": 3.7, "eval_time": 9.58351731300354, "mean_episode_reward": 3.7, "best_episode_reward": 7.0, "step": 607000}
{"episode": 1825.0, "episode_reward": 1.3, "eval_time": 9.71892786026001, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 608000}
{"episode": 1828.0, "episode_reward": 1.3, "eval_time": 9.712064981460571, "mean_episode_reward": 1.3, "best_episode_reward": 4.0, "step": 609000}
{"episode": 1831.0, "episode_reward": 3.3, "eval_time": 9.658999681472778, "mean_episode_reward": 3.3, "best_episode_reward": 6.0, "step": 610000}
{"episode": 1834.0, "episode_reward": 2.1, "eval_time": 9.618287324905396, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 611000}
{"episode": 1837.0, "episode_reward": 3.9, "eval_time": 9.677912950515747, "mean_episode_reward": 3.9, "best_episode_reward": 6.0, "step": 612000}
{"episode": 1840.0, "episode_reward": 3.6, "eval_time": 9.734721422195435, "mean_episode_reward": 3.6, "best_episode_reward": 7.0, "step": 613000}
{"episode": 1843.0, "episode_reward": 5.2, "eval_time": 9.92897891998291, "mean_episode_reward": 5.2, "best_episode_reward": 10.0, "step": 614000}
{"episode": 1846.0, "episode_reward": 5.4, "eval_time": 9.51956844329834, "mean_episode_reward": 5.4, "best_episode_reward": 7.0, "step": 615000}
{"episode": 1849.0, "episode_reward": 4.3, "eval_time": 9.667612314224243, "mean_episode_reward": 4.3, "best_episode_reward": 6.0, "step": 616000}
{"episode": 1852.0, "episode_reward": 4.1, "eval_time": 9.742340803146362, "mean_episode_reward": 4.1, "best_episode_reward": 7.0, "step": 617000}
{"episode": 1855.0, "episode_reward": 4.1, "eval_time": 9.542443037033081, "mean_episode_reward": 4.1, "best_episode_reward": 8.0, "step": 618000}
{"episode": 1858.0, "episode_reward": 2.5, "eval_time": 9.678383111953735, "mean_episode_reward": 2.5, "best_episode_reward": 7.0, "step": 619000}
{"episode": 1861.0, "episode_reward": 5.1, "eval_time": 9.729805707931519, "mean_episode_reward": 5.1, "best_episode_reward": 6.0, "step": 620000}
{"episode": 1864.0, "episode_reward": 3.4, "eval_time": 9.576419830322266, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 621000}
{"episode": 1867.0, "episode_reward": 3.2, "eval_time": 9.677069425582886, "mean_episode_reward": 3.2, "best_episode_reward": 6.0, "step": 622000}
{"episode": 1870.0, "episode_reward": 4.0, "eval_time": 10.017988204956055, "mean_episode_reward": 4.0, "best_episode_reward": 6.0, "step": 623000}
{"episode": 1873.0, "episode_reward": 4.4, "eval_time": 9.578429222106934, "mean_episode_reward": 4.4, "best_episode_reward": 7.0, "step": 624000}
{"episode": 1876.0, "episode_reward": 5.9, "eval_time": 9.571912288665771, "mean_episode_reward": 5.9, "best_episode_reward": 8.0, "step": 625000}
{"episode": 1879.0, "episode_reward": 2.4, "eval_time": 9.678650379180908, "mean_episode_reward": 2.4, "best_episode_reward": 7.0, "step": 626000}
{"episode": 1882.0, "episode_reward": 1.1, "eval_time": 9.706855058670044, "mean_episode_reward": 1.1, "best_episode_reward": 3.0, "step": 627000}
{"episode": 1885.0, "episode_reward": 2.4, "eval_time": 9.927914142608643, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 628000}
{"episode": 1888.0, "episode_reward": 1.5, "eval_time": 9.837067365646362, "mean_episode_reward": 1.5, "best_episode_reward": 6.0, "step": 629000}
{"episode": 1891.0, "episode_reward": 4.7, "eval_time": 9.729089260101318, "mean_episode_reward": 4.7, "best_episode_reward": 8.0, "step": 630000}
{"episode": 1894.0, "episode_reward": 5.8, "eval_time": 9.677721738815308, "mean_episode_reward": 5.8, "best_episode_reward": 8.0, "step": 631000}
{"episode": 1897.0, "episode_reward": 2.7, "eval_time": 9.635043621063232, "mean_episode_reward": 2.7, "best_episode_reward": 8.0, "step": 632000}
{"episode": 1900.0, "episode_reward": 4.4, "eval_time": 9.744014263153076, "mean_episode_reward": 4.4, "best_episode_reward": 7.0, "step": 633000}
{"episode": 1903.0, "episode_reward": 2.2, "eval_time": 9.813437938690186, "mean_episode_reward": 2.2, "best_episode_reward": 6.0, "step": 634000}
{"episode": 1906.0, "episode_reward": 0.8, "eval_time": 9.691976547241211, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 635000}
{"episode": 1909.0, "episode_reward": 0.8, "eval_time": 8.992833375930786, "mean_episode_reward": 0.8, "best_episode_reward": 2.0, "step": 636000}
{"episode": 1912.0, "episode_reward": 2.4, "eval_time": 9.58970594406128, "mean_episode_reward": 2.4, "best_episode_reward": 6.0, "step": 637000}
{"episode": 1915.0, "episode_reward": 2.5, "eval_time": 9.33130931854248, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 638000}
{"episode": 1918.0, "episode_reward": 2.5, "eval_time": 9.427117109298706, "mean_episode_reward": 2.5, "best_episode_reward": 4.0, "step": 639000}
{"episode": 1921.0, "episode_reward": 2.5, "eval_time": 9.476054430007935, "mean_episode_reward": 2.5, "best_episode_reward": 5.0, "step": 640000}
{"episode": 1924.0, "episode_reward": 2.6, "eval_time": 10.09780502319336, "mean_episode_reward": 2.6, "best_episode_reward": 6.0, "step": 641000}
{"episode": 1927.0, "episode_reward": 2.4, "eval_time": 9.745660781860352, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 642000}
{"episode": 1930.0, "episode_reward": 2.1, "eval_time": 9.878935098648071, "mean_episode_reward": 2.1, "best_episode_reward": 5.0, "step": 643000}
{"episode": 1933.0, "episode_reward": 2.4, "eval_time": 9.730191230773926, "mean_episode_reward": 2.4, "best_episode_reward": 5.0, "step": 644000}
{"episode": 1936.0, "episode_reward": 1.2, "eval_time": 9.627528667449951, "mean_episode_reward": 1.2, "best_episode_reward": 3.0, "step": 645000}
{"episode": 1939.0, "episode_reward": 0.6, "eval_time": 9.72189211845398, "mean_episode_reward": 0.6, "best_episode_reward": 2.0, "step": 646000}
{"episode": 1942.0, "episode_reward": 0.8, "eval_time": 9.618910789489746, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 647000}
{"episode": 1945.0, "episode_reward": 3.9, "eval_time": 9.83216118812561, "mean_episode_reward": 3.9, "best_episode_reward": 8.0, "step": 648000}
{"episode": 1948.0, "episode_reward": 0.8, "eval_time": 9.736847162246704, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 649000}
{"episode": 1951.0, "episode_reward": 4.2, "eval_time": 9.78808307647705, "mean_episode_reward": 4.2, "best_episode_reward": 7.0, "step": 650000}
{"episode": 1954.0, "episode_reward": 1.0, "eval_time": 10.737944602966309, "mean_episode_reward": 1.0, "best_episode_reward": 2.0, "step": 651000}
{"episode": 1957.0, "episode_reward": 2.8, "eval_time": 9.900787353515625, "mean_episode_reward": 2.8, "best_episode_reward": 5.0, "step": 652000}
{"episode": 1960.0, "episode_reward": 1.3, "eval_time": 9.744988203048706, "mean_episode_reward": 1.3, "best_episode_reward": 3.0, "step": 653000}
{"episode": 1963.0, "episode_reward": 2.7, "eval_time": 9.809465646743774, "mean_episode_reward": 2.7, "best_episode_reward": 6.0, "step": 654000}
{"episode": 1966.0, "episode_reward": 3.8, "eval_time": 9.785318851470947, "mean_episode_reward": 3.8, "best_episode_reward": 5.0, "step": 655000}
{"episode": 1969.0, "episode_reward": 2.0, "eval_time": 9.8772611618042, "mean_episode_reward": 2.0, "best_episode_reward": 5.0, "step": 656000}
{"episode": 1972.0, "episode_reward": 1.0, "eval_time": 9.681132555007935, "mean_episode_reward": 1.0, "best_episode_reward": 3.0, "step": 657000}
{"episode": 1975.0, "episode_reward": 2.4, "eval_time": 9.771457433700562, "mean_episode_reward": 2.4, "best_episode_reward": 4.0, "step": 658000}
{"episode": 1978.0, "episode_reward": 0.9, "eval_time": 9.555253982543945, "mean_episode_reward": 0.9, "best_episode_reward": 3.0, "step": 659000}
{"episode": 1981.0, "episode_reward": 1.8, "eval_time": 9.963176250457764, "mean_episode_reward": 1.8, "best_episode_reward": 4.0, "step": 660000}
{"episode": 1984.0, "episode_reward": 1.8, "eval_time": 9.457794904708862, "mean_episode_reward": 1.8, "best_episode_reward": 5.0, "step": 661000}
{"episode": 1987.0, "episode_reward": 3.6, "eval_time": 9.543286323547363, "mean_episode_reward": 3.6, "best_episode_reward": 7.0, "step": 662000}
{"episode": 1990.0, "episode_reward": 4.0, "eval_time": 9.725239276885986, "mean_episode_reward": 4.0, "best_episode_reward": 10.0, "step": 663000}
{"episode": 1993.0, "episode_reward": 1.7, "eval_time": 9.647879123687744, "mean_episode_reward": 1.7, "best_episode_reward": 5.0, "step": 664000}
{"episode": 1996.0, "episode_reward": 1.9, "eval_time": 9.788537502288818, "mean_episode_reward": 1.9, "best_episode_reward": 5.0, "step": 665000}
{"episode": 1999.0, "episode_reward": 3.4, "eval_time": 9.751505136489868, "mean_episode_reward": 3.4, "best_episode_reward": 5.0, "step": 666000}
{"episode": 2002.0, "episode_reward": 4.5, "eval_time": 9.606289863586426, "mean_episode_reward": 4.5, "best_episode_reward": 8.0, "step": 667000}
{"episode": 2005.0, "episode_reward": 3.4, "eval_time": 9.676157236099243, "mean_episode_reward": 3.4, "best_episode_reward": 4.0, "step": 668000}
{"episode": 2008.0, "episode_reward": 1.4, "eval_time": 9.981717109680176, "mean_episode_reward": 1.4, "best_episode_reward": 3.0, "step": 669000}
{"episode": 2011.0, "episode_reward": 1.6, "eval_time": 9.792388439178467, "mean_episode_reward": 1.6, "best_episode_reward": 3.0, "step": 670000}
{"episode": 2014.0, "episode_reward": 1.2, "eval_time": 9.853425979614258, "mean_episode_reward": 1.2, "best_episode_reward": 5.0, "step": 671000}
{"episode": 2017.0, "episode_reward": 2.2, "eval_time": 9.932172775268555, "mean_episode_reward": 2.2, "best_episode_reward": 7.0, "step": 672000}
